{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75aac972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03a3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/test_data.csv', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a385c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reencode_and_normalize(text):\n",
    "    transl_table = dict([(ord(x), ord(y)) for x,y in zip( u\"‘’´“”–-\",  u\"'''\\\"\\\"--\")])\n",
    "    fixed_text = text.replace('鈥�', '\"').replace('鉂�', '').encode('gb18030').decode('utf8')\n",
    "    fixed_text = unicodedata.normalize(\"NFKD\", fixed_text)\n",
    "    fixed_text = fixed_text.translate(transl_table)\n",
    "    return fixed_text\n",
    "\n",
    "test_df['Text data'] = test_df['Text data'].apply(reencode_and_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a260da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Text data'] = test_df['Text data'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a567a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = list(test_df['Text data'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795153b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = 'kfold/output'\n",
    "n_folds = 4\n",
    "\n",
    "model_names = [d for d in os.listdir(models_path) if os.path.isdir(os.path.join(models_path, d))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6989e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deberta-mental-health-v3',\n",
       " 'roberta-large-v3-maxlen',\n",
       " 'regression-v1',\n",
       " 'deberta-large-v3-maxlen',\n",
       " 'regression-headtail-50',\n",
       " 'roberta-mental-health-headtail-75',\n",
       " 'roberta-mental-health-headtail-0',\n",
       " 'roberta-mental-health-v3-maxlen',\n",
       " 'regression',\n",
       " 'roberta-mental-health-headtail-50',\n",
       " 'roberta-mental-health-headtail-25']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5897ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "#model, tokenizer = load_model('hypsearch/output/roberta-large-v3-maxlen/trial_4')\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a859747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts, model, tokenizer, batchsize=64, device=torch.device('cpu')):\n",
    "    all_logits = []\n",
    "    for i in range(0, len(texts), batchsize):\n",
    "        #print(len(all_logits), len(texts)//batchsize)\n",
    "        batch = texts[i:i+batchsize]\n",
    "        inputs = tokenizer(batch, truncation=True, padding='max_length', return_tensors='pt', max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        all_logits.append(outputs.logits.detach().cpu())\n",
    "        \n",
    "        del inputs\n",
    "        del outputs\n",
    "\n",
    "    logits_output = torch.cat(all_logits)\n",
    "    softmax_output = F.softmax(logits_output, dim=-1)\n",
    "    preds = softmax_output.argmax(-1)\n",
    "    \n",
    "    return preds.numpy(), softmax_output.numpy(), logits_output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6af209b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold/output/deberta-mental-health-v3/fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold/output/deberta-mental-health-v3/fold_1\n",
      "kfold/output/deberta-mental-health-v3/fold_2\n",
      "kfold/output/deberta-mental-health-v3/fold_3\n",
      "kfold/output/roberta-large-v3-maxlen/fold_0\n",
      "kfold/output/roberta-large-v3-maxlen/fold_1\n",
      "kfold/output/roberta-large-v3-maxlen/fold_2\n",
      "kfold/output/roberta-large-v3-maxlen/fold_3\n",
      "kfold/output/deberta-large-v3-maxlen/fold_0\n",
      "kfold/output/deberta-large-v3-maxlen/fold_1\n",
      "kfold/output/deberta-large-v3-maxlen/fold_2\n",
      "kfold/output/deberta-large-v3-maxlen/fold_3\n",
      "kfold/output/roberta-mental-health-v3-maxlen/fold_0\n",
      "kfold/output/roberta-mental-health-v3-maxlen/fold_1\n",
      "kfold/output/roberta-mental-health-v3-maxlen/fold_2\n",
      "kfold/output/roberta-mental-health-v3-maxlen/fold_3\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:5')\n",
    "outputs = []\n",
    "for model_name in model_names:\n",
    "    fold_outputs = []\n",
    "    for fold in range(n_folds):\n",
    "        model_path = os.path.join(models_path, model_name, 'fold_'+str(fold))\n",
    "        print(model_path)\n",
    "\n",
    "        model, tokenizer = load_model(model_path)\n",
    "        model = model.to(device)\n",
    "        model_outputs = predict(test_texts, model, tokenizer, batchsize=128, device=device)\n",
    "        fold_outputs.append(model_outputs)\n",
    "    outputs.append(fold_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd360353",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0:\"moderate\",\n",
    "    1:\"not depression\",\n",
    "    2:\"severe\"\n",
    "}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d3483d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_flatten = []\n",
    "for m in outputs:\n",
    "    for f in m:\n",
    "        outputs_flatten.append(f)\n",
    "len(outputs_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e98c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.asarray([o[0] for o in outputs_flatten])\n",
    "softmax = np.asarray([o[1] for o in outputs_flatten])\n",
    "logits = np.asarray([o[2] for o in outputs_flatten])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "029cb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_mean(preds):\n",
    "    map_ordered = {0:1, 1:0, 2:2}\n",
    "    unmap_ordered = {1:0, 0:1, 2:2}\n",
    "    \n",
    "    pred_ordered = np.vectorize(lambda x: map_ordered[x])(preds)\n",
    "    pred_ordered_mean = np.mean(pred_ordered, axis=0).round()\n",
    "    pred_ordered_mean_unmap = np.vectorize(lambda x: unmap_ordered[x])(pred_ordered_mean)\n",
    "    return pred_ordered_mean_unmap\n",
    "\n",
    "def mode(preds):\n",
    "    return stats.mode(preds, axis=0).mode[0]\n",
    "\n",
    "def logits_mean(logits):\n",
    "    return np.mean(logits, axis=0).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e686179",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"ordered_mean\": ordered_mean(preds),\n",
    "    \"mode\": mode(preds),\n",
    "    \"logits_mean\": logits_mean(logits),\n",
    "}\n",
    "\n",
    "for name, preds_model in results.items():\n",
    "    sub_df = test_df.copy()\n",
    "    sub_df['class_label'] = preds_model\n",
    "    sub_df['class_label'] = sub_df['class_label'].map(id2label)\n",
    "    sub_df['pid'] = sub_df['Pid']\n",
    "    sub_df.to_csv(os.path.join('submissions', name+'.csv'), index=False)\n",
    "    sub_df[['pid', 'class_label']].to_csv(os.path.join('submissions', 'DeepLearningBrasil_'+name+'.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9959592c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = list(results.values())\n",
    "(results_list[1] != results_list[1].copy()).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaeadb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pid</th>\n",
       "      <th>Text data</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_id_1</td>\n",
       "      <td>This is me. Don't get me wrong, it's better th...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_id_2</td>\n",
       "      <td>I hate that people don't understand that i don...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_id_3</td>\n",
       "      <td>But here I am, 24 years old man and doing exac...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_id_4</td>\n",
       "      <td>I'm trapped inside. Does anyone else get that ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_id_5</td>\n",
       "      <td>I read a lot of posts on here of people strugg...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_id_495</td>\n",
       "      <td>I'm 14\\nmy mom doesn't take my mental health s...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_id_496</td>\n",
       "      <td>I was quite shocked at their reactions. I sort...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_id_497</td>\n",
       "      <td>Lying on my bed..... fantasising another life ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_id_498</td>\n",
       "      <td>I was bullied in elementary school, and I alwa...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_id_499</td>\n",
       "      <td>I can't go on. Im after finishing a 26oz bottl...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pid                                          Text data  \\\n",
       "0      test_id_1  This is me. Don't get me wrong, it's better th...   \n",
       "1      test_id_2  I hate that people don't understand that i don...   \n",
       "2      test_id_3  But here I am, 24 years old man and doing exac...   \n",
       "3      test_id_4  I'm trapped inside. Does anyone else get that ...   \n",
       "4      test_id_5  I read a lot of posts on here of people strugg...   \n",
       "..           ...                                                ...   \n",
       "494  test_id_495  I'm 14\\nmy mom doesn't take my mental health s...   \n",
       "495  test_id_496  I was quite shocked at their reactions. I sort...   \n",
       "496  test_id_497  Lying on my bed..... fantasising another life ...   \n",
       "497  test_id_498  I was bullied in elementary school, and I alwa...   \n",
       "498  test_id_499  I can't go on. Im after finishing a 26oz bottl...   \n",
       "\n",
       "        class_label  \n",
       "0          moderate  \n",
       "1          moderate  \n",
       "2    not depression  \n",
       "3          moderate  \n",
       "4          moderate  \n",
       "..              ...  \n",
       "494        moderate  \n",
       "495  not depression  \n",
       "496        moderate  \n",
       "497        moderate  \n",
       "498        moderate  \n",
       "\n",
       "[499 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"softmax_mean_preds\": np.mean(softmax, axis=0).argmax(-1),\n",
    "    \"softmax_max_preds\": np.max(softmax, axis=0).argmax(-1),\n",
    "    \"logits_mean_preds\": np.mean(logits, axis=0).argmax(-1),\n",
    "    \"logits_max_preds\": np.max(logits, axis=0).argmax(-1),\n",
    "    \"preds_mode\": stats.mode(preds, axis=0).mode[0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(r, f1_score(y_true, results[r], average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
