{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a3473e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dicriminator_weights = 'deberta/deberta-v3-large/pytorch_model.bin'\n",
    "generator_weights = 'deberta/deberta-v3-large/pytorch_model.generator.bin'\n",
    "dicriminator = torch.load(dicriminator_weights, map_location='cpu')\n",
    "generator = torch.load(generator_weights, map_location='cpu')\n",
    "if 'deberta.embeddings.word_embeddings._weight' not in dicriminator:\n",
    "    dicriminator['deberta.embeddings.word_embeddings._weight'] = (dicriminator['deberta.embeddings.word_embeddings.weight'] - generator['deberta.embeddings.word_embeddings.weight']).clone()\n",
    "    dicriminator['deberta.embeddings.position_embeddings._weight'] = (dicriminator['deberta.embeddings.position_embeddings.weight'] - generator['deberta.embeddings.position_embeddings.weight']).clone()\n",
    "torch.save(dicriminator, \"deberta/deberta-v3-large/pytorch_model.fix.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80192b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before deberta.embeddings.word_embeddings.weight torch.Size([251000, 768])\n",
      "after deberta.embeddings.word_embeddings.weight torch.Size([128100, 768])\n",
      "before lm_predictions.lm_head.bias torch.Size([251000])\n",
      "after lm_predictions.lm_head.bias torch.Size([128100])\n",
      "before deberta.embeddings.word_embeddings._weight torch.Size([251000, 768])\n",
      "after deberta.embeddings.word_embeddings._weight torch.Size([128100, 768])\n",
      "before lm_predictions.lm_head.bias torch.Size([251000])\n",
      "after lm_predictions.lm_head.bias torch.Size([128100])\n",
      "before deberta.embeddings.word_embeddings.weight torch.Size([251000, 768])\n",
      "after deberta.embeddings.word_embeddings.weight torch.Size([128100, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dicriminator_weights = 'deberta/mdeberta-v3-base/pytorch_model.bin'\n",
    "generator_weights = 'deberta/mdeberta-v3-base/pytorch_model.generator.bin'\n",
    "\n",
    "original_vocab_size = 251000\n",
    "target_vocab_size = 128100\n",
    "\n",
    "discriminator = torch.load(dicriminator_weights, map_location='cpu')\n",
    "generator = torch.load(generator_weights, map_location='cpu')\n",
    "\n",
    "for state_dict in [discriminator, generator]:\n",
    "    for key in list(state_dict.keys()):\n",
    "        if state_dict[key].shape[0] == original_vocab_size:\n",
    "            print('before', key, state_dict[key].shape)\n",
    "            state_dict[key] = state_dict[key].split(target_vocab_size)[0].clone()\n",
    "            print('after', key, state_dict[key].shape)\n",
    "\n",
    "torch.save(discriminator, \"deberta/mdeberta-v3-base/pytorch_model.reshape.bin\")\n",
    "torch.save(generator, \"deberta/mdeberta-v3-base/pytorch_model.reshape.generator.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73285cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.4G\n",
      "1.3G -rw-r--r-- 1 root root 1.3G Apr  6 02:32 pytorch_model.bin\n",
      "906M -rw-r--r-- 1 root root 906M Apr  6 02:32 pytorch_model.generator.bin\n",
      "731M -rw-r--r-- 1 root root 731M Jun  1 23:54 pytorch_model.reshape.bin\n",
      "546M -rw-r--r-- 1 root root 546M Jun  1 23:54 pytorch_model.reshape.generator.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -lsh deberta/mdeberta-v3-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2837c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0187, -0.0047, -0.0024,  ..., -0.0198,  0.0154,  0.0246],\n",
       "        [-0.0253, -0.0084, -0.0109,  ..., -0.0201, -0.0056, -0.0047],\n",
       "        [-0.0233, -0.0060, -0.0109,  ..., -0.0165, -0.0049, -0.0019],\n",
       "        ...,\n",
       "        [-0.2800, -0.0232, -0.0640,  ...,  0.1013,  0.0841,  0.1001],\n",
       "        [-0.3164,  0.0015, -0.2363,  ..., -0.0097,  0.0348,  0.2197],\n",
       "        [-0.2710, -0.0572, -0.0813,  ...,  0.0056,  0.1879, -0.0383]],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = torch.load(\"deberta/mdeberta-v3-base/pytorch_model.reshape.bin\", map_location='cpu')\n",
    "discriminator['deberta.embeddings.word_embeddings.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b2fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d4fb21726f2c7e7a5515828de1fa5ccbbde9795  deberta/mdeberta-v3-base/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!sha1sum \"deberta/mdeberta-v3-base/pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c787ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6c70605d29ff9af82911bc628efd40f04d5a9002  deberta/mdeberta-v3-base/pytorch_model.reshape.bin\n"
     ]
    }
   ],
   "source": [
    "!sha1sum \"deberta/mdeberta-v3-base/pytorch_model.reshape.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f606f203",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator.embeddings.word_embeddings.weight tensor([[-0.0501, -0.0456, -0.0493,  ..., -0.0525, -0.0520, -0.0367],\n",
      "        [-0.0024, -0.0065,  0.0099,  ..., -0.0135, -0.0091, -0.0034],\n",
      "        [-0.0002, -0.0050,  0.0105,  ..., -0.0146, -0.0082, -0.0082],\n",
      "        ...,\n",
      "        [-0.0497, -0.0591, -0.0370,  ..., -0.0590, -0.0502, -0.0357],\n",
      "        [-0.0446, -0.0495, -0.0461,  ..., -0.0547, -0.0564, -0.0456],\n",
      "        [-0.0398, -0.0425, -0.0417,  ..., -0.0585, -0.0485, -0.0334]],\n",
      "       dtype=torch.float16)\n",
      "discriminator.embeddings.word_embeddings._weight tensor([[-0.0690, -0.0634, -0.0508,  ..., -0.0562, -0.0447, -0.0366],\n",
      "        [-0.0070,  0.0010,  0.0031,  ..., -0.0152, -0.0202, -0.0076],\n",
      "        [-0.0196,  0.0115,  0.0088,  ..., -0.0115, -0.0091, -0.0049],\n",
      "        ...,\n",
      "        [-0.0609, -0.0787, -0.0340,  ..., -0.0591, -0.0501, -0.0352],\n",
      "        [-0.0704, -0.0728, -0.0488,  ..., -0.0565, -0.0470, -0.0415],\n",
      "        [-0.0572, -0.0560, -0.0423,  ..., -0.0613, -0.0490, -0.0315]],\n",
      "       dtype=torch.float16)\n",
      "discriminator.embeddings.position_embeddings.weight tensor([[ 5.3406e-05,  5.0545e-05, -5.7220e-06,  ...,  1.9073e-06,\n",
      "          7.6294e-06, -4.6253e-05],\n",
      "        [ 1.0760e-01,  4.3640e-03, -8.7769e-02,  ..., -1.8738e-01,\n",
      "          9.5093e-02,  6.0852e-02],\n",
      "        [ 8.4412e-02,  1.1124e-02, -8.3466e-03,  ...,  2.1133e-02,\n",
      "          7.0557e-02,  6.2561e-02],\n",
      "        ...,\n",
      "        [-2.7313e-03, -1.9531e-02,  6.8542e-02,  ..., -2.5558e-03,\n",
      "          3.5431e-02,  1.6647e-02],\n",
      "        [-8.6243e-02,  7.0801e-03,  9.4910e-03,  ..., -6.8848e-02,\n",
      "          5.0446e-02,  2.0294e-02],\n",
      "        [ 2.4796e-05,  3.1590e-05, -3.2902e-05,  ...,  1.9073e-05,\n",
      "          2.4796e-05, -3.8147e-06]], dtype=torch.float16)\n",
      "discriminator.embeddings.position_embeddings._weight tensor([[ 0.0068, -0.0004, -0.0020,  ..., -0.0021, -0.0041,  0.0008],\n",
      "        [ 0.1212,  0.0635, -0.0303,  ..., -0.0756,  0.1246,  0.0602],\n",
      "        [ 0.0814,  0.0176, -0.0175,  ...,  0.0423,  0.0687,  0.0483],\n",
      "        ...,\n",
      "        [-0.0169,  0.0037,  0.0623,  ..., -0.0119,  0.0408,  0.0162],\n",
      "        [-0.0478,  0.0714,  0.0111,  ..., -0.0581,  0.0734,  0.0585],\n",
      "        [ 0.0005,  0.0002,  0.0003,  ..., -0.0053,  0.0027, -0.0057]],\n",
      "       dtype=torch.float16)\n",
      "generator.embeddings.word_embeddings.weight tensor([[ 0.0188,  0.0177,  0.0014,  ...,  0.0038, -0.0073, -0.0001],\n",
      "        [ 0.0046, -0.0075,  0.0068,  ...,  0.0018,  0.0111,  0.0042],\n",
      "        [ 0.0194, -0.0165,  0.0017,  ..., -0.0031,  0.0009, -0.0033],\n",
      "        ...,\n",
      "        [ 0.0113,  0.0196, -0.0031,  ...,  0.0001, -0.0002, -0.0006],\n",
      "        [ 0.0259,  0.0233,  0.0027,  ...,  0.0018, -0.0094, -0.0041],\n",
      "        [ 0.0175,  0.0135,  0.0006,  ...,  0.0028,  0.0004, -0.0019]],\n",
      "       dtype=torch.float16)\n",
      "generator.embeddings.position_embeddings.weight tensor([[-0.0067,  0.0005,  0.0020,  ...,  0.0021,  0.0041, -0.0009],\n",
      "        [-0.0136, -0.0592, -0.0575,  ..., -0.1118, -0.0295,  0.0006],\n",
      "        [ 0.0030, -0.0064,  0.0091,  ..., -0.0211,  0.0019,  0.0143],\n",
      "        ...,\n",
      "        [ 0.0141, -0.0232,  0.0062,  ...,  0.0094, -0.0054,  0.0005],\n",
      "        [-0.0384, -0.0643, -0.0016,  ..., -0.0107, -0.0230, -0.0382],\n",
      "        [-0.0005, -0.0002, -0.0004,  ...,  0.0053, -0.0027,  0.0057]],\n",
      "       dtype=torch.float16)\n",
      "should equal to discriminator.embeddings.word_embeddings._weight tensor([[-0.0690, -0.0634, -0.0508,  ..., -0.0562, -0.0447, -0.0366],\n",
      "        [-0.0070,  0.0010,  0.0031,  ..., -0.0152, -0.0202, -0.0076],\n",
      "        [-0.0196,  0.0115,  0.0088,  ..., -0.0115, -0.0091, -0.0049],\n",
      "        ...,\n",
      "        [-0.0609, -0.0787, -0.0340,  ..., -0.0591, -0.0501, -0.0352],\n",
      "        [-0.0704, -0.0728, -0.0488,  ..., -0.0565, -0.0470, -0.0415],\n",
      "        [-0.0572, -0.0560, -0.0423,  ..., -0.0613, -0.0490, -0.0315]],\n",
      "       dtype=torch.float16)\n",
      "should equal to discriminator.embeddings.position_embeddings._weight tensor([[ 0.0068, -0.0004, -0.0020,  ..., -0.0021, -0.0041,  0.0008],\n",
      "        [ 0.1212,  0.0635, -0.0302,  ..., -0.0756,  0.1246,  0.0602],\n",
      "        [ 0.0814,  0.0176, -0.0175,  ...,  0.0423,  0.0687,  0.0483],\n",
      "        ...,\n",
      "        [-0.0169,  0.0037,  0.0623,  ..., -0.0119,  0.0408,  0.0162],\n",
      "        [-0.0478,  0.0714,  0.0111,  ..., -0.0581,  0.0734,  0.0585],\n",
      "        [ 0.0005,  0.0002,  0.0003,  ..., -0.0053,  0.0027, -0.0057]],\n",
      "       dtype=torch.float16)\n",
      "should equal to discriminator.embeddings.word_embeddings.weight tensor([[-0.0501, -0.0456, -0.0493,  ..., -0.0525, -0.0520, -0.0367],\n",
      "        [-0.0024, -0.0065,  0.0099,  ..., -0.0135, -0.0091, -0.0034],\n",
      "        [-0.0002, -0.0050,  0.0105,  ..., -0.0146, -0.0082, -0.0082],\n",
      "        ...,\n",
      "        [-0.0497, -0.0591, -0.0370,  ..., -0.0590, -0.0502, -0.0357],\n",
      "        [-0.0446, -0.0495, -0.0461,  ..., -0.0547, -0.0564, -0.0456],\n",
      "        [-0.0398, -0.0425, -0.0417,  ..., -0.0585, -0.0485, -0.0334]],\n",
      "       dtype=torch.float16)\n",
      "should equal to discriminator.embeddings.position_embeddings.weight tensor([[ 5.3406e-05,  5.0545e-05, -5.7220e-06,  ...,  1.9073e-06,\n",
      "          7.6294e-06, -4.6253e-05],\n",
      "        [ 1.0760e-01,  4.3640e-03, -8.7769e-02,  ..., -1.8738e-01,\n",
      "          9.5093e-02,  6.0852e-02],\n",
      "        [ 8.4412e-02,  1.1124e-02, -8.3466e-03,  ...,  2.1133e-02,\n",
      "          7.0557e-02,  6.2561e-02],\n",
      "        ...,\n",
      "        [-2.7313e-03, -1.9531e-02,  6.8542e-02,  ..., -2.5558e-03,\n",
      "          3.5431e-02,  1.6647e-02],\n",
      "        [-8.6243e-02,  7.0801e-03,  9.4910e-03,  ..., -6.8848e-02,\n",
      "          5.0446e-02,  2.0294e-02],\n",
      "        [ 2.4796e-05,  3.1590e-05, -3.2902e-05,  ...,  1.9073e-05,\n",
      "          2.4796e-05, -3.8147e-06]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "original = torch.load('deberta/models/deberta-v3-large-fix-v4-2/discriminator/pytorch.model-015000.bin', map_location='cpu')\n",
    "original_g = torch.load('deberta/models/deberta-v3-large-fix-v4-2/generator/pytorch.model-015000.bin', map_location='cpu')\n",
    "\n",
    "#[(k, original[k].shape, original[k]) for k in original if 'deberta.embeddings' in k]\n",
    "print('discriminator.embeddings.word_embeddings.weight', original['deberta.embeddings.word_embeddings.weight'])\n",
    "print('discriminator.embeddings.word_embeddings._weight', original['deberta.embeddings.word_embeddings._weight'])\n",
    "\n",
    "print('discriminator.embeddings.position_embeddings.weight', original['deberta.embeddings.position_embeddings.weight'])\n",
    "print('discriminator.embeddings.position_embeddings._weight', original['deberta.embeddings.position_embeddings._weight'])\n",
    "\n",
    "print('generator.embeddings.word_embeddings.weight', original_g['deberta.embeddings.word_embeddings.weight'])\n",
    "print('generator.embeddings.position_embeddings.weight', original_g['deberta.embeddings.position_embeddings.weight'])\n",
    "\n",
    "print('should equal to discriminator.embeddings.word_embeddings._weight', original['deberta.embeddings.word_embeddings.weight'] - original_g['deberta.embeddings.word_embeddings.weight'])\n",
    "print('should equal to discriminator.embeddings.position_embeddings._weight', original['deberta.embeddings.position_embeddings.weight'] - original_g['deberta.embeddings.position_embeddings.weight'])\n",
    "\n",
    "print('should equal to discriminator.embeddings.word_embeddings.weight', original['deberta.embeddings.word_embeddings._weight'] + original_g['deberta.embeddings.word_embeddings.weight'])\n",
    "print('should equal to discriminator.embeddings.position_embeddings.weight', original['deberta.embeddings.position_embeddings._weight'] + original_g['deberta.embeddings.position_embeddings.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0453b2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
      "Git LFS initialized.\n",
      "Cloning into 'models/deberta-v3-large-mental-health-v2'...\n",
      "remote: Enumerating objects: 75, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 75 (delta 0), reused 0 (delta 0), pack-reused 71\u001b[K\n",
      "Unpacking objects: 100% (75/75), 10.29 KiB | 658.00 KiB/s, done.\n",
      "Filtering content: 100% (4/4), 2.96 GiB | 4.33 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf  models/deberta-v3-large-mental-health-v2\n",
    "!git lfs install\n",
    "!git clone https://huggingface.co/microsoft/deberta-v3-large models/deberta-v3-large-mental-health-v2\n",
    "!rm models/deberta-v3-large-mental-health-v2/tf_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b25f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "modelpath = \"deberta/models/deberta-v3-large-fix-v4-2/{}/pytorch.model-{}.bin\"\n",
    "checkpoint = \"025000\"\n",
    "output_path = 'models/deberta-v3-large-mental-health-v2'\n",
    "\n",
    "discriminator = torch.load(modelpath.format('discriminator', checkpoint), map_location='cpu')\n",
    "del discriminator['deberta.embeddings.word_embeddings._weight']\n",
    "del discriminator['deberta.embeddings.position_embeddings._weight']\n",
    "torch.save(discriminator, os.path.join(output_path, 'pytorch_model.bin'))\n",
    "generator = torch.load(modelpath.format('generator', checkpoint), map_location='cpu')\n",
    "torch.save(generator, os.path.join(output_path, 'pytorch_model.generator.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2752bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp deberta/models/deberta-v3-large-es-v3/discriminator/pytorch.model-003000.bin models/deberta-v3-large-mental-health-v2/pytorch_model.bin\n",
    "#!cp deberta/models/deberta-v3-large-es-v3/generator/pytorch.model-003000.bin models/deberta-v3-large-mental-health-v2/pytorch_model.generator.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6553aa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "path = 'roberta-mental-health'\n",
    "#AutoModel.from_pretrained('microsoft/deberta-v3-large').save_pretrained('models/deberta-v3-large-mental-health-v2')\n",
    "#AutoTokenizer.from_pretrained('microsoft/deberta-v3-large').save_pretrained('models/deberta-v3-large-mental-health-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eda7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm models/deberta-v3-large-mental-health-v2/tf_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913fdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477acd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "discriminator = torch.load('deberta/models/deberta-v3-large-v2/discriminator/pytorch.model-005000.bin', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0cb3f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deberta.embeddings.word_embeddings._weight',\n",
       " 'deberta.embeddings.word_embeddings.weight',\n",
       " 'deberta.embeddings.position_embeddings._weight',\n",
       " 'deberta.embeddings.position_embeddings.weight',\n",
       " 'deberta.embeddings.LayerNorm.weight',\n",
       " 'deberta.embeddings.LayerNorm.bias']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = [k for k in discriminator.keys() if 'deberta.embeddings' in k]\n",
    "d_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "840d43a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deberta.embeddings.word_embeddings.weight',\n",
       "  torch.Size([128100, 1024]),\n",
       "  tensor([[ 1.8890e-02,  1.7776e-02,  1.4286e-03,  ...,  3.7632e-03,\n",
       "           -7.3776e-03, -9.8228e-05],\n",
       "          [ 4.7646e-03, -7.3166e-03,  8.7433e-03,  ...,  1.0443e-03,\n",
       "            1.1230e-02,  2.2469e-03],\n",
       "          [ 1.8829e-02, -1.5381e-02,  9.7942e-04,  ..., -2.5730e-03,\n",
       "            1.5574e-03, -1.1778e-03],\n",
       "          ...,\n",
       "          [ 1.1292e-02,  1.9653e-02, -3.0918e-03,  ...,  1.2565e-04,\n",
       "           -1.7440e-04, -5.7507e-04],\n",
       "          [ 2.5970e-02,  2.3392e-02,  2.6569e-03,  ...,  1.8206e-03,\n",
       "           -9.4528e-03, -4.1046e-03],\n",
       "          [ 1.7502e-02,  1.3474e-02,  5.7983e-04,  ...,  2.7714e-03,\n",
       "            4.3130e-04, -1.9255e-03]], dtype=torch.float16)),\n",
       " ('deberta.embeddings.position_embeddings.weight',\n",
       "  torch.Size([512, 1024]),\n",
       "  tensor([[-0.0067,  0.0005,  0.0020,  ...,  0.0021,  0.0041, -0.0009],\n",
       "          [-0.0199, -0.0573, -0.0528,  ..., -0.1196, -0.0335,  0.0053],\n",
       "          [ 0.0096, -0.0049,  0.0075,  ..., -0.0229,  0.0069,  0.0204],\n",
       "          ...,\n",
       "          [ 0.0142, -0.0233,  0.0063,  ...,  0.0094, -0.0054,  0.0005],\n",
       "          [-0.0385, -0.0645, -0.0016,  ..., -0.0108, -0.0231, -0.0383],\n",
       "          [-0.0005, -0.0002, -0.0004,  ...,  0.0053, -0.0027,  0.0057]],\n",
       "         dtype=torch.float16)),\n",
       " ('deberta.embeddings.LayerNorm.weight',\n",
       "  torch.Size([1024]),\n",
       "  tensor([1.1426, 1.0576, 1.0908,  ..., 1.0342, 1.1152, 1.1094],\n",
       "         dtype=torch.float16)),\n",
       " ('deberta.embeddings.LayerNorm.bias',\n",
       "  torch.Size([1024]),\n",
       "  tensor([-0.0405,  0.0761, -0.1710,  ...,  0.1859,  0.0020, -0.0242],\n",
       "         dtype=torch.float16))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = torch.load('deberta/models/deberta-v3-large-es-v3/discriminator/pytorch.model-003000.bin', map_location='cpu')\n",
    "[(k, original[k].shape, original[k]) for k in original if 'deberta.embeddings' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7add252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deberta.embeddings.word_embeddings.weight',\n",
       "  torch.Size([128100, 1024]),\n",
       "  tensor([[ 1.8890e-02,  1.7776e-02,  1.4286e-03,  ...,  3.7632e-03,\n",
       "           -7.3776e-03, -9.8228e-05],\n",
       "          [ 4.7646e-03, -7.3166e-03,  8.7433e-03,  ...,  1.0443e-03,\n",
       "            1.1230e-02,  2.2469e-03],\n",
       "          [ 1.8829e-02, -1.5381e-02,  9.7942e-04,  ..., -2.5730e-03,\n",
       "            1.5574e-03, -1.1778e-03],\n",
       "          ...,\n",
       "          [ 1.1292e-02,  1.9653e-02, -3.0918e-03,  ...,  1.2565e-04,\n",
       "           -1.7440e-04, -5.7507e-04],\n",
       "          [ 2.5970e-02,  2.3392e-02,  2.6569e-03,  ...,  1.8206e-03,\n",
       "           -9.4528e-03, -4.1046e-03],\n",
       "          [ 1.7502e-02,  1.3474e-02,  5.7983e-04,  ...,  2.7714e-03,\n",
       "            4.3130e-04, -1.9255e-03]], dtype=torch.float16)),\n",
       " ('deberta.embeddings.position_embeddings.weight',\n",
       "  torch.Size([512, 1024]),\n",
       "  tensor([[-0.0067,  0.0005,  0.0020,  ...,  0.0021,  0.0041, -0.0009],\n",
       "          [-0.0199, -0.0573, -0.0528,  ..., -0.1196, -0.0335,  0.0053],\n",
       "          [ 0.0096, -0.0049,  0.0075,  ..., -0.0229,  0.0069,  0.0204],\n",
       "          ...,\n",
       "          [ 0.0142, -0.0233,  0.0063,  ...,  0.0094, -0.0054,  0.0005],\n",
       "          [-0.0385, -0.0645, -0.0016,  ..., -0.0108, -0.0231, -0.0383],\n",
       "          [-0.0005, -0.0002, -0.0004,  ...,  0.0053, -0.0027,  0.0057]],\n",
       "         dtype=torch.float16)),\n",
       " ('deberta.embeddings.LayerNorm.weight',\n",
       "  torch.Size([1024]),\n",
       "  tensor([0.5664, 0.5737, 0.6978,  ..., 0.8013, 0.8428, 0.7573],\n",
       "         dtype=torch.float16)),\n",
       " ('deberta.embeddings.LayerNorm.bias',\n",
       "  torch.Size([1024]),\n",
       "  tensor([ 0.0989,  0.0426,  0.0015,  ...,  0.0359, -0.0066,  0.0630],\n",
       "         dtype=torch.float16))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = torch.load('deberta/models/deberta-v3-large-es-v3/generator/pytorch.model-003000.bin', map_location='cpu')\n",
    "[(k, original[k].shape, original[k]) for k in original if 'deberta.embeddings' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76f76aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deberta.embeddings.word_embeddings.weight',\n",
       "  torch.Size([128100, 1024]),\n",
       "  tensor([[-0.0504, -0.0459, -0.0496,  ..., -0.0528, -0.0523, -0.0369],\n",
       "          [-0.0017, -0.0081,  0.0130,  ..., -0.0137, -0.0064, -0.0035],\n",
       "          [-0.0034, -0.0082,  0.0118,  ..., -0.0140, -0.0061, -0.0045],\n",
       "          ...,\n",
       "          [-0.0500, -0.0595, -0.0373,  ..., -0.0593, -0.0505, -0.0359],\n",
       "          [-0.0448, -0.0498, -0.0464,  ..., -0.0550, -0.0567, -0.0458],\n",
       "          [-0.0400, -0.0428, -0.0420,  ..., -0.0588, -0.0488, -0.0336]],\n",
       "         dtype=torch.float16)),\n",
       " ('deberta.embeddings.position_embeddings.weight',\n",
       "  torch.Size([512, 1024]),\n",
       "  tensor([[ 5.1737e-05,  5.0843e-05, -6.3777e-06,  ...,  2.0266e-06,\n",
       "            7.5102e-06, -4.6372e-05],\n",
       "          [ 1.0138e-01,  1.2589e-02, -8.4656e-02,  ..., -1.9812e-01,\n",
       "            9.2041e-02,  6.9214e-02],\n",
       "          [ 9.3933e-02,  1.7166e-02, -1.1780e-02,  ...,  1.9485e-02,\n",
       "            8.0505e-02,  6.5735e-02],\n",
       "          ...,\n",
       "          [-2.7542e-03, -1.9638e-02,  6.8909e-02,  ..., -2.5711e-03,\n",
       "            3.5614e-02,  1.6724e-02],\n",
       "          [-8.6670e-02,  7.1526e-03,  9.5367e-03,  ..., -6.9214e-02,\n",
       "            5.0690e-02,  2.0416e-02],\n",
       "          [ 2.4974e-05,  3.1769e-05, -3.3200e-05,  ...,  1.8179e-05,\n",
       "            2.3901e-05, -5.0664e-06]], dtype=torch.float16)),\n",
       " ('deberta.embeddings.LayerNorm.weight',\n",
       "  torch.Size([1024]),\n",
       "  tensor([1.1426, 1.0566, 1.0908,  ..., 1.0342, 1.1162, 1.1094],\n",
       "         dtype=torch.float16)),\n",
       " ('deberta.embeddings.LayerNorm.bias',\n",
       "  torch.Size([1024]),\n",
       "  tensor([-0.0406,  0.0761, -0.1703,  ...,  0.1855,  0.0016, -0.0242],\n",
       "         dtype=torch.float16))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = torch.load('deberta/deberta-v3-large/pytorch_model.bin', map_location='cpu')\n",
    "[(k, original[k].shape, original[k]) for k in original if 'deberta.embeddings' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8f5804f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deberta.embeddings.word_embeddings.weight',\n",
       "  torch.Size([128100, 1024]),\n",
       "  tensor([[ 1.8906e-02,  1.7792e-02,  1.4267e-03,  ...,  3.7670e-03,\n",
       "           -7.3891e-03, -9.7692e-05],\n",
       "          [ 4.4289e-03, -7.9422e-03,  8.4000e-03,  ...,  8.1301e-04,\n",
       "            1.0284e-02,  3.8700e-03],\n",
       "          [ 1.6312e-02, -1.6815e-02,  2.1744e-03,  ..., -2.0256e-03,\n",
       "            2.1210e-03,  1.0052e-03],\n",
       "          ...,\n",
       "          [ 1.1299e-02,  1.9669e-02, -3.0994e-03,  ...,  1.2505e-04,\n",
       "           -1.7583e-04, -5.7459e-04],\n",
       "          [ 2.6001e-02,  2.3422e-02,  2.6569e-03,  ...,  1.8225e-03,\n",
       "           -9.4681e-03, -4.1084e-03],\n",
       "          [ 1.7517e-02,  1.3489e-02,  5.7650e-04,  ...,  2.7733e-03,\n",
       "            4.3035e-04, -1.9264e-03]], dtype=torch.float16)),\n",
       " ('deberta.embeddings.position_embeddings.weight',\n",
       "  torch.Size([512, 1024]),\n",
       "  tensor([[-0.0067,  0.0005,  0.0020,  ...,  0.0021,  0.0041, -0.0009],\n",
       "          [-0.0204, -0.0512, -0.0542,  ..., -0.1222, -0.0332,  0.0087],\n",
       "          [ 0.0121, -0.0005,  0.0058,  ..., -0.0230,  0.0115,  0.0172],\n",
       "          ...,\n",
       "          [ 0.0142, -0.0233,  0.0063,  ...,  0.0094, -0.0054,  0.0005],\n",
       "          [-0.0386, -0.0646, -0.0016,  ..., -0.0108, -0.0231, -0.0384],\n",
       "          [-0.0005, -0.0002, -0.0004,  ...,  0.0053, -0.0027,  0.0058]],\n",
       "         dtype=torch.float16)),\n",
       " ('deberta.embeddings.LayerNorm.weight',\n",
       "  torch.Size([1024]),\n",
       "  tensor([0.5684, 0.5820, 0.6958,  ..., 0.7988, 0.8403, 0.7578],\n",
       "         dtype=torch.float16)),\n",
       " ('deberta.embeddings.LayerNorm.bias',\n",
       "  torch.Size([1024]),\n",
       "  tensor([ 0.1002,  0.0385,  0.0019,  ...,  0.0334, -0.0076,  0.0626],\n",
       "         dtype=torch.float16))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_g = torch.load('deberta/deberta-v3-large/pytorch_model.generator.bin', map_location='cpu')\n",
    "[(k, original_g[k].shape, original_g[k]) for k in original_g if 'deberta.embeddings' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c0c8bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta.embeddings.word_embeddings.weight tensor([[ 0.0187, -0.0047, -0.0024,  ..., -0.0198,  0.0154,  0.0246],\n",
      "        [-0.0253, -0.0084, -0.0109,  ..., -0.0201, -0.0056, -0.0047],\n",
      "        [-0.0233, -0.0060, -0.0109,  ..., -0.0165, -0.0049, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0157, -0.0065, -0.0094,  ..., -0.0145,  0.0058,  0.0148],\n",
      "        [ 0.0123, -0.0027, -0.0048,  ..., -0.0144,  0.0147,  0.0226],\n",
      "        [ 0.0246,  0.0043, -0.0025,  ..., -0.0212,  0.0232,  0.0247]],\n",
      "       dtype=torch.float16)\n",
      "deberta.embeddings.word_embeddings._weight tensor([[ 0.0099,  0.0036,  0.0137,  ..., -0.0282,  0.0195,  0.0024],\n",
      "        [-0.0341, -0.0494, -0.0281,  ..., -0.0823, -0.0181, -0.0084],\n",
      "        [-0.0222,  0.0148, -0.0013,  ..., -0.0286, -0.0090, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0329,  0.0123,  0.0083,  ..., -0.0286,  0.0269,  0.0105],\n",
      "        [ 0.0257,  0.0163,  0.0057,  ..., -0.0081, -0.0016,  0.0111],\n",
      "        [ 0.0391,  0.0337,  0.0045,  ..., -0.0149,  0.0448,  0.0351]])\n",
      "deberta.embeddings.position_embeddings.weight tensor([[-0.0085,  0.0013,  0.0039,  ...,  0.0104,  0.0092, -0.0002],\n",
      "        [-0.0671,  0.0984,  0.0517,  ..., -0.0766, -0.0206,  0.1014],\n",
      "        [-0.0054,  0.0539,  0.0078,  ..., -0.0726, -0.0310,  0.0616],\n",
      "        ...,\n",
      "        [-0.0031,  0.0097,  0.0298,  ..., -0.0207, -0.0550, -0.0591],\n",
      "        [-0.0165, -0.0045,  0.0418,  ..., -0.0266, -0.0946, -0.0660],\n",
      "        [ 0.0008,  0.0019,  0.0017,  ...,  0.0026,  0.0041,  0.0005]],\n",
      "       dtype=torch.float16)\n",
      "deberta.embeddings.position_embeddings._weight tensor([[-0.0228,  0.0326,  0.0095,  ..., -0.0077,  0.0206,  0.0182],\n",
      "        [-0.0818,  0.1288,  0.0435,  ..., -0.0429, -0.0476,  0.1203],\n",
      "        [ 0.0064,  0.0594, -0.0121,  ..., -0.0809, -0.0295,  0.0544],\n",
      "        ...,\n",
      "        [-0.0018,  0.0096,  0.0228,  ..., -0.0247, -0.0489, -0.0758],\n",
      "        [-0.0328,  0.0074,  0.0187,  ..., -0.0251, -0.0750, -0.0602],\n",
      "        [-0.0044,  0.0079, -0.0119,  ...,  0.0212,  0.0060, -0.0074]])\n"
     ]
    }
   ],
   "source": [
    "original = torch.load('deberta/mdeberta-v3-base/pytorch_model.bin', map_location='cpu')\n",
    "#[(k, original[k].shape, original[k]) for k in original if 'deberta.embeddings' in k]\n",
    "print('deberta.embeddings.word_embeddings.weight', original['deberta.embeddings.word_embeddings.weight'])\n",
    "print('deberta.embeddings.word_embeddings._weight', original['deberta.embeddings.word_embeddings._weight'])\n",
    "\n",
    "print('deberta.embeddings.position_embeddings.weight', original['deberta.embeddings.position_embeddings.weight'])\n",
    "print('deberta.embeddings.position_embeddings._weight', original['deberta.embeddings.position_embeddings._weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a568a0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta.embeddings.word_embeddings.weight tensor([[ 0.0088, -0.0082, -0.0161,  ...,  0.0084, -0.0041,  0.0222],\n",
      "        [ 0.0087,  0.0409,  0.0172,  ...,  0.0622,  0.0125,  0.0036],\n",
      "        [-0.0011, -0.0209, -0.0095,  ...,  0.0122,  0.0040,  0.0058],\n",
      "        ...,\n",
      "        [-0.0172, -0.0188, -0.0176,  ...,  0.0141, -0.0211,  0.0043],\n",
      "        [-0.0133, -0.0190, -0.0105,  ..., -0.0062,  0.0163,  0.0115],\n",
      "        [-0.0145, -0.0294, -0.0071,  ..., -0.0063, -0.0215, -0.0104]])\n",
      "deberta.embeddings.position_embeddings.weight tensor([[ 1.4325e-02, -3.1255e-02, -5.6232e-03,  ...,  1.8072e-02,\n",
      "         -1.1372e-02, -1.8335e-02],\n",
      "        [ 1.4725e-02, -3.0408e-02,  8.2078e-03,  ..., -3.3722e-02,\n",
      "          2.7028e-02, -1.8940e-02],\n",
      "        [-1.1823e-02, -5.4432e-03,  1.9808e-02,  ...,  8.3164e-03,\n",
      "         -1.4451e-03,  7.1966e-03],\n",
      "        ...,\n",
      "        [-1.2880e-03,  9.6206e-05,  7.0541e-03,  ...,  4.0525e-03,\n",
      "         -6.0144e-03,  1.6610e-02],\n",
      "        [ 1.6347e-02, -1.1903e-02,  2.3155e-02,  ..., -1.5050e-03,\n",
      "         -1.9603e-02, -5.8545e-03],\n",
      "        [ 5.1148e-03, -6.0544e-03,  1.3674e-02,  ..., -1.8529e-02,\n",
      "         -1.9506e-03,  7.9108e-03]])\n"
     ]
    }
   ],
   "source": [
    "original_g = torch.load('deberta/mdeberta-v3-base/pytorch_model.generator.bin', map_location='cpu')\n",
    "#[(k, original_g[k].shape, original_g[k]) for k in original_g if 'deberta.embeddings' in k]\n",
    "print('deberta.embeddings.word_embeddings.weight', original_g['deberta.embeddings.word_embeddings.weight'])\n",
    "print('deberta.embeddings.position_embeddings.weight', original_g['deberta.embeddings.position_embeddings.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc16b019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calx tensor([[ 0.0099,  0.0036,  0.0137,  ..., -0.0282,  0.0195,  0.0024],\n",
      "        [-0.0341, -0.0494, -0.0281,  ..., -0.0823, -0.0181, -0.0084],\n",
      "        [-0.0222,  0.0148, -0.0013,  ..., -0.0286, -0.0090, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0329,  0.0123,  0.0083,  ..., -0.0286,  0.0269,  0.0105],\n",
      "        [ 0.0257,  0.0163,  0.0057,  ..., -0.0081, -0.0016,  0.0111],\n",
      "        [ 0.0391,  0.0337,  0.0045,  ..., -0.0149,  0.0448,  0.0351]])\n",
      "calx tensor([[-0.0228,  0.0326,  0.0095,  ..., -0.0077,  0.0206,  0.0182],\n",
      "        [-0.0818,  0.1288,  0.0435,  ..., -0.0429, -0.0476,  0.1203],\n",
      "        [ 0.0064,  0.0594, -0.0121,  ..., -0.0809, -0.0295,  0.0544],\n",
      "        ...,\n",
      "        [-0.0018,  0.0096,  0.0228,  ..., -0.0247, -0.0489, -0.0758],\n",
      "        [-0.0328,  0.0074,  0.0187,  ..., -0.0251, -0.0750, -0.0602],\n",
      "        [-0.0044,  0.0079, -0.0119,  ...,  0.0212,  0.0060, -0.0074]])\n"
     ]
    }
   ],
   "source": [
    "print('calx', original['deberta.embeddings.word_embeddings.weight'] - original_g['deberta.embeddings.word_embeddings.weight'])\n",
    "print('calx', original['deberta.embeddings.position_embeddings.weight'] - original_g['deberta.embeddings.position_embeddings.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7068f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deberta.embeddings.word_embeddings.weight', torch.Size([251000, 768])),\n",
       " ('deberta.embeddings.position_embeddings.weight', torch.Size([512, 768])),\n",
       " ('deberta.embeddings.LayerNorm.weight', torch.Size([768])),\n",
       " ('deberta.embeddings.LayerNorm.bias', torch.Size([768]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = torch.load('deberta/mdeberta-v3-base/pytorch_model.generator.bin', map_location='cpu')\n",
    "[(k, original[k].shape) for k in original if 'deberta.embeddings' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2473a824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deberta.embeddings.word_embeddings.weight',\n",
       " 'deberta.embeddings.position_embeddings.weight',\n",
       " 'deberta.embeddings.LayerNorm.weight',\n",
       " 'deberta.embeddings.LayerNorm.bias']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11577153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0547c9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deberta.embeddings.word_embeddings.weight',\n",
       " 'deberta.embeddings.position_embeddings.weight',\n",
       " 'deberta.embeddings.LayerNorm.weight',\n",
       " 'deberta.embeddings.LayerNorm.bias',\n",
       " 'deberta.embeddings.word_embeddings._weight',\n",
       " 'deberta.embeddings.position_embeddings._weight']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_k = [k for k in original.keys() if 'deberta.embeddings' in k]\n",
    "o_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f195bacc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original deberta.embeddings.word_embeddings._weight tensor([[ 0.0099,  0.0036,  0.0137,  ..., -0.0282,  0.0195,  0.0024],\n",
      "        [-0.0341, -0.0494, -0.0281,  ..., -0.0823, -0.0181, -0.0084],\n",
      "        [-0.0222,  0.0148, -0.0013,  ..., -0.0286, -0.0090, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0329,  0.0123,  0.0083,  ..., -0.0286,  0.0269,  0.0105],\n",
      "        [ 0.0257,  0.0163,  0.0057,  ..., -0.0081, -0.0016,  0.0111],\n",
      "        [ 0.0391,  0.0337,  0.0045,  ..., -0.0149,  0.0448,  0.0351]])\n",
      "discriminator deberta.embeddings.word_embeddings._weight tensor([[-0.0503, -0.0458, -0.0495,  ..., -0.0526, -0.0522, -0.0368],\n",
      "        [-0.0002, -0.0090,  0.0163,  ..., -0.0106, -0.0101, -0.0032],\n",
      "        [-0.0028, -0.0092,  0.0134,  ..., -0.0107, -0.0090, -0.0089],\n",
      "        ...,\n",
      "        [-0.0499, -0.0594, -0.0372,  ..., -0.0592, -0.0504, -0.0358],\n",
      "        [-0.0447, -0.0497, -0.0463,  ..., -0.0549, -0.0566, -0.0457],\n",
      "        [-0.0399, -0.0427, -0.0419,  ..., -0.0587, -0.0487, -0.0335]],\n",
      "       dtype=torch.float16)\n",
      "\n",
      "original deberta.embeddings.word_embeddings.weight tensor([[ 0.0187, -0.0047, -0.0024,  ..., -0.0198,  0.0154,  0.0246],\n",
      "        [-0.0253, -0.0084, -0.0109,  ..., -0.0201, -0.0056, -0.0047],\n",
      "        [-0.0233, -0.0060, -0.0109,  ..., -0.0165, -0.0049, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0157, -0.0065, -0.0094,  ..., -0.0145,  0.0058,  0.0148],\n",
      "        [ 0.0123, -0.0027, -0.0048,  ..., -0.0144,  0.0147,  0.0226],\n",
      "        [ 0.0246,  0.0043, -0.0025,  ..., -0.0212,  0.0232,  0.0247]],\n",
      "       dtype=torch.float16)\n",
      "discriminator deberta.embeddings.word_embeddings.weight tensor([[-0.0314, -0.0280, -0.0480,  ..., -0.0489, -0.0595, -0.0369],\n",
      "        [ 0.0027, -0.0168,  0.0235,  ..., -0.0113, -0.0012,  0.0003],\n",
      "        [ 0.0134, -0.0224,  0.0137,  ..., -0.0112, -0.0090, -0.0106],\n",
      "        ...,\n",
      "        [-0.0386, -0.0397, -0.0403,  ..., -0.0591, -0.0506, -0.0364],\n",
      "        [-0.0188, -0.0263, -0.0436,  ..., -0.0530, -0.0660, -0.0498],\n",
      "        [-0.0224, -0.0292, -0.0413,  ..., -0.0559, -0.0482, -0.0355]],\n",
      "       dtype=torch.float16)\n",
      "\n",
      "original deberta.embeddings.position_embeddings._weight tensor([[-0.0228,  0.0326,  0.0095,  ..., -0.0077,  0.0206,  0.0182],\n",
      "        [-0.0818,  0.1288,  0.0435,  ..., -0.0429, -0.0476,  0.1203],\n",
      "        [ 0.0064,  0.0594, -0.0121,  ..., -0.0809, -0.0295,  0.0544],\n",
      "        ...,\n",
      "        [-0.0018,  0.0096,  0.0228,  ..., -0.0247, -0.0489, -0.0758],\n",
      "        [-0.0328,  0.0074,  0.0187,  ..., -0.0251, -0.0750, -0.0602],\n",
      "        [-0.0044,  0.0079, -0.0119,  ...,  0.0212,  0.0060, -0.0074]])\n",
      "discriminator deberta.embeddings.position_embeddings._weight tensor([[ 5.1618e-05,  5.0724e-05, -6.3777e-06,  ...,  2.0266e-06,\n",
      "          7.5102e-06, -4.6253e-05],\n",
      "        [ 1.0114e-01,  1.2566e-02, -8.4473e-02,  ..., -1.9775e-01,\n",
      "          9.1858e-02,  6.9092e-02],\n",
      "        [ 9.3750e-02,  1.7136e-02, -1.1757e-02,  ...,  1.9440e-02,\n",
      "          8.0322e-02,  6.5613e-02],\n",
      "        ...,\n",
      "        [-2.7485e-03, -1.9592e-02,  6.8787e-02,  ..., -2.5654e-03,\n",
      "          3.5522e-02,  1.6693e-02],\n",
      "        [-8.6487e-02,  7.1373e-03,  9.5139e-03,  ..., -6.9092e-02,\n",
      "          5.0568e-02,  2.0370e-02],\n",
      "        [ 2.4915e-05,  3.1710e-05, -3.3140e-05,  ...,  1.8120e-05,\n",
      "          2.3842e-05, -5.0664e-06]], dtype=torch.float16)\n",
      "\n",
      "original deberta.embeddings.position_embeddings.weight tensor([[-0.0085,  0.0013,  0.0039,  ...,  0.0104,  0.0092, -0.0002],\n",
      "        [-0.0671,  0.0984,  0.0517,  ..., -0.0766, -0.0206,  0.1014],\n",
      "        [-0.0054,  0.0539,  0.0078,  ..., -0.0726, -0.0310,  0.0616],\n",
      "        ...,\n",
      "        [-0.0031,  0.0097,  0.0298,  ..., -0.0207, -0.0550, -0.0591],\n",
      "        [-0.0165, -0.0045,  0.0418,  ..., -0.0266, -0.0946, -0.0660],\n",
      "        [ 0.0008,  0.0019,  0.0017,  ...,  0.0026,  0.0041,  0.0005]],\n",
      "       dtype=torch.float16)\n",
      "discriminator deberta.embeddings.position_embeddings.weight tensor([[-6.6719e-03,  5.3406e-04,  1.9970e-03,  ...,  2.0885e-03,\n",
      "          4.0855e-03, -9.1648e-04],\n",
      "        [ 8.3557e-02, -4.2084e-02, -1.3477e-01,  ..., -3.1445e-01,\n",
      "          6.0760e-02,  7.0862e-02],\n",
      "        [ 1.0193e-01,  9.8267e-03, -7.0229e-03,  ..., -2.0905e-03,\n",
      "          8.3313e-02,  8.5815e-02],\n",
      "        ...,\n",
      "        [ 1.1436e-02, -4.2877e-02,  7.5073e-02,  ...,  6.8436e-03,\n",
      "          3.0151e-02,  1.7151e-02],\n",
      "        [-1.2500e-01, -5.7312e-02,  7.8964e-03,  ..., -7.9834e-02,\n",
      "          2.7512e-02, -1.7929e-02],\n",
      "        [-4.6396e-04, -1.5485e-04, -3.9005e-04,  ...,  5.3139e-03,\n",
      "         -2.6474e-03,  5.7373e-03]], dtype=torch.float16)\n",
      "\n",
      "original deberta.embeddings.LayerNorm.weight tensor([0.4121, 0.4622, 0.4111, 0.4387, 0.3960, 0.3992, 0.4509, 0.4629, 0.4175,\n",
      "        0.4653, 0.4343, 0.4177, 0.4204, 0.4194, 0.4487, 0.4116, 0.4216, 0.4719,\n",
      "        0.4360, 0.4282, 0.4402, 0.4395, 0.4341, 0.4189, 0.4402, 0.4214, 0.4150,\n",
      "        0.4377, 0.4412, 0.4353, 0.4175, 0.4385, 0.4260, 0.4160, 0.4453, 0.4316,\n",
      "        0.4304, 0.4111, 0.4402, 0.2111, 0.4531, 0.4302, 0.4321, 0.4353, 0.4292,\n",
      "        0.4128, 0.4612, 0.4207, 0.4421, 0.4207, 0.4568, 0.4231, 0.4346, 0.4241,\n",
      "        0.4153, 0.1598, 0.4482, 0.4148, 0.4255, 0.4338, 0.4268, 0.4668, 0.4321,\n",
      "        0.4221, 0.4419, 0.4309, 0.5054, 0.4446, 0.4426, 0.4358, 0.4690, 0.4287,\n",
      "        0.4231, 0.4346, 0.4153, 0.4341, 0.4255, 0.4802, 0.4216, 0.4219, 0.4456,\n",
      "        0.4397, 0.4155, 0.4241, 0.4294, 0.4490, 0.3613, 0.4353, 0.4187, 0.4385,\n",
      "        0.4307, 0.4243, 0.4551, 0.4199, 0.4622, 0.4456, 0.4290, 0.3987, 0.4453,\n",
      "        0.4155, 0.4670, 0.4229, 0.4751, 0.4849, 0.4292, 0.4734, 0.4585, 0.4526,\n",
      "        0.4263, 0.4561, 0.3860, 0.4297, 0.4661, 0.4565, 0.4219, 0.4270, 0.4395,\n",
      "        0.4268, 0.4175, 0.4309, 0.4207, 0.4299, 0.3899, 0.3989, 0.2864, 0.4089,\n",
      "        0.3835, 0.4189, 0.4392, 0.3916, 0.4431, 0.4290, 0.4285, 0.4763, 0.4114,\n",
      "        0.4153, 0.4309, 0.4631, 0.4197, 0.4263, 0.4307, 0.4294, 0.4153, 0.4395,\n",
      "        0.3936, 0.4333, 0.4612, 0.4551, 0.4326, 0.4446, 0.4277, 0.3303, 0.4006,\n",
      "        0.4395, 0.4434, 0.4126, 0.4421, 0.4348, 0.4292, 0.4280, 0.4248, 0.4456,\n",
      "        0.4285, 0.3809, 0.4385, 0.4492, 0.4265, 0.4338, 0.4490, 0.4453, 0.4194,\n",
      "        0.4272, 0.4419, 0.3542, 0.4248, 0.4377, 0.4287, 0.4287, 0.4309, 0.4441,\n",
      "        0.4150, 0.4265, 0.4150, 0.4124, 0.4648, 0.4470, 0.4236, 0.4124, 0.4038,\n",
      "        0.4272, 0.4163, 0.4082, 0.4258, 0.4304, 0.4167, 0.4570, 0.4734, 0.4424,\n",
      "        0.4390, 0.4202, 0.4143, 0.3867, 0.4023, 0.4160, 0.4553, 0.4211, 0.4465,\n",
      "        0.4219, 0.4319, 0.4604, 0.4133, 0.4116, 0.4141, 0.4341, 0.4385, 0.4336,\n",
      "        0.4402, 0.4246, 0.4233, 0.4285, 0.4185, 0.4546, 0.4431, 0.3535, 0.4395,\n",
      "        0.3960, 0.1246, 0.4275, 0.4355, 0.3928, 0.4280, 0.4226, 0.4463, 0.4194,\n",
      "        0.4114, 0.4458, 0.4441, 0.4182, 0.4260, 0.4351, 0.4226, 0.4592, 0.4382,\n",
      "        0.4194, 0.4294, 0.4309, 0.4285, 0.4238, 0.4312, 0.4714, 0.4146, 0.4373,\n",
      "        0.4155, 0.4109, 0.4160, 0.4465, 0.4097, 0.4006, 0.4441, 0.4209, 0.4287,\n",
      "        0.4231, 0.4451, 0.3777, 0.4231, 0.4705, 0.4265, 0.2490, 0.3984, 0.4871,\n",
      "        0.4065, 0.4478, 0.4390, 0.4241, 0.4104, 0.3857, 0.4465, 0.4333, 0.4580,\n",
      "        0.4387, 0.4263, 0.4341, 0.4231, 0.4490, 0.4404, 0.5034, 0.4390, 0.4150,\n",
      "        0.4690, 0.4397, 0.4636, 0.4070, 0.4553, 0.4468, 0.4351, 0.4124, 0.4146,\n",
      "        0.4468, 0.4365, 0.4165, 0.4233, 0.4114, 0.4246, 0.4438, 0.3767, 0.4265,\n",
      "        0.4058, 0.4187, 0.4529, 0.4258, 0.4290, 0.4485, 0.4092, 0.4114, 0.4290,\n",
      "        0.4231, 0.4468, 0.4473, 0.4109, 0.4263, 0.4570, 0.4329, 0.4167, 0.4541,\n",
      "        0.4351, 0.4299, 0.3845, 0.4583, 0.4573, 0.4517, 0.4375, 0.4070, 0.4260,\n",
      "        0.4368, 0.4436, 0.4221, 0.4265, 0.4258, 0.4307, 0.4026, 0.4182, 0.4922,\n",
      "        0.4241, 0.4272, 0.4185, 0.4697, 0.4338, 0.4053, 0.4355, 0.4580, 0.3806,\n",
      "        0.4500, 0.4299, 0.4644, 0.4490, 0.4255, 0.4153, 0.4702, 0.4246, 0.4626,\n",
      "        0.4553, 0.5220, 0.4226, 0.3784, 0.4321, 0.3992, 0.4192, 0.3999, 0.4241,\n",
      "        0.4211, 0.3887, 0.4067, 0.3843, 0.4504, 0.4678, 0.4265, 0.4658, 0.4197,\n",
      "        0.4204, 0.4512, 0.4053, 0.3889, 0.4336, 0.4087, 0.4790, 0.4634, 0.3997,\n",
      "        0.4326, 0.4326, 0.4878, 0.4116, 0.4290, 0.4199, 0.4080, 0.4224, 0.4460,\n",
      "        0.4419, 0.4360, 0.4612, 0.4114, 0.4192, 0.4556, 0.4304, 0.4246, 0.4404,\n",
      "        0.4355, 0.4414, 0.4626, 0.4531, 0.4155, 0.3474, 0.4468, 0.4146, 0.3813,\n",
      "        0.4775, 0.4165, 0.4558, 0.4590, 0.4336, 0.4980, 0.4185, 0.5205, 0.4639,\n",
      "        0.3733, 0.4243, 0.4089, 0.4265, 0.4141, 0.4136, 0.4199, 0.4014, 0.4241,\n",
      "        0.4446, 0.4434, 0.2693, 0.4187, 0.4282, 0.4399, 0.4397, 0.4614, 0.4348,\n",
      "        0.4250, 0.4158, 0.4155, 0.4321, 0.4233, 0.4565, 0.4553, 0.4268, 0.4553,\n",
      "        0.4377, 0.3835, 0.4348, 0.4165, 0.4041, 0.4580, 0.4102, 0.3826, 0.4180,\n",
      "        0.4626, 0.4521, 0.4385, 0.4287, 0.4233, 0.4167, 0.4490, 0.3955, 0.4363,\n",
      "        0.4463, 0.4314, 0.4102, 0.4648, 0.4297, 0.4182, 0.4441, 0.4290, 0.4395,\n",
      "        0.4192, 0.3838, 0.4246, 0.4202, 0.4363, 0.3972, 0.4102, 0.4678, 0.3989,\n",
      "        0.4258, 0.4331, 0.4487, 0.4048, 0.4197, 0.4338, 0.4058, 0.3960, 0.4104,\n",
      "        0.3931, 0.4404, 0.3938, 0.4255, 0.4561, 0.4436, 0.4197, 0.4375, 0.4321,\n",
      "        0.4399, 0.4150, 0.4351, 0.4016, 0.4336, 0.4358, 0.4231, 0.4238, 0.4390,\n",
      "        0.4424, 0.4661, 0.4265, 0.4331, 0.3875, 0.4348, 0.4397, 0.4456, 0.4065,\n",
      "        0.4385, 0.4458, 0.4285, 0.4373, 0.4224, 0.4387, 0.4202, 0.3860, 0.4343,\n",
      "        0.4351, 0.4509, 0.4263, 0.4001, 0.4370, 0.4121, 0.3806, 0.4478, 0.4326,\n",
      "        0.4060, 0.4365, 0.4468, 0.4497, 0.4170, 0.3755, 0.5459, 0.4890, 0.4204,\n",
      "        0.3672, 0.4214, 0.4290, 0.4299, 0.3901, 0.4287, 0.4360, 0.4258, 0.4492,\n",
      "        0.4167, 0.4417, 0.4004, 0.4602, 0.4404, 0.4272, 0.4390, 0.4106, 0.4304,\n",
      "        0.2986, 0.4575, 0.4438, 0.4392, 0.4126, 0.4309, 0.4641, 0.4377, 0.3948,\n",
      "        0.4590, 0.4355, 0.2732, 0.4709, 0.3977, 0.4363, 0.4373, 0.4143, 0.4438,\n",
      "        0.4033, 0.4507, 0.4373, 0.4019, 0.4341, 0.4211, 0.4016, 0.4929, 0.4282,\n",
      "        0.4199, 0.4885, 0.4167, 0.4102, 0.4346, 0.4246, 0.4421, 0.3792, 0.4631,\n",
      "        0.4180, 0.4260, 0.4448, 0.4717, 0.4370, 0.4971, 0.4153, 0.4155, 0.3938,\n",
      "        0.4407, 0.4421, 0.4358, 0.4226, 0.4282, 0.4417, 0.4617, 0.4629, 0.4409,\n",
      "        0.4326, 0.4229, 0.4270, 0.4143, 0.4290, 0.4004, 0.3752, 0.4465, 0.4475,\n",
      "        0.4280, 0.4231, 0.4231, 0.4209, 0.3811, 0.4546, 0.4434, 0.4363, 0.4177,\n",
      "        0.4390, 0.4009, 0.4326, 0.4307, 0.4419, 0.4424, 0.4446, 0.4570, 0.4299,\n",
      "        0.4160, 0.4272, 0.4229, 0.4199, 0.4260, 0.4084, 0.4189, 0.4341, 0.4263,\n",
      "        0.4407, 0.4326, 0.3887, 0.4133, 0.4583, 0.4626, 0.4514, 0.4607, 0.4448,\n",
      "        0.4360, 0.4009, 0.4353, 0.4353, 0.4331, 0.4468, 0.4465, 0.4319, 0.4529,\n",
      "        0.4302, 0.4524, 0.4106, 0.4231, 0.1786, 0.4497, 0.4067, 0.4370, 0.4302,\n",
      "        0.4736, 0.3931, 0.4485, 0.4224, 0.4238, 0.4678, 0.3911, 0.4158, 0.1647,\n",
      "        0.4351, 0.4412, 0.4194, 0.4270, 0.4109, 0.4480, 0.5200, 0.4312, 0.4504,\n",
      "        0.4380, 0.4492, 0.4109, 0.4189, 0.3865, 0.4094, 0.4265, 0.4321, 0.4580,\n",
      "        0.3906, 0.4243, 0.4980, 0.4370, 0.4436, 0.4373, 0.4268, 0.4148, 0.4341,\n",
      "        0.4170, 0.4368, 0.4480, 0.4404, 0.4060, 0.4666, 0.4880, 0.4875, 0.4194,\n",
      "        0.4500, 0.4312, 0.4014, 0.4292, 0.4465, 0.4478, 0.4639, 0.4255, 0.4607,\n",
      "        0.4343, 0.4534, 0.4504, 0.4592, 0.4250, 0.4146, 0.4282, 0.4297, 0.4412,\n",
      "        0.4385, 0.4202, 0.3816, 0.4143, 0.4189, 0.4253, 0.4485, 0.3691, 0.4163,\n",
      "        0.4199, 0.4429, 0.4243, 0.4619, 0.4487, 0.4531, 0.4172, 0.4011, 0.4265,\n",
      "        0.4348, 0.3992, 0.4407], dtype=torch.float16)\n",
      "discriminator deberta.embeddings.LayerNorm.weight tensor([1.1162, 1.0498, 1.0967,  ..., 1.0439, 1.1191, 1.1152],\n",
      "       dtype=torch.float16)\n",
      "\n",
      "original deberta.embeddings.LayerNorm.bias tensor([ 2.3376e-01,  4.1290e-02,  3.4332e-02,  1.2924e-02,  9.2102e-02,\n",
      "        -2.0187e-02,  6.2866e-02,  1.7053e-01,  1.1316e-01, -2.2156e-02,\n",
      "         4.0100e-02,  5.6213e-02,  1.3965e-01, -9.8633e-02, -3.9612e-02,\n",
      "        -1.5417e-01, -2.3285e-02,  2.5024e-02, -6.2134e-02,  5.6396e-02,\n",
      "         8.5693e-02, -1.4191e-02, -7.2289e-03, -1.9800e-01, -1.2549e-01,\n",
      "        -8.8379e-02,  1.0773e-01, -6.3477e-02, -5.0293e-02, -1.3086e-01,\n",
      "         4.5563e-02, -1.6382e-01, -3.6194e-02, -2.2009e-01,  1.0223e-01,\n",
      "         6.5491e-02,  5.6488e-02,  9.8633e-02,  1.0248e-01,  7.4402e-02,\n",
      "        -7.8125e-02,  1.1272e-03, -1.7859e-01,  4.8920e-02, -7.8308e-02,\n",
      "         1.5039e-01, -8.9478e-02, -1.8692e-02, -1.1737e-01, -2.6596e-02,\n",
      "         7.2510e-02, -7.1289e-02,  1.5369e-01, -1.2451e-01, -1.5735e-01,\n",
      "         1.6443e-01,  1.6309e-01, -1.0208e-02, -3.0060e-02,  9.8694e-02,\n",
      "        -3.4546e-02, -4.4037e-02, -1.4661e-01, -7.1594e-02, -2.2424e-01,\n",
      "        -1.1523e-01, -1.2337e-02,  1.5442e-01,  2.5848e-02, -4.9347e-02,\n",
      "         1.3779e-02,  3.4210e-02, -1.4086e-03,  1.2693e-03,  5.6854e-02,\n",
      "        -1.1009e-02, -8.9478e-02,  7.6904e-02,  4.2908e-02,  5.4565e-02,\n",
      "         4.3213e-02, -9.9850e-04, -3.3112e-02,  1.6556e-02, -6.5422e-03,\n",
      "        -7.2021e-02,  1.5472e-02, -8.9844e-02, -1.4587e-01, -8.7036e-02,\n",
      "        -8.9550e-04,  3.8483e-02, -7.8430e-02, -1.2427e-01,  2.0349e-01,\n",
      "         1.2634e-01, -3.3356e-02,  1.2683e-01, -2.4890e-01,  4.7882e-02,\n",
      "        -2.7417e-01,  4.8828e-02, -1.1151e-01,  6.1188e-02, -1.5114e-02,\n",
      "        -4.8889e-02,  5.4749e-02, -8.2581e-02, -7.2021e-02,  2.5732e-01,\n",
      "         1.3025e-01, -5.3558e-02,  6.7139e-02, -4.5837e-02, -1.0535e-01,\n",
      "         3.0563e-02, -7.5195e-02,  7.1526e-03,  1.8896e-01,  6.7322e-02,\n",
      "         1.1597e-01, -1.0901e-01,  5.1613e-03,  2.4792e-01,  2.4658e-01,\n",
      "         2.6047e-02,  2.7856e-01, -1.1841e-02, -3.1738e-02,  3.2043e-02,\n",
      "        -1.8872e-01, -4.8981e-02, -7.7087e-02, -3.8116e-02,  1.8103e-01,\n",
      "        -9.9304e-02,  5.3619e-02,  6.7139e-02, -5.2765e-02, -6.4758e-02,\n",
      "        -8.8013e-02,  1.0333e-01, -7.9590e-02,  1.2537e-01, -3.5431e-02,\n",
      "         6.0303e-02, -3.4637e-02, -1.0498e-01, -9.4482e-02,  7.2098e-03,\n",
      "         7.9679e-04, -1.8604e-01,  1.6541e-01, -1.9946e-01, -5.2795e-02,\n",
      "        -7.5134e-02,  1.7480e-01,  1.0577e-01, -1.8103e-01,  1.4641e-02,\n",
      "         1.1749e-01, -1.5015e-01,  1.3159e-01,  8.4106e-02, -1.0138e-01,\n",
      "        -3.9917e-02, -6.0455e-02,  3.9886e-02, -7.6233e-02,  5.6458e-02,\n",
      "         1.3647e-01,  1.6748e-01,  4.1534e-02,  2.9785e-01,  2.5708e-01,\n",
      "         6.1111e-03, -9.5642e-02, -2.5421e-02,  2.9999e-02,  3.2673e-03,\n",
      "        -2.2476e-02, -5.0842e-02, -8.7952e-02, -1.7065e-01,  8.9172e-02,\n",
      "        -1.2085e-01, -6.9031e-02,  7.8552e-02,  2.5269e-01, -1.0181e-01,\n",
      "        -2.2119e-01,  1.3817e-02,  3.7750e-02, -3.9734e-02, -8.7341e-02,\n",
      "         5.8174e-03, -7.3792e-02,  3.1769e-02, -1.4661e-01, -8.5999e-02,\n",
      "        -1.2878e-01,  1.0779e-01,  3.0640e-02,  1.8921e-02, -7.1259e-03,\n",
      "         3.4485e-02,  1.8768e-02,  1.8204e-02, -2.5375e-02,  1.8799e-01,\n",
      "        -1.1597e-01, -8.3618e-03, -2.4414e-02, -8.8928e-02, -3.7781e-02,\n",
      "         1.0632e-01,  6.5063e-02, -1.8909e-01, -6.1981e-02,  3.8849e-02,\n",
      "        -7.4097e-02,  1.0815e-01, -4.7058e-02,  8.9844e-02, -1.7468e-01,\n",
      "         1.5491e-01,  3.3813e-02,  2.3804e-03, -1.7456e-01, -1.0297e-01,\n",
      "         5.9174e-02, -8.4900e-02, -9.4055e-02, -1.4600e-01, -1.0333e-01,\n",
      "         4.4006e-02,  1.3623e-01,  3.7262e-02,  1.3403e-01, -1.4563e-01,\n",
      "        -1.9394e-02, -9.6375e-02, -1.7554e-01,  3.3569e-02,  7.3204e-03,\n",
      "         3.1052e-02,  1.5556e-02, -1.4992e-02,  4.5746e-02,  7.6721e-02,\n",
      "         6.3660e-02, -1.1359e-01, -7.2021e-02,  5.3406e-02,  1.2383e-02,\n",
      "         1.8091e-01,  1.8359e-01, -3.6774e-03, -7.6843e-02,  1.4856e-01,\n",
      "        -4.2999e-02,  1.2939e-01, -5.6763e-02,  1.3159e-01, -6.4636e-02,\n",
      "        -7.0839e-03, -2.1228e-01, -2.1423e-01,  1.0956e-01, -4.4281e-02,\n",
      "         8.9661e-02, -2.3865e-02, -1.7920e-01, -1.3416e-01,  5.3009e-02,\n",
      "         1.8298e-01, -1.6321e-01, -3.3966e-02,  4.9988e-02, -1.4905e-01,\n",
      "        -5.1605e-02, -9.9548e-02,  6.5979e-02,  7.8583e-03,  1.2558e-02,\n",
      "        -3.2654e-02, -1.2659e-01, -1.2158e-01,  7.0190e-02, -1.9455e-02,\n",
      "         2.5040e-02,  1.6858e-01,  1.8845e-02,  5.5115e-02,  5.9204e-02,\n",
      "         9.5276e-02,  2.3059e-01, -1.5295e-01,  1.6708e-02,  1.6022e-02,\n",
      "         6.2622e-02, -2.4246e-02,  4.6539e-02,  5.0659e-03,  9.3079e-02,\n",
      "        -4.0894e-02, -1.0016e-01,  1.2566e-02,  3.1738e-02, -7.6782e-02,\n",
      "         1.2878e-01, -7.2449e-02, -1.7224e-01,  1.4282e-01,  1.3184e-01,\n",
      "         4.8187e-02,  7.5745e-02, -2.1240e-02,  4.4342e-02,  3.3325e-02,\n",
      "         6.3232e-02,  4.6326e-02, -9.2102e-02, -5.0415e-02, -5.2986e-03,\n",
      "        -3.8788e-02, -1.2512e-01, -1.0162e-01, -8.5510e-02,  1.7639e-01,\n",
      "         7.9224e-02, -8.2321e-03, -7.1289e-02, -2.2449e-01, -9.1858e-02,\n",
      "         7.2815e-02, -2.1027e-02,  5.4413e-02, -3.5431e-02,  1.7114e-01,\n",
      "        -5.6915e-02,  2.0557e-01, -7.2876e-02,  1.0590e-01, -8.2703e-02,\n",
      "        -1.0278e-01, -6.4575e-02, -6.2622e-02,  1.4481e-02, -9.9976e-02,\n",
      "         3.4595e-01, -3.6102e-02, -9.0149e-02,  5.4199e-02, -7.0877e-03,\n",
      "        -6.6406e-02, -1.5540e-01,  3.0689e-03,  1.0529e-02, -7.0435e-02,\n",
      "         8.3923e-03,  1.0345e-01,  1.3879e-01,  2.1362e-01, -8.7769e-02,\n",
      "         8.3801e-02, -2.5073e-01,  1.8494e-01,  9.3384e-03,  1.6907e-01,\n",
      "         2.2742e-01,  4.8706e-02, -1.2744e-01,  4.8676e-02,  4.6539e-02,\n",
      "        -5.0873e-02,  2.7069e-02, -1.5393e-01,  9.9976e-02,  1.1432e-01,\n",
      "         1.2238e-01, -7.0839e-03,  1.9257e-02, -8.5693e-02, -1.7078e-01,\n",
      "        -2.9083e-02,  1.2286e-01,  1.4099e-01, -2.8442e-02,  5.8868e-02,\n",
      "         5.3497e-02,  1.1163e-01, -3.7781e-02, -8.8196e-02, -9.0149e-02,\n",
      "        -1.5088e-01, -1.1223e-02,  1.0944e-01,  1.1459e-02,  1.4319e-01,\n",
      "        -1.1589e-02, -4.9011e-02, -8.2520e-02, -6.3354e-02, -3.9734e-02,\n",
      "         1.9714e-02,  4.5105e-02,  7.4463e-02, -3.1982e-02, -7.3700e-03,\n",
      "         3.0835e-01, -2.7039e-02, -7.9224e-02,  3.2104e-01, -1.2927e-01,\n",
      "        -1.5015e-01, -1.7493e-01, -3.4515e-02,  1.6464e-02, -3.0762e-01,\n",
      "        -7.3853e-02,  8.8318e-02, -1.1066e-01,  1.9031e-01, -3.7842e-02,\n",
      "         1.1353e-01, -3.8330e-02, -6.1737e-02, -4.8828e-02,  1.4473e-02,\n",
      "         2.0157e-02, -7.2205e-02,  1.8164e-01,  1.3611e-01, -2.7908e-02,\n",
      "        -2.6245e-01, -1.6833e-01, -3.6652e-02,  1.9806e-02, -1.2146e-01,\n",
      "         8.0078e-02,  8.7341e-02, -3.5034e-02,  1.3354e-01, -1.0223e-01,\n",
      "         4.8004e-02, -4.3762e-02, -5.9967e-02,  3.8788e-02, -9.3689e-02,\n",
      "        -4.9713e-02, -3.6407e-02,  1.0101e-01,  1.0919e-01,  1.4880e-01,\n",
      "         7.2670e-04,  1.1432e-01, -9.3269e-04, -9.9915e-02,  2.5024e-02,\n",
      "        -1.2622e-01,  2.2034e-01, -1.0974e-01,  4.4746e-03, -2.2302e-01,\n",
      "        -2.1988e-02,  2.8711e-01, -1.4966e-01, -8.6731e-02,  2.4826e-02,\n",
      "        -1.1469e-01,  1.6858e-01, -3.0640e-02, -1.6382e-01, -3.6835e-02,\n",
      "        -2.3270e-03, -4.9957e-02, -4.0131e-02,  1.8506e-01, -2.4231e-01,\n",
      "         1.7349e-02, -7.2266e-02, -6.7329e-03,  2.6459e-02, -6.0425e-02,\n",
      "        -1.5491e-01, -2.5073e-01, -7.3486e-02, -9.1064e-02, -1.1371e-01,\n",
      "         5.6000e-02,  9.6069e-02,  1.5930e-01,  1.0002e-02, -5.3741e-02,\n",
      "         1.2268e-01,  1.0651e-01, -8.0444e-02, -8.2703e-02, -2.8885e-02,\n",
      "        -1.0687e-01, -7.4768e-02,  8.0383e-02, -8.1909e-02,  1.7236e-01,\n",
      "        -2.6474e-03, -2.5330e-02,  8.4534e-03, -1.0071e-01, -8.2642e-02,\n",
      "        -4.7943e-02,  3.3478e-02, -9.1919e-02, -9.4849e-02,  1.6418e-02,\n",
      "        -1.8835e-01, -1.7731e-02, -5.8594e-02, -1.9995e-01, -9.0332e-02,\n",
      "         8.2474e-03, -7.9102e-02,  5.2368e-02, -1.4075e-01, -1.9104e-01,\n",
      "        -1.2520e-02,  4.7241e-02,  2.7100e-02,  6.4636e-02,  2.4146e-01,\n",
      "         1.0516e-01,  1.0553e-01, -4.2496e-03, -1.6785e-01,  1.7371e-01,\n",
      "        -3.4149e-02, -4.6570e-02,  7.1533e-02, -3.8696e-02,  1.2073e-01,\n",
      "        -6.8604e-02, -7.1182e-03, -8.0444e-02, -1.0187e-01,  1.2444e-02,\n",
      "        -4.9255e-02, -1.4183e-02,  1.0388e-01,  5.5511e-02,  4.3066e-01,\n",
      "        -3.6499e-02, -2.4734e-02,  6.6589e-02,  5.5878e-02,  1.2030e-01,\n",
      "        -2.7251e-04, -2.6123e-02, -1.2244e-01, -6.0791e-02,  8.8745e-02,\n",
      "         1.1700e-01, -1.6571e-02, -5.8411e-02, -5.6519e-02,  8.4290e-02,\n",
      "        -1.1902e-01, -1.0419e-01,  1.5759e-01, -1.2500e-01, -1.9165e-02,\n",
      "        -9.7839e-02, -5.3436e-02, -1.4929e-01,  6.3965e-02, -1.5222e-01,\n",
      "         1.1139e-01,  8.7357e-03, -3.8361e-02,  2.4967e-03,  1.8384e-01,\n",
      "         4.1479e-01,  5.7953e-02, -9.4543e-02, -1.1848e-02, -1.8274e-01,\n",
      "         4.7241e-02, -1.2927e-01, -6.9275e-02,  7.9346e-01,  2.3743e-02,\n",
      "        -3.2539e-03,  2.8610e-02, -6.0577e-02,  3.0106e-02, -4.3365e-02,\n",
      "         7.8918e-02, -1.4343e-01, -1.1450e-01, -1.8005e-01,  2.6581e-02,\n",
      "        -1.6418e-01,  2.3450e-01, -1.2274e-01, -3.1677e-02, -1.3145e-02,\n",
      "        -3.2104e-02,  2.2070e-01, -9.5642e-02,  8.7509e-03,  8.0444e-02,\n",
      "         4.0070e-02,  1.5967e-01, -2.5879e-01,  1.0414e-02,  1.2039e-02,\n",
      "         1.8768e-02,  7.9041e-02, -7.2327e-02, -5.2032e-02, -4.3549e-02,\n",
      "         5.8105e-02, -6.8054e-02,  1.6504e-01, -6.1188e-02, -1.3330e-01,\n",
      "        -6.8604e-02,  2.1866e-02, -5.5817e-02, -9.1064e-02,  4.0222e-02,\n",
      "         2.4506e-02,  3.7537e-02,  4.4678e-02,  5.0293e-02,  6.3599e-02,\n",
      "        -1.0596e-01, -8.1055e-02,  1.5906e-01,  2.1011e-02, -2.0004e-02,\n",
      "        -2.3621e-01, -6.2134e-02,  7.9224e-02, -1.6016e-01,  6.4758e-02,\n",
      "         6.9702e-02,  2.6047e-02,  4.8828e-02,  7.2384e-04,  1.3107e-02,\n",
      "         1.1041e-01, -3.5736e-02, -1.6138e-01,  1.9873e-01,  6.9702e-02,\n",
      "        -7.5378e-02, -1.4136e-01, -6.0699e-02,  9.8816e-02,  1.3037e-01,\n",
      "         5.3864e-02, -5.8167e-02, -1.0486e-01, -1.4648e-01,  2.3730e-01,\n",
      "        -6.5125e-02, -4.2358e-02,  1.0156e-01,  5.7434e-02, -1.2366e-01,\n",
      "        -3.8452e-02, -6.2866e-02, -5.5939e-02, -6.7932e-02, -1.2347e-01,\n",
      "         1.2299e-02, -1.5465e-02, -1.7053e-01,  2.0905e-03,  1.9385e-01,\n",
      "        -2.0203e-01,  2.0386e-01,  1.4392e-01, -4.1473e-02, -5.6854e-02,\n",
      "         1.8559e-03, -7.8278e-03, -1.8213e-01, -2.9526e-02, -2.1191e-01,\n",
      "        -3.7262e-02,  4.0588e-02,  7.6965e-02,  1.2854e-01, -3.5553e-02,\n",
      "        -3.0384e-03,  1.8616e-01,  1.7365e-02,  1.6947e-03,  6.5674e-02,\n",
      "        -2.7771e-02,  1.2039e-02, -2.0432e-02,  3.6285e-02, -5.3589e-02,\n",
      "        -1.3245e-01, -8.4473e-02, -8.8989e-02,  5.6030e-02, -1.0522e-01,\n",
      "         2.6337e-02, -1.3989e-01, -7.9102e-02,  3.0411e-02, -1.3504e-02,\n",
      "        -1.9806e-02,  1.0815e-01, -4.7684e-03, -6.5735e-02,  6.2744e-02,\n",
      "         6.2637e-03, -2.3148e-02,  4.5532e-02,  3.5553e-02, -1.1316e-01,\n",
      "        -7.2815e-02,  5.8655e-02,  2.1313e-01, -7.4463e-02,  6.4880e-02,\n",
      "        -6.1432e-02,  2.3289e-03, -3.4485e-02, -1.1877e-01, -3.5980e-02,\n",
      "        -1.0109e-02,  7.3814e-03, -8.8013e-02,  1.2793e-01, -7.6538e-02,\n",
      "         5.6702e-02, -9.9426e-02,  1.4830e-03, -3.5828e-02, -9.0210e-02,\n",
      "         5.0293e-02,  2.9160e-02, -9.9426e-02,  2.7759e-01,  1.1108e-01,\n",
      "        -1.0095e-01, -1.0950e-01, -1.4075e-01, -4.8492e-02,  2.3181e-01,\n",
      "        -1.7847e-01, -2.4414e-01, -8.8501e-02, -7.9651e-02,  3.7750e-02,\n",
      "        -1.6541e-01,  1.5869e-01, -8.7646e-02, -9.8022e-02, -7.3486e-02,\n",
      "        -1.5121e-02,  6.9153e-02, -2.7893e-02], dtype=torch.float16)\n",
      "discriminator deberta.embeddings.LayerNorm.bias tensor([-0.0350,  0.0765, -0.1661,  ...,  0.1870,  0.0007, -0.0216],\n",
      "       dtype=torch.float16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in d_k:\n",
    "    if k in original:\n",
    "        print('original', k, original[k])\n",
    "    if k in discriminator:\n",
    "        print('discriminator', k, discriminator[k])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47564441",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deberta.embeddings.word_embeddings.weight': tensor([[-0.0504, -0.0459, -0.0496,  ..., -0.0528, -0.0523, -0.0369],\n",
       "         [-0.0017, -0.0081,  0.0130,  ..., -0.0137, -0.0064, -0.0035],\n",
       "         [-0.0034, -0.0082,  0.0118,  ..., -0.0140, -0.0061, -0.0045],\n",
       "         ...,\n",
       "         [-0.0500, -0.0595, -0.0373,  ..., -0.0593, -0.0505, -0.0359],\n",
       "         [-0.0448, -0.0498, -0.0464,  ..., -0.0550, -0.0567, -0.0458],\n",
       "         [-0.0400, -0.0428, -0.0420,  ..., -0.0588, -0.0488, -0.0336]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.embeddings.position_embeddings.weight': tensor([[ 5.1737e-05,  5.0843e-05, -6.3777e-06,  ...,  2.0266e-06,\n",
       "           7.5102e-06, -4.6372e-05],\n",
       "         [ 1.0138e-01,  1.2589e-02, -8.4656e-02,  ..., -1.9812e-01,\n",
       "           9.2041e-02,  6.9214e-02],\n",
       "         [ 9.3933e-02,  1.7166e-02, -1.1780e-02,  ...,  1.9485e-02,\n",
       "           8.0505e-02,  6.5735e-02],\n",
       "         ...,\n",
       "         [-2.7542e-03, -1.9638e-02,  6.8909e-02,  ..., -2.5711e-03,\n",
       "           3.5614e-02,  1.6724e-02],\n",
       "         [-8.6670e-02,  7.1526e-03,  9.5367e-03,  ..., -6.9214e-02,\n",
       "           5.0690e-02,  2.0416e-02],\n",
       "         [ 2.4974e-05,  3.1769e-05, -3.3200e-05,  ...,  1.8179e-05,\n",
       "           2.3901e-05, -5.0664e-06]], dtype=torch.float16),\n",
       " 'deberta.embeddings.LayerNorm.weight': tensor([1.1426, 1.0566, 1.0908,  ..., 1.0342, 1.1162, 1.1094],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.embeddings.LayerNorm.bias': tensor([-0.0406,  0.0761, -0.1703,  ...,  0.1855,  0.0016, -0.0242],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.self.query_proj.weight': tensor([[ 0.0512, -0.0285, -0.0567,  ...,  0.0057,  0.0511, -0.0137],\n",
       "         [ 0.0016,  0.0573,  0.0359,  ..., -0.0339, -0.0032,  0.0350],\n",
       "         [-0.0171, -0.0281, -0.0292,  ..., -0.0740, -0.0005,  0.0301],\n",
       "         ...,\n",
       "         [-0.0027,  0.0209,  0.0728,  ..., -0.0475, -0.0333, -0.0427],\n",
       "         [ 0.0326, -0.0166, -0.0454,  ...,  0.0294,  0.0465, -0.0065],\n",
       "         [-0.0298, -0.0316, -0.0235,  ...,  0.1019, -0.0828,  0.0056]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.self.query_proj.bias': tensor([ 0.1310,  0.1663,  0.3843,  ..., -0.0930, -0.0115,  0.0551],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.self.key_proj.weight': tensor([[ 0.0261,  0.0283,  0.0513,  ..., -0.0247, -0.0719, -0.0219],\n",
       "         [-0.0067, -0.0690, -0.0141,  ..., -0.0117, -0.0135,  0.0045],\n",
       "         [-0.1008, -0.1040,  0.0210,  ..., -0.0186,  0.0244, -0.0562],\n",
       "         ...,\n",
       "         [ 0.0526, -0.0144, -0.0215,  ...,  0.0486,  0.0175,  0.0387],\n",
       "         [ 0.0223, -0.0101,  0.0561,  ..., -0.0316, -0.0157, -0.0351],\n",
       "         [-0.0031,  0.0481,  0.0195,  ..., -0.0193, -0.0037, -0.0579]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.self.key_proj.bias': tensor([-0.2922,  0.1032, -0.0101,  ...,  0.0297, -0.0028, -0.0782],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.self.value_proj.weight': tensor([[ 0.0400, -0.0250, -0.0252,  ...,  0.0329,  0.0134,  0.0088],\n",
       "         [ 0.0389, -0.0108,  0.0205,  ..., -0.0072,  0.0065, -0.0083],\n",
       "         [-0.0671, -0.0236,  0.0316,  ..., -0.0178,  0.0322,  0.0401],\n",
       "         ...,\n",
       "         [-0.0291, -0.0383, -0.0848,  ..., -0.0144,  0.0197,  0.0440],\n",
       "         [ 0.0246,  0.0420, -0.0556,  ...,  0.0192, -0.0116,  0.0043],\n",
       "         [ 0.0298,  0.0065,  0.0406,  ..., -0.0129, -0.0104, -0.0183]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.self.value_proj.bias': tensor([-0.0208,  0.1506,  0.0829,  ..., -0.0058,  0.0319, -0.0265],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.output.dense.weight': tensor([[-0.0118, -0.0045, -0.0074,  ..., -0.0074,  0.0164,  0.0107],\n",
       "         [ 0.0426,  0.0520,  0.0552,  ...,  0.0043,  0.0293,  0.0322],\n",
       "         [ 0.0057,  0.0476, -0.0476,  ..., -0.0527,  0.0057,  0.0091],\n",
       "         ...,\n",
       "         [ 0.0118,  0.0056, -0.0394,  ..., -0.0215,  0.0288, -0.0404],\n",
       "         [-0.0292,  0.0016, -0.0171,  ...,  0.0170,  0.0073, -0.0145],\n",
       "         [-0.0170, -0.0055, -0.0466,  ..., -0.0686, -0.0017, -0.0307]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.output.dense.bias': tensor([ 0.0067,  0.1461, -0.0360,  ..., -0.0102, -0.0378, -0.0423],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.output.LayerNorm.weight': tensor([0.8325, 0.8140, 0.8228,  ..., 0.7905, 0.8267, 0.8003],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.attention.output.LayerNorm.bias': tensor([0.0482, 0.1876, 0.0206,  ..., 0.0849, 0.2004, 0.1218],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.intermediate.dense.weight': tensor([[ 0.0429, -0.0091,  0.0267,  ...,  0.0313, -0.0042, -0.0478],\n",
       "         [-0.0352, -0.0812, -0.0013,  ...,  0.0127, -0.0753,  0.0398],\n",
       "         [ 0.0308, -0.0018, -0.0253,  ...,  0.0366, -0.0381,  0.0096],\n",
       "         ...,\n",
       "         [ 0.0050, -0.0016, -0.0286,  ...,  0.0005,  0.0392, -0.0061],\n",
       "         [-0.0392, -0.0180, -0.0761,  ..., -0.0811,  0.0302, -0.0106],\n",
       "         [ 0.0005, -0.0432, -0.0205,  ..., -0.0115,  0.0014, -0.1187]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.intermediate.dense.bias': tensor([-0.0433, -0.0575, -0.0904,  ..., -0.0635, -0.0721, -0.0588],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.output.dense.weight': tensor([[ 0.0098,  0.0354,  0.0243,  ...,  0.0125, -0.0481, -0.0384],\n",
       "         [-0.0367, -0.0173,  0.0399,  ...,  0.0467, -0.0508,  0.0447],\n",
       "         [ 0.0327, -0.0063, -0.0355,  ...,  0.0063, -0.0587, -0.0290],\n",
       "         ...,\n",
       "         [-0.0166,  0.0060,  0.0259,  ...,  0.0872, -0.0084,  0.0404],\n",
       "         [ 0.0138, -0.0407,  0.0097,  ...,  0.0784,  0.0584,  0.0374],\n",
       "         [-0.0602,  0.0132, -0.0008,  ...,  0.0115,  0.0173, -0.0096]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.output.dense.bias': tensor([-0.0083,  0.0401, -0.0092,  ..., -0.1121, -0.0482, -0.0464],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.output.LayerNorm.weight': tensor([1.1250, 1.1006, 1.1602,  ..., 1.1816, 1.1133, 1.1035],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.0.output.LayerNorm.bias': tensor([-0.0426, -0.0696, -0.0179,  ..., -0.0151, -0.0724, -0.0513],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.self.query_proj.weight': tensor([[-4.6661e-02,  6.7932e-02, -1.6998e-02,  ..., -7.4524e-02,\n",
       "          -4.1321e-02,  2.3651e-03],\n",
       "         [ 1.1856e-02,  3.3325e-02,  2.0493e-02,  ..., -5.3650e-02,\n",
       "           2.3727e-02, -3.8788e-02],\n",
       "         [ 2.2903e-02, -4.7913e-02,  4.7272e-02,  ..., -1.3641e-02,\n",
       "           2.0615e-02,  3.1677e-02],\n",
       "         ...,\n",
       "         [-4.3549e-02, -1.4359e-02, -5.2765e-02,  ..., -3.9093e-02,\n",
       "          -6.5918e-02, -7.2556e-03],\n",
       "         [-6.3965e-02,  1.2779e-03, -2.3468e-02,  ..., -6.0959e-03,\n",
       "          -1.1070e-02, -8.3618e-03],\n",
       "         [ 7.3792e-02,  7.1228e-05, -6.2561e-02,  ...,  4.1840e-02,\n",
       "           5.0306e-05, -6.0211e-02]], dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.self.query_proj.bias': tensor([ 0.1501, -0.0945,  0.0674,  ...,  0.0346, -0.0095,  0.0226],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.self.key_proj.weight': tensor([[ 0.0452, -0.0039, -0.0289,  ...,  0.0165,  0.0199,  0.0155],\n",
       "         [ 0.0961,  0.0270,  0.0220,  ...,  0.0102,  0.0436,  0.0237],\n",
       "         [-0.0081, -0.0543,  0.0242,  ..., -0.0109, -0.0436, -0.0503],\n",
       "         ...,\n",
       "         [-0.0083, -0.0262,  0.0463,  ..., -0.0172, -0.0103,  0.0285],\n",
       "         [-0.0372,  0.0445, -0.0499,  ..., -0.0086,  0.0331,  0.0406],\n",
       "         [-0.0750, -0.0136,  0.0060,  ..., -0.0230,  0.0108, -0.0323]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.self.key_proj.bias': tensor([ 0.0738, -0.1477, -0.1355,  ...,  0.0423, -0.0338, -0.0158],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.self.value_proj.weight': tensor([[ 0.0460, -0.0679,  0.0145,  ..., -0.0494, -0.0012, -0.0193],\n",
       "         [ 0.0135, -0.0632, -0.0105,  ...,  0.0268,  0.0629, -0.0122],\n",
       "         [-0.0222, -0.0161,  0.0334,  ...,  0.0130,  0.0154, -0.0388],\n",
       "         ...,\n",
       "         [ 0.0225, -0.0103,  0.0117,  ..., -0.0310,  0.0112,  0.0233],\n",
       "         [-0.0025,  0.0628, -0.0425,  ..., -0.0003, -0.0068,  0.0281],\n",
       "         [ 0.0137, -0.0276,  0.0113,  ...,  0.0408,  0.0063, -0.0306]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.self.value_proj.bias': tensor([ 0.0126,  0.0457,  0.0096,  ..., -0.0334, -0.0180,  0.0035],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.output.dense.weight': tensor([[-7.3280e-03,  6.8307e-05,  1.0353e-02,  ..., -1.9928e-02,\n",
       "          -1.1292e-02,  3.2074e-02],\n",
       "         [ 1.2184e-02,  1.7319e-02, -2.0996e-02,  ...,  2.4155e-02,\n",
       "           1.3306e-02, -9.8724e-03],\n",
       "         [ 2.9739e-02,  2.4567e-02,  1.7532e-02,  ...,  5.4474e-02,\n",
       "          -2.3346e-02, -2.6733e-02],\n",
       "         ...,\n",
       "         [ 1.5411e-02,  4.8828e-02,  3.5339e-02,  ..., -8.8959e-03,\n",
       "          -2.6138e-02,  4.3182e-03],\n",
       "         [ 1.3161e-03, -2.4124e-02, -3.6621e-02,  ...,  3.1799e-02,\n",
       "           1.6357e-02,  4.3213e-02],\n",
       "         [ 4.0627e-03, -3.8513e-02,  5.8556e-03,  ...,  4.5532e-02,\n",
       "          -3.8666e-02,  2.7908e-02]], dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.output.dense.bias': tensor([-0.0560,  0.0342,  0.0133,  ..., -0.0469, -0.0141,  0.0140],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.output.LayerNorm.weight': tensor([0.9058, 0.8838, 0.9204,  ..., 0.9395, 0.9243, 0.9180],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.attention.output.LayerNorm.bias': tensor([-0.0100, -0.0901,  0.0447,  ...,  0.3054,  0.0029,  0.0078],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.intermediate.dense.weight': tensor([[-0.0964,  0.0359, -0.0014,  ..., -0.0177, -0.0729, -0.0247],\n",
       "         [ 0.0320,  0.0176, -0.0317,  ..., -0.0015, -0.0079, -0.0184],\n",
       "         [-0.0481, -0.0230,  0.0098,  ...,  0.0597, -0.0352, -0.0903],\n",
       "         ...,\n",
       "         [ 0.0853,  0.0944, -0.0889,  ..., -0.0282, -0.0673,  0.0124],\n",
       "         [-0.0692, -0.0586,  0.0673,  ..., -0.0535,  0.0340,  0.0585],\n",
       "         [-0.0245, -0.0131, -0.0461,  ..., -0.0070, -0.0376, -0.0042]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.intermediate.dense.bias': tensor([-0.0367, -0.0501, -0.0483,  ..., -0.0525, -0.0377, -0.0608],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.output.dense.weight': tensor([[ 0.0217, -0.0306, -0.0148,  ...,  0.0509, -0.0292,  0.0242],\n",
       "         [-0.0083,  0.0249, -0.0070,  ...,  0.0022,  0.0084, -0.0255],\n",
       "         [-0.0275,  0.0178, -0.0004,  ..., -0.0501,  0.0264, -0.0715],\n",
       "         ...,\n",
       "         [-0.0578, -0.0446, -0.0138,  ..., -0.0725,  0.0199, -0.0177],\n",
       "         [ 0.0123, -0.0151, -0.0501,  ..., -0.0048,  0.0692,  0.0546],\n",
       "         [ 0.0011,  0.0074, -0.0033,  ..., -0.0042,  0.0355,  0.0304]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.output.dense.bias': tensor([-0.0401,  0.0140,  0.0164,  ...,  0.0007, -0.0140, -0.0013],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.output.LayerNorm.weight': tensor([1.2197, 1.1943, 1.2061,  ..., 1.1777, 1.1973, 1.2148],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.1.output.LayerNorm.bias': tensor([-0.0300,  0.0044,  0.0151,  ..., -0.0471, -0.0547, -0.0329],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.self.query_proj.weight': tensor([[-0.0551, -0.0240,  0.0375,  ...,  0.1058, -0.0189, -0.0312],\n",
       "         [ 0.0226,  0.0180,  0.0184,  ..., -0.0892,  0.0246,  0.0160],\n",
       "         [ 0.0506, -0.0054,  0.0411,  ...,  0.0018, -0.0589, -0.0053],\n",
       "         ...,\n",
       "         [ 0.0411,  0.0399,  0.0325,  ..., -0.0135,  0.0362, -0.0382],\n",
       "         [ 0.0078, -0.0260,  0.0420,  ...,  0.0152,  0.0372,  0.0472],\n",
       "         [ 0.0756, -0.0013, -0.0798,  ...,  0.0061, -0.0392, -0.0218]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.self.query_proj.bias': tensor([-0.0265, -0.0781, -0.0469,  ...,  0.0974, -0.0164,  0.0760],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.self.key_proj.weight': tensor([[ 0.0389, -0.0025, -0.0748,  ..., -0.0167,  0.0229,  0.0508],\n",
       "         [ 0.0447, -0.0258, -0.0007,  ..., -0.0534,  0.0155,  0.0019],\n",
       "         [-0.0583, -0.0360,  0.0403,  ...,  0.0009,  0.0078,  0.0323],\n",
       "         ...,\n",
       "         [ 0.0332,  0.0733,  0.0266,  ..., -0.0014,  0.0189, -0.0353],\n",
       "         [-0.0096, -0.0513,  0.0213,  ...,  0.0160,  0.0560,  0.0363],\n",
       "         [ 0.1020,  0.0097, -0.0900,  ...,  0.0260, -0.0462, -0.0148]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.self.key_proj.bias': tensor([0.0682, 0.1648, 0.2917,  ..., 0.1373, 0.2111, 0.3767],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.self.value_proj.weight': tensor([[-0.0079,  0.0114,  0.0045,  ..., -0.0178,  0.0193, -0.0359],\n",
       "         [ 0.0068,  0.0135,  0.0141,  ..., -0.0066,  0.0449,  0.0528],\n",
       "         [-0.0180, -0.0294,  0.0260,  ..., -0.0114, -0.0128,  0.0071],\n",
       "         ...,\n",
       "         [-0.0098, -0.0067, -0.0005,  ...,  0.0042, -0.0053, -0.0184],\n",
       "         [-0.0042, -0.0168,  0.0136,  ..., -0.0120, -0.0275, -0.0084],\n",
       "         [-0.0106,  0.0061, -0.0387,  ...,  0.0050, -0.0311, -0.0180]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.self.value_proj.bias': tensor([-0.0146, -0.0094,  0.0429,  ..., -0.0213,  0.0180, -0.0079],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.output.dense.weight': tensor([[-0.0096, -0.0034, -0.0346,  ..., -0.0049, -0.0026, -0.0077],\n",
       "         [ 0.0146, -0.0352, -0.0301,  ..., -0.0171, -0.0188,  0.0097],\n",
       "         [ 0.0367,  0.0118, -0.0206,  ..., -0.0184,  0.0101, -0.0231],\n",
       "         ...,\n",
       "         [-0.0163,  0.0171, -0.0237,  ...,  0.0125, -0.0110, -0.0255],\n",
       "         [-0.0508, -0.0036,  0.0142,  ..., -0.0154, -0.0052, -0.0341],\n",
       "         [-0.0243,  0.0193, -0.0276,  ..., -0.0177,  0.0026, -0.0326]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.output.dense.bias': tensor([-0.0947,  0.0356,  0.0183,  ..., -0.1365, -0.0152,  0.0051],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.output.LayerNorm.weight': tensor([0.8867, 0.8516, 0.9243,  ..., 0.9883, 0.8799, 0.8887],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.attention.output.LayerNorm.bias': tensor([-0.1196,  0.0240,  0.1161,  ...,  0.3403, -0.0235,  0.0060],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.intermediate.dense.weight': tensor([[ 0.0762,  0.1859,  0.0523,  ...,  0.0224, -0.1218, -0.0158],\n",
       "         [ 0.0713, -0.0954,  0.0020,  ...,  0.0255, -0.0359,  0.0203],\n",
       "         [ 0.0127, -0.0065, -0.0434,  ...,  0.0016, -0.0347, -0.0092],\n",
       "         ...,\n",
       "         [-0.0662,  0.0597,  0.0324,  ..., -0.0231,  0.0500,  0.0227],\n",
       "         [ 0.0954,  0.0385, -0.0085,  ..., -0.0023, -0.0251, -0.0068],\n",
       "         [ 0.0189,  0.0064, -0.0053,  ...,  0.0165,  0.0677,  0.0339]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.intermediate.dense.bias': tensor([-0.0294, -0.0305,  0.0623,  ..., -0.0635, -0.0517, -0.0339],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.output.dense.weight': tensor([[ 0.0077, -0.0603, -0.0563,  ...,  0.0768,  0.0762, -0.0299],\n",
       "         [-0.0312,  0.0955,  0.0085,  ...,  0.0152, -0.0153, -0.0287],\n",
       "         [-0.0014, -0.0617,  0.0207,  ...,  0.0501,  0.0127, -0.0170],\n",
       "         ...,\n",
       "         [-0.0110,  0.0157,  0.0102,  ..., -0.0618,  0.0518, -0.0032],\n",
       "         [ 0.0306,  0.0018,  0.0275,  ..., -0.0139,  0.0156, -0.0039],\n",
       "         [ 0.0111,  0.0500, -0.0073,  ...,  0.0254,  0.0446,  0.0315]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.output.dense.bias': tensor([-0.0578,  0.0486, -0.0145,  ..., -0.0576, -0.0289,  0.0014],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.output.LayerNorm.weight': tensor([1.0957, 1.0488, 1.0811,  ..., 1.0352, 1.0850, 1.0684],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.2.output.LayerNorm.bias': tensor([-0.0134, -0.0066, -0.0699,  ..., -0.1300, -0.0597, -0.0699],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.self.query_proj.weight': tensor([[-0.0232, -0.0742,  0.0578,  ...,  0.0111,  0.0297,  0.0425],\n",
       "         [ 0.0309, -0.0282,  0.0284,  ...,  0.0046,  0.0245, -0.0085],\n",
       "         [-0.0175, -0.0274,  0.0406,  ...,  0.0037, -0.0227,  0.0322],\n",
       "         ...,\n",
       "         [ 0.0309, -0.0174, -0.0032,  ...,  0.0364, -0.0069, -0.0485],\n",
       "         [ 0.0379, -0.0241, -0.0294,  ..., -0.0125, -0.0609,  0.0037],\n",
       "         [-0.0003,  0.0248, -0.0040,  ..., -0.0222, -0.0067,  0.0126]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.self.query_proj.bias': tensor([-0.0455,  0.0189, -0.0525,  ...,  0.0473, -0.0590, -0.0384],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.self.key_proj.weight': tensor([[ 0.0264,  0.0152, -0.0014,  ...,  0.0496,  0.0081,  0.0374],\n",
       "         [-0.0002,  0.0350,  0.0341,  ...,  0.0079, -0.0213,  0.0273],\n",
       "         [-0.0515, -0.0131,  0.0210,  ...,  0.0165, -0.0021,  0.0349],\n",
       "         ...,\n",
       "         [-0.0012,  0.0237,  0.0460,  ..., -0.0013, -0.0106,  0.0133],\n",
       "         [-0.0243, -0.0446,  0.0320,  ...,  0.0480,  0.0164, -0.0157],\n",
       "         [ 0.0256, -0.0265, -0.0018,  ..., -0.0440,  0.0060, -0.0289]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.self.key_proj.bias': tensor([ 0.2234,  0.0715,  0.0469,  ..., -0.0032,  0.0164,  0.0165],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.self.value_proj.weight': tensor([[ 0.0792,  0.0056, -0.0259,  ...,  0.0103, -0.0016,  0.0456],\n",
       "         [ 0.0302, -0.0120, -0.0710,  ..., -0.0133,  0.0032, -0.0378],\n",
       "         [ 0.0045, -0.0198,  0.0367,  ..., -0.0073,  0.0305, -0.0271],\n",
       "         ...,\n",
       "         [ 0.0106, -0.0131, -0.0110,  ..., -0.0288,  0.0118,  0.0127],\n",
       "         [-0.0130,  0.0278, -0.0184,  ..., -0.0385, -0.0202,  0.0141],\n",
       "         [ 0.0113,  0.0231, -0.0067,  ...,  0.0378, -0.0191, -0.0283]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.self.value_proj.bias': tensor([ 0.0197, -0.0726, -0.0085,  ..., -0.0003,  0.0260,  0.0049],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.output.dense.weight': tensor([[ 5.5908e-02,  1.6617e-02, -2.0248e-02,  ..., -6.0242e-02,\n",
       "          -5.8746e-03, -1.4244e-02],\n",
       "         [ 1.9852e-02,  4.2603e-02,  6.3538e-02,  ..., -1.7563e-02,\n",
       "          -2.7771e-02, -2.6855e-02],\n",
       "         [ 2.3758e-02, -3.4760e-02, -6.9656e-03,  ..., -2.4529e-03,\n",
       "          -1.8942e-04, -4.0039e-02],\n",
       "         ...,\n",
       "         [-2.6810e-02, -2.2964e-02,  2.6459e-02,  ...,  2.0691e-02,\n",
       "          -9.7809e-03,  3.9816e-05],\n",
       "         [-2.9114e-02,  1.3725e-02, -1.9440e-02,  ..., -1.1215e-02,\n",
       "           8.4229e-03,  1.8219e-02],\n",
       "         [ 2.0203e-02,  4.0703e-03, -6.8855e-03,  ...,  5.5542e-03,\n",
       "          -2.5787e-02,  2.9770e-02]], dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.output.dense.bias': tensor([-0.0214, -0.0306, -0.0663,  ..., -0.1140, -0.0285,  0.0392],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.output.LayerNorm.weight': tensor([0.8750, 0.8345, 0.8906,  ..., 0.9751, 0.8730, 0.8672],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.attention.output.LayerNorm.bias': tensor([-0.0864,  0.1396,  0.0859,  ...,  0.2944, -0.0565, -0.1578],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.intermediate.dense.weight': tensor([[ 0.0014, -0.0351, -0.0211,  ..., -0.0460, -0.0658,  0.0272],\n",
       "         [ 0.0170,  0.0202,  0.0088,  ...,  0.0215,  0.0882, -0.0256],\n",
       "         [-0.0095, -0.0339, -0.0672,  ..., -0.0356,  0.0521,  0.0302],\n",
       "         ...,\n",
       "         [ 0.0420,  0.0400, -0.0377,  ...,  0.0398, -0.0247,  0.0552],\n",
       "         [-0.0052, -0.0581, -0.0733,  ...,  0.0281, -0.0418,  0.0139],\n",
       "         [ 0.0788, -0.0759,  0.0297,  ..., -0.0094, -0.0503,  0.0281]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.intermediate.dense.bias': tensor([-0.0524, -0.0430, -0.0016,  ..., -0.0222, -0.0478, -0.0447],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.output.dense.weight': tensor([[-0.0056,  0.0223,  0.0381,  ..., -0.0144,  0.0261,  0.0161],\n",
       "         [-0.0390,  0.0319, -0.0138,  ..., -0.0007, -0.0212, -0.0289],\n",
       "         [-0.0311, -0.0100,  0.0255,  ..., -0.0724,  0.0196, -0.0122],\n",
       "         ...,\n",
       "         [ 0.0212,  0.0068, -0.0158,  ...,  0.0727, -0.0332, -0.0650],\n",
       "         [ 0.0353,  0.0137,  0.0355,  ...,  0.0845, -0.0255,  0.0005],\n",
       "         [ 0.0631, -0.0356, -0.0186,  ...,  0.0352, -0.0294,  0.0089]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.output.dense.bias': tensor([-0.0302,  0.0219, -0.0419,  ..., -0.0301,  0.0113, -0.0150],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.output.LayerNorm.weight': tensor([1.1172, 1.0791, 1.0996,  ..., 0.9937, 1.1152, 1.1201],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.3.output.LayerNorm.bias': tensor([ 0.0281, -0.0468, -0.0950,  ..., -0.1621, -0.0228,  0.0117],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.self.query_proj.weight': tensor([[ 0.0093,  0.0530,  0.0266,  ..., -0.0814,  0.0221, -0.0225],\n",
       "         [-0.0170,  0.0080,  0.0294,  ..., -0.0104,  0.0277, -0.0164],\n",
       "         [ 0.0148, -0.0244,  0.0406,  ...,  0.0595,  0.0973,  0.0551],\n",
       "         ...,\n",
       "         [ 0.0053, -0.0361, -0.0270,  ...,  0.0487,  0.0019, -0.0182],\n",
       "         [-0.0267,  0.0246, -0.0598,  ...,  0.0445, -0.0162, -0.0274],\n",
       "         [-0.0537, -0.0372, -0.0076,  ...,  0.0318,  0.0323,  0.1312]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.self.query_proj.bias': tensor([-0.1451, -0.0699, -0.0115,  ..., -0.0170,  0.0577,  0.0055],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.self.key_proj.weight': tensor([[ 0.0052, -0.0089,  0.0481,  ..., -0.0607,  0.0293, -0.0144],\n",
       "         [-0.0436,  0.0216,  0.0200,  ..., -0.0109,  0.0331,  0.0091],\n",
       "         [ 0.0032,  0.0068,  0.0355,  ...,  0.0460,  0.0762,  0.0791],\n",
       "         ...,\n",
       "         [ 0.0698, -0.0621, -0.0455,  ..., -0.0461,  0.0078, -0.0782],\n",
       "         [ 0.1002,  0.0789,  0.0190,  ...,  0.0267,  0.0837,  0.0133],\n",
       "         [ 0.0392,  0.0833,  0.0010,  ...,  0.0658, -0.0045,  0.0977]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.self.key_proj.bias': tensor([-0.3477,  0.0822,  0.2974,  ...,  0.0976,  0.0809, -0.1855],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.self.value_proj.weight': tensor([[-6.1798e-02, -6.0196e-03,  1.7487e-02,  ..., -6.7787e-03,\n",
       "          -5.4717e-05, -1.2413e-02],\n",
       "         [ 3.0182e-02, -9.7733e-03,  3.0762e-02,  ...,  3.2349e-02,\n",
       "           4.0527e-02, -1.4816e-02],\n",
       "         [-1.3771e-02,  1.8799e-02, -2.4658e-02,  ...,  2.0523e-02,\n",
       "           2.1057e-02, -1.8051e-02],\n",
       "         ...,\n",
       "         [-3.0731e-02, -5.3497e-02, -4.2999e-02,  ..., -3.0155e-03,\n",
       "          -4.1229e-02, -3.5889e-02],\n",
       "         [-2.6073e-03,  1.7136e-02, -1.4297e-02,  ...,  1.3542e-02,\n",
       "          -3.0212e-03, -2.1149e-02],\n",
       "         [-3.0098e-03, -1.6571e-02,  8.7204e-03,  ...,  3.0258e-02,\n",
       "           2.8900e-02,  5.8258e-02]], dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.self.value_proj.bias': tensor([ 0.0122, -0.0008, -0.0085,  ...,  0.0218, -0.0355,  0.0030],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.output.dense.weight': tensor([[-0.0410,  0.0293, -0.0105,  ..., -0.0222,  0.0047,  0.0349],\n",
       "         [-0.0066,  0.0239,  0.0417,  ...,  0.0343,  0.0033,  0.0182],\n",
       "         [ 0.0121,  0.0370, -0.0161,  ...,  0.0074,  0.0179,  0.0197],\n",
       "         ...,\n",
       "         [-0.0094, -0.0280, -0.0111,  ..., -0.0368,  0.0260,  0.0106],\n",
       "         [ 0.0072,  0.0004, -0.0252,  ..., -0.0241, -0.0246, -0.0023],\n",
       "         [ 0.0023, -0.0372, -0.0387,  ..., -0.0097, -0.0250,  0.0273]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.output.dense.bias': tensor([-0.0267,  0.0365,  0.0167,  ..., -0.0302,  0.0215, -0.0289],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.output.LayerNorm.weight': tensor([0.8340, 0.8066, 0.8608,  ..., 0.9219, 0.8052, 0.8374],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.attention.output.LayerNorm.bias': tensor([ 0.0116,  0.0652,  0.0168,  ...,  0.0881, -0.0394, -0.0676],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.intermediate.dense.weight': tensor([[-0.0163,  0.0624,  0.0129,  ..., -0.0138,  0.0580, -0.0324],\n",
       "         [-0.0449,  0.0074, -0.0489,  ..., -0.0037,  0.0199,  0.0302],\n",
       "         [ 0.0279,  0.0039, -0.0623,  ..., -0.0525,  0.0171,  0.0114],\n",
       "         ...,\n",
       "         [ 0.0168, -0.0653, -0.0032,  ..., -0.0517,  0.0600, -0.0684],\n",
       "         [-0.0201, -0.0413,  0.0109,  ...,  0.0232,  0.0353,  0.0370],\n",
       "         [ 0.0121, -0.0217,  0.0100,  ..., -0.0609, -0.0238,  0.0454]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.intermediate.dense.bias': tensor([-0.0419, -0.0427, -0.0488,  ..., -0.0388,  0.0048, -0.0025],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.output.dense.weight': tensor([[ 0.0284, -0.0258,  0.0099,  ..., -0.0676, -0.0270,  0.0593],\n",
       "         [ 0.0397,  0.0520, -0.0096,  ...,  0.0278,  0.0219,  0.0032],\n",
       "         [ 0.0138, -0.1023, -0.0700,  ..., -0.0159, -0.0292,  0.0492],\n",
       "         ...,\n",
       "         [-0.0552,  0.0054, -0.0154,  ..., -0.0833,  0.0095, -0.0249],\n",
       "         [-0.0002,  0.0303, -0.0800,  ...,  0.0506, -0.0423, -0.0330],\n",
       "         [ 0.0196,  0.0192, -0.0058,  ...,  0.0007,  0.0180,  0.0615]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.output.dense.bias': tensor([ 0.0250, -0.0252, -0.0299,  ...,  0.0209,  0.0011, -0.0301],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.output.LayerNorm.weight': tensor([1.0752, 1.0303, 1.0645,  ..., 0.9902, 1.0391, 1.0439],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.4.output.LayerNorm.bias': tensor([ 0.0173, -0.0293, -0.0383,  ..., -0.0965, -0.0012,  0.0168],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.self.query_proj.weight': tensor([[-0.0228, -0.0044,  0.0072,  ...,  0.0225,  0.0065, -0.0200],\n",
       "         [-0.0269,  0.0120, -0.0008,  ..., -0.0163, -0.0267, -0.0073],\n",
       "         [-0.0061,  0.0218, -0.0167,  ...,  0.1265,  0.0491, -0.0184],\n",
       "         ...,\n",
       "         [ 0.0134, -0.0329, -0.0654,  ..., -0.0257,  0.0347,  0.0654],\n",
       "         [ 0.0032,  0.1013,  0.0100,  ...,  0.0909,  0.0321, -0.0041],\n",
       "         [-0.0549,  0.0023,  0.0671,  ...,  0.0324,  0.0289,  0.0844]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.self.query_proj.bias': tensor([-0.0637,  0.0435, -0.0389,  ...,  0.0035, -0.0144, -0.0432],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.self.key_proj.weight': tensor([[-0.0768,  0.0169,  0.0449,  ...,  0.0038, -0.0396, -0.0517],\n",
       "         [-0.0064,  0.0417,  0.0364,  ..., -0.0809,  0.0511, -0.0323],\n",
       "         [ 0.0126, -0.0087, -0.0587,  ..., -0.0071,  0.0505,  0.0065],\n",
       "         ...,\n",
       "         [ 0.0544, -0.0031, -0.0262,  ..., -0.0249, -0.0215,  0.0172],\n",
       "         [ 0.0662,  0.0098, -0.0072,  ...,  0.0373,  0.0695, -0.0660],\n",
       "         [-0.0170, -0.0117,  0.0254,  ..., -0.0050, -0.0103,  0.0386]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.self.key_proj.bias': tensor([-0.1656,  0.1508, -0.1167,  ...,  0.0279, -0.1017,  0.0827],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.self.value_proj.weight': tensor([[ 0.0878,  0.0336,  0.0455,  ..., -0.0064,  0.0445, -0.0167],\n",
       "         [-0.0205, -0.0166, -0.0408,  ..., -0.0459,  0.0091,  0.0169],\n",
       "         [-0.0163,  0.0132, -0.0134,  ..., -0.0012, -0.0208, -0.0322],\n",
       "         ...,\n",
       "         [ 0.0189,  0.0094, -0.0457,  ...,  0.0058, -0.0480,  0.0052],\n",
       "         [-0.0138, -0.0202, -0.0173,  ..., -0.0038,  0.0042, -0.0084],\n",
       "         [ 0.0091, -0.0193,  0.0193,  ..., -0.0243,  0.0202, -0.0354]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.self.value_proj.bias': tensor([ 0.0020, -0.0023, -0.0141,  ...,  0.0012,  0.0277,  0.0034],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.output.dense.weight': tensor([[ 0.0344,  0.0136, -0.0616,  ..., -0.0138, -0.0135,  0.0304],\n",
       "         [ 0.0087,  0.0406,  0.0310,  ...,  0.0264,  0.0632,  0.0277],\n",
       "         [ 0.0428,  0.0155,  0.0057,  ..., -0.0011, -0.0058,  0.0524],\n",
       "         ...,\n",
       "         [-0.0087,  0.0556, -0.0416,  ..., -0.0176, -0.0071, -0.0109],\n",
       "         [-0.0275, -0.0280,  0.0260,  ..., -0.0206, -0.0232, -0.0006],\n",
       "         [ 0.0345, -0.0038,  0.0437,  ..., -0.0173, -0.0221, -0.0053]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.output.dense.bias': tensor([-0.0399, -0.0379, -0.0438,  ..., -0.1174, -0.0231,  0.0670],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.output.LayerNorm.weight': tensor([0.8242, 0.8335, 0.8667,  ..., 0.8940, 0.8159, 0.8364],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.attention.output.LayerNorm.bias': tensor([ 0.1015,  0.0459,  0.0992,  ...,  0.1935,  0.0055, -0.0762],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.intermediate.dense.weight': tensor([[-0.0498, -0.0177, -0.0354,  ..., -0.0166, -0.0085,  0.0048],\n",
       "         [ 0.0357, -0.0214, -0.0380,  ...,  0.0223, -0.0529,  0.0088],\n",
       "         [-0.0294,  0.0510, -0.0679,  ...,  0.0021, -0.0928,  0.0238],\n",
       "         ...,\n",
       "         [-0.0009, -0.0018, -0.0298,  ..., -0.0164, -0.0206, -0.0047],\n",
       "         [ 0.0567,  0.0012,  0.0219,  ...,  0.0036, -0.0128, -0.0500],\n",
       "         [-0.0146, -0.0165, -0.0236,  ..., -0.0237,  0.0021,  0.0004]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.intermediate.dense.bias': tensor([-0.0184,  0.0063, -0.0337,  ..., -0.0192, -0.0273, -0.0362],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.output.dense.weight': tensor([[-0.0576, -0.0241,  0.0167,  ...,  0.0007,  0.0331, -0.0399],\n",
       "         [-0.0008,  0.0618, -0.0512,  ...,  0.0175,  0.0376,  0.0199],\n",
       "         [-0.0219,  0.0407, -0.0264,  ...,  0.0324,  0.0446, -0.0326],\n",
       "         ...,\n",
       "         [ 0.0021, -0.0142,  0.0531,  ...,  0.0302,  0.0980,  0.0066],\n",
       "         [-0.0187, -0.0120, -0.0637,  ...,  0.0264,  0.0613,  0.0173],\n",
       "         [ 0.0251,  0.0203, -0.0326,  ..., -0.0589, -0.0235, -0.0009]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.output.dense.bias': tensor([-0.0188, -0.0546, -0.0198,  ..., -0.0041,  0.0046, -0.0003],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.output.LayerNorm.weight': tensor([1.0488, 1.0234, 1.0625,  ..., 0.9951, 1.0371, 1.0215],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.5.output.LayerNorm.bias': tensor([-0.0138, -0.0175, -0.0417,  ..., -0.0951,  0.0279,  0.0546],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.self.query_proj.weight': tensor([[-0.0324, -0.0002, -0.0158,  ..., -0.0010, -0.0571, -0.0049],\n",
       "         [-0.0095, -0.1016, -0.0341,  ..., -0.0133, -0.0143,  0.0292],\n",
       "         [ 0.0144,  0.0298,  0.0140,  ..., -0.0527, -0.0016, -0.0009],\n",
       "         ...,\n",
       "         [ 0.0527, -0.0225, -0.0216,  ..., -0.0251, -0.0244, -0.0251],\n",
       "         [-0.0527, -0.0261, -0.0666,  ..., -0.0140, -0.0183, -0.0154],\n",
       "         [-0.0302,  0.0126,  0.0046,  ..., -0.0359,  0.0202,  0.0117]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.self.query_proj.bias': tensor([-0.0626,  0.0171,  0.0008,  ..., -0.0618, -0.0004,  0.0011],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.self.key_proj.weight': tensor([[-0.0040, -0.0152, -0.0287,  ...,  0.0114,  0.0032, -0.0552],\n",
       "         [-0.0428,  0.0170,  0.0596,  ...,  0.0041,  0.0135, -0.0171],\n",
       "         [ 0.0135,  0.0021, -0.0436,  ...,  0.0501, -0.0305, -0.0144],\n",
       "         ...,\n",
       "         [-0.0111, -0.0227, -0.0018,  ..., -0.0446,  0.0498,  0.0464],\n",
       "         [ 0.0007,  0.0220, -0.0134,  ..., -0.0052,  0.0407,  0.0256],\n",
       "         [-0.0189,  0.0045, -0.0468,  ...,  0.0133, -0.0396,  0.0014]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.self.key_proj.bias': tensor([-0.1143,  0.1028, -0.0901,  ..., -0.0641,  0.1057,  0.0478],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.self.value_proj.weight': tensor([[ 0.0447,  0.0271, -0.0045,  ...,  0.0017, -0.0305,  0.0573],\n",
       "         [-0.0054, -0.0051,  0.0200,  ..., -0.0215,  0.0111,  0.0473],\n",
       "         [-0.0152,  0.0033,  0.0026,  ..., -0.0109,  0.0347, -0.0542],\n",
       "         ...,\n",
       "         [ 0.0317,  0.0637, -0.0023,  ...,  0.0130, -0.0016, -0.0121],\n",
       "         [ 0.0238, -0.0363,  0.0150,  ..., -0.0415, -0.0365, -0.0178],\n",
       "         [ 0.0390, -0.0068, -0.0400,  ..., -0.0152, -0.0442,  0.0540]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.self.value_proj.bias': tensor([-0.0265,  0.0172, -0.0197,  ..., -0.0087,  0.0002, -0.0074],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.output.dense.weight': tensor([[-0.0551,  0.0258,  0.0151,  ..., -0.0542,  0.0089,  0.0140],\n",
       "         [-0.0643, -0.0237,  0.0310,  ...,  0.0188, -0.0458, -0.0285],\n",
       "         [ 0.0051, -0.0070, -0.0298,  ...,  0.0018,  0.0004,  0.0035],\n",
       "         ...,\n",
       "         [-0.0107,  0.0375,  0.0122,  ..., -0.0115,  0.0168, -0.0239],\n",
       "         [-0.0033,  0.0461, -0.0071,  ..., -0.0249,  0.0353,  0.0142],\n",
       "         [ 0.0062, -0.0037,  0.0030,  ..., -0.0240,  0.0568, -0.0001]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.output.dense.bias': tensor([ 0.0212,  0.0124, -0.0398,  ..., -0.0421,  0.0224, -0.0034],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.output.LayerNorm.weight': tensor([0.8208, 0.8105, 0.8569,  ..., 0.8901, 0.8027, 0.8125],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.attention.output.LayerNorm.bias': tensor([-0.0248,  0.0768,  0.1225,  ...,  0.2332,  0.1406,  0.0310],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.intermediate.dense.weight': tensor([[-0.0479, -0.0381,  0.0398,  ..., -0.0656,  0.0595, -0.0427],\n",
       "         [ 0.0181,  0.0337,  0.0258,  ..., -0.1088,  0.0163,  0.0085],\n",
       "         [-0.0107, -0.0204,  0.0052,  ..., -0.0489, -0.0404,  0.0339],\n",
       "         ...,\n",
       "         [-0.0185, -0.0160,  0.0074,  ..., -0.0045, -0.0115,  0.0167],\n",
       "         [-0.0233, -0.0223,  0.0042,  ..., -0.0498, -0.0582, -0.0142],\n",
       "         [ 0.0244,  0.0302, -0.0383,  ..., -0.0171, -0.0018, -0.0575]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.intermediate.dense.bias': tensor([-0.0414, -0.0375, -0.0370,  ...,  0.0384, -0.0281, -0.0386],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.output.dense.weight': tensor([[-0.0187, -0.0011, -0.0010,  ..., -0.0057, -0.0307, -0.0582],\n",
       "         [-0.0457,  0.0786, -0.0629,  ..., -0.0075,  0.0229,  0.0109],\n",
       "         [ 0.0840,  0.0961,  0.0126,  ..., -0.0283, -0.0399, -0.0263],\n",
       "         ...,\n",
       "         [-0.0821, -0.0092, -0.0120,  ...,  0.0112,  0.0422, -0.0703],\n",
       "         [-0.0050, -0.0495, -0.0500,  ..., -0.0293, -0.0608, -0.0489],\n",
       "         [ 0.0338, -0.0759, -0.0219,  ...,  0.0152, -0.0036, -0.0253]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.output.dense.bias': tensor([ 0.0238, -0.0760, -0.0174,  ..., -0.0302, -0.0245, -0.0278],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.output.LayerNorm.weight': tensor([1.0244, 1.0322, 1.0420,  ..., 0.9595, 0.9863, 0.9775],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.6.output.LayerNorm.bias': tensor([ 0.0514, -0.0124, -0.0140,  ..., -0.0745,  0.0112,  0.0596],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.self.query_proj.weight': tensor([[-0.0039,  0.0462,  0.0178,  ...,  0.0096,  0.0160,  0.0149],\n",
       "         [-0.0113,  0.0014, -0.0084,  ..., -0.0110,  0.0323, -0.0216],\n",
       "         [-0.0281, -0.0170,  0.0272,  ...,  0.0287,  0.0181,  0.0125],\n",
       "         ...,\n",
       "         [ 0.0338,  0.0370, -0.0234,  ...,  0.0201,  0.0282,  0.0099],\n",
       "         [ 0.0660, -0.0074, -0.0315,  ...,  0.0776, -0.0333,  0.0202],\n",
       "         [ 0.0349, -0.0097, -0.0102,  ...,  0.0130,  0.0103,  0.0233]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.self.query_proj.bias': tensor([-0.0109, -0.0232,  0.0287,  ...,  0.0176, -0.0039, -0.0068],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.self.key_proj.weight': tensor([[ 0.0105, -0.0856, -0.0344,  ..., -0.0048,  0.0043,  0.0530],\n",
       "         [ 0.0024, -0.0042,  0.0040,  ..., -0.0508,  0.0091,  0.0340],\n",
       "         [ 0.0197,  0.0183, -0.0528,  ..., -0.0219,  0.0340,  0.0054],\n",
       "         ...,\n",
       "         [ 0.0336, -0.1127, -0.0322,  ...,  0.0385,  0.0584,  0.0072],\n",
       "         [ 0.0029, -0.0177,  0.0127,  ..., -0.0133, -0.0078,  0.0768],\n",
       "         [-0.0291,  0.0054,  0.0037,  ...,  0.0179,  0.0136,  0.0143]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.self.key_proj.bias': tensor([-0.0628,  0.0597, -0.0199,  ..., -0.1162, -0.1050,  0.0615],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.self.value_proj.weight': tensor([[ 0.0138, -0.0015, -0.0199,  ..., -0.0227,  0.0605,  0.0421],\n",
       "         [ 0.0626,  0.0597, -0.0367,  ..., -0.0099,  0.0095, -0.0067],\n",
       "         [-0.0629,  0.0429,  0.0010,  ..., -0.0206,  0.0068,  0.0204],\n",
       "         ...,\n",
       "         [-0.0240, -0.0040, -0.0096,  ...,  0.0121,  0.0556, -0.0231],\n",
       "         [-0.0265, -0.0484, -0.0266,  ...,  0.0748, -0.0232, -0.0773],\n",
       "         [-0.0552,  0.0171, -0.0217,  ..., -0.0080, -0.0082,  0.0278]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.self.value_proj.bias': tensor([ 0.0115,  0.0021, -0.0262,  ...,  0.0034,  0.0088, -0.0124],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.output.dense.weight': tensor([[ 0.0568, -0.0392,  0.0693,  ..., -0.0685, -0.0273,  0.0472],\n",
       "         [-0.0325, -0.0123,  0.0335,  ..., -0.0469, -0.0243, -0.0074],\n",
       "         [ 0.0494,  0.0591, -0.0022,  ..., -0.0359,  0.0431, -0.0267],\n",
       "         ...,\n",
       "         [ 0.0150,  0.0262, -0.0020,  ..., -0.0172,  0.0036,  0.0360],\n",
       "         [-0.0283, -0.0503,  0.0018,  ...,  0.0374, -0.0042, -0.0679],\n",
       "         [ 0.0158,  0.0328, -0.0197,  ...,  0.0091, -0.0432,  0.0319]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.output.dense.bias': tensor([-0.0130,  0.0403,  0.0017,  ..., -0.0286, -0.0053,  0.0154],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.output.LayerNorm.weight': tensor([0.8359, 0.8447, 0.8730,  ..., 0.8906, 0.8037, 0.8179],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.attention.output.LayerNorm.bias': tensor([ 0.1399, -0.1157,  0.1644,  ...,  0.1707,  0.1378,  0.0072],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.intermediate.dense.weight': tensor([[-0.0462,  0.0478, -0.0184,  ..., -0.0229,  0.0251,  0.0258],\n",
       "         [ 0.0331,  0.0437,  0.0562,  ...,  0.0875,  0.0032, -0.0055],\n",
       "         [ 0.0496,  0.0239,  0.0021,  ..., -0.0138,  0.0494, -0.0226],\n",
       "         ...,\n",
       "         [ 0.0425, -0.0150, -0.0069,  ...,  0.0078,  0.0194,  0.0120],\n",
       "         [-0.0083,  0.0026, -0.0282,  ..., -0.0146, -0.0078,  0.0269],\n",
       "         [-0.0209,  0.0542, -0.0182,  ..., -0.0111,  0.0413,  0.0503]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.intermediate.dense.bias': tensor([-0.0406, -0.0391, -0.0251,  ..., -0.0259, -0.0386, -0.0349],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.output.dense.weight': tensor([[-0.0482,  0.0473,  0.0040,  ...,  0.0597,  0.0391, -0.0184],\n",
       "         [ 0.0323,  0.0154, -0.0239,  ...,  0.0594,  0.0565, -0.0092],\n",
       "         [-0.0071,  0.0797,  0.0309,  ...,  0.0218,  0.0129, -0.0517],\n",
       "         ...,\n",
       "         [ 0.0019,  0.0303, -0.0491,  ...,  0.0487, -0.0219, -0.0412],\n",
       "         [-0.0352,  0.0464,  0.0786,  ...,  0.0117,  0.0837,  0.0299],\n",
       "         [ 0.0888, -0.0635,  0.0017,  ...,  0.0580,  0.0216, -0.0437]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.output.dense.bias': tensor([ 0.0238, -0.0456, -0.0076,  ...,  0.0113, -0.0243, -0.0038],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.output.LayerNorm.weight': tensor([1.0479, 1.0586, 1.0635,  ..., 1.0010, 1.0234, 1.0303],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.7.output.LayerNorm.bias': tensor([ 0.0278,  0.0573, -0.0237,  ..., -0.0480, -0.0124,  0.0602],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.self.query_proj.weight': tensor([[-0.0099,  0.0251,  0.0542,  ...,  0.0912, -0.0170, -0.0367],\n",
       "         [-0.0228, -0.0769,  0.0185,  ...,  0.0213,  0.0280, -0.0428],\n",
       "         [ 0.0039,  0.0170, -0.0068,  ...,  0.0355, -0.0791,  0.0136],\n",
       "         ...,\n",
       "         [-0.0526, -0.0014, -0.0023,  ...,  0.0049,  0.0118,  0.0073],\n",
       "         [-0.0042, -0.0133, -0.0246,  ...,  0.0188, -0.0198,  0.0263],\n",
       "         [-0.0046, -0.0398, -0.0070,  ..., -0.0131, -0.0071,  0.0518]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.self.query_proj.bias': tensor([-0.0136,  0.0456,  0.0226,  ...,  0.0766, -0.1472, -0.0444],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.self.key_proj.weight': tensor([[-0.0703, -0.0341,  0.0188,  ..., -0.0825,  0.0148, -0.0892],\n",
       "         [-0.0229,  0.0858, -0.0311,  ...,  0.0275,  0.0561,  0.0750],\n",
       "         [ 0.0812, -0.0625, -0.0363,  ...,  0.1013,  0.0906,  0.0204],\n",
       "         ...,\n",
       "         [ 0.0156, -0.0462,  0.0103,  ...,  0.0303, -0.0551,  0.0363],\n",
       "         [ 0.0026, -0.0739,  0.0371,  ...,  0.0128, -0.0115,  0.0054],\n",
       "         [-0.0309,  0.0628,  0.0168,  ..., -0.0338,  0.0061,  0.0272]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.self.key_proj.bias': tensor([-0.2069, -0.0009,  0.1681,  ...,  0.0859, -0.1049, -0.1120],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.self.value_proj.weight': tensor([[-0.0004,  0.0030,  0.0075,  ..., -0.0201,  0.0280,  0.0209],\n",
       "         [-0.0481, -0.0106, -0.0080,  ..., -0.0239,  0.0130,  0.0267],\n",
       "         [ 0.0304, -0.0083,  0.0044,  ..., -0.0499,  0.0513, -0.0300],\n",
       "         ...,\n",
       "         [-0.0510,  0.0099,  0.0420,  ..., -0.0077, -0.0801, -0.0074],\n",
       "         [ 0.0123,  0.0148,  0.0336,  ..., -0.0144, -0.0065,  0.0153],\n",
       "         [-0.0120, -0.0031,  0.0486,  ..., -0.0176,  0.0175,  0.0334]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.self.value_proj.bias': tensor([-0.0026, -0.0121,  0.0066,  ..., -0.0210, -0.0087, -0.0102],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.output.dense.weight': tensor([[ 0.0063,  0.0048, -0.0472,  ..., -0.0156, -0.0157, -0.0460],\n",
       "         [ 0.0105, -0.0005,  0.0013,  ..., -0.0140, -0.0420, -0.0512],\n",
       "         [-0.0152,  0.0250,  0.0017,  ..., -0.0265,  0.0084,  0.0101],\n",
       "         ...,\n",
       "         [ 0.0302, -0.0350, -0.0180,  ...,  0.0144,  0.0286,  0.0149],\n",
       "         [-0.0316,  0.0446, -0.0298,  ...,  0.0212, -0.0190,  0.0536],\n",
       "         [-0.0265, -0.0182,  0.0294,  ..., -0.0094,  0.0127, -0.0122]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.output.dense.bias': tensor([-0.0216,  0.0465, -0.0153,  ..., -0.0585,  0.0554,  0.0035],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.output.LayerNorm.weight': tensor([0.8569, 0.8667, 0.8799,  ..., 0.8843, 0.8149, 0.8320],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.attention.output.LayerNorm.bias': tensor([ 0.1145, -0.0090,  0.1997,  ...,  0.2150,  0.0115,  0.0646],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.intermediate.dense.weight': tensor([[-0.0106,  0.0143,  0.0305,  ..., -0.0986, -0.0256, -0.0019],\n",
       "         [-0.0058, -0.0220, -0.0120,  ..., -0.0396,  0.0158, -0.0191],\n",
       "         [-0.0270, -0.0053, -0.0005,  ..., -0.0252,  0.0003,  0.0315],\n",
       "         ...,\n",
       "         [-0.0458,  0.0273,  0.0036,  ...,  0.0274,  0.0392, -0.0147],\n",
       "         [ 0.0238, -0.0309, -0.0113,  ..., -0.0310,  0.0483, -0.0071],\n",
       "         [ 0.0182,  0.0574,  0.0051,  ...,  0.0294, -0.0453, -0.0085]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.intermediate.dense.bias': tensor([-0.0367, -0.0061, -0.0270,  ..., -0.0240, -0.0266, -0.0383],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.output.dense.weight': tensor([[-0.0346, -0.0096,  0.0381,  ...,  0.0282, -0.0150, -0.0191],\n",
       "         [-0.0037,  0.0170, -0.0037,  ...,  0.0341,  0.0296,  0.0282],\n",
       "         [ 0.0388,  0.0180,  0.0229,  ...,  0.0280,  0.0061,  0.0497],\n",
       "         ...,\n",
       "         [-0.0184,  0.0197,  0.0191,  ..., -0.0240, -0.0187, -0.0030],\n",
       "         [ 0.0037,  0.0060,  0.0140,  ...,  0.0336,  0.0012, -0.0641],\n",
       "         [-0.0462, -0.0201,  0.0061,  ...,  0.0114, -0.0483, -0.0042]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.output.dense.bias': tensor([ 0.0006, -0.0372, -0.0149,  ...,  0.0334,  0.0392, -0.0255],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.output.LayerNorm.weight': tensor([1.0342, 1.0586, 1.0518,  ..., 0.9971, 1.0273, 1.0293],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.8.output.LayerNorm.bias': tensor([ 0.0075,  0.0967, -0.0354,  ..., -0.0568,  0.0587,  0.0590],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.self.query_proj.weight': tensor([[-0.0402,  0.0358, -0.0127,  ...,  0.0545,  0.0518,  0.0466],\n",
       "         [ 0.0194,  0.0092, -0.0493,  ..., -0.0207,  0.0344,  0.0086],\n",
       "         [-0.0204, -0.0358, -0.0328,  ..., -0.0566,  0.0015,  0.0598],\n",
       "         ...,\n",
       "         [ 0.0425, -0.0351, -0.0373,  ..., -0.0056, -0.0112, -0.0254],\n",
       "         [ 0.0424,  0.0159, -0.0564,  ..., -0.0288, -0.0114, -0.0065],\n",
       "         [ 0.0090,  0.0113,  0.0121,  ..., -0.0041,  0.0741,  0.0511]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.self.query_proj.bias': tensor([-0.0232, -0.0839,  0.0111,  ..., -0.0173, -0.0178, -0.0438],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.self.key_proj.weight': tensor([[-0.0142, -0.0548,  0.0107,  ...,  0.0197, -0.0310,  0.0321],\n",
       "         [ 0.0026, -0.0413,  0.0117,  ..., -0.0121, -0.0602, -0.0172],\n",
       "         [ 0.0217,  0.0590, -0.0175,  ...,  0.0259,  0.0024,  0.0199],\n",
       "         ...,\n",
       "         [-0.0167,  0.0441, -0.0164,  ..., -0.0470,  0.0869,  0.0401],\n",
       "         [ 0.0240, -0.0016,  0.0215,  ..., -0.0178,  0.0354,  0.0037],\n",
       "         [ 0.0370,  0.0089,  0.0109,  ..., -0.0169,  0.0656, -0.0111]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.self.key_proj.bias': tensor([ 0.1257, -0.1121,  0.2125,  ..., -0.0981,  0.1675, -0.0033],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.self.value_proj.weight': tensor([[ 0.0061, -0.0214,  0.0247,  ..., -0.0096, -0.0225, -0.0640],\n",
       "         [-0.0419, -0.0416, -0.0141,  ...,  0.0120, -0.0119, -0.0480],\n",
       "         [ 0.0057, -0.0037, -0.0304,  ..., -0.0201,  0.0445,  0.0185],\n",
       "         ...,\n",
       "         [ 0.0195, -0.0394, -0.0421,  ...,  0.0415, -0.0323, -0.0253],\n",
       "         [-0.0323, -0.0049, -0.0145,  ..., -0.0473, -0.0418, -0.0072],\n",
       "         [ 0.0299, -0.0356,  0.0224,  ...,  0.0016, -0.0226,  0.0449]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.self.value_proj.bias': tensor([ 0.0429, -0.0032, -0.0148,  ...,  0.0084,  0.0086,  0.0087],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.output.dense.weight': tensor([[-0.0238, -0.0183, -0.0057,  ...,  0.0595, -0.0339,  0.0111],\n",
       "         [-0.0261, -0.0004, -0.0226,  ..., -0.0222, -0.0064,  0.0192],\n",
       "         [ 0.0165, -0.0397, -0.0237,  ...,  0.0724, -0.0309,  0.0323],\n",
       "         ...,\n",
       "         [ 0.0234,  0.0211, -0.0017,  ..., -0.0324, -0.0379,  0.0371],\n",
       "         [-0.0306, -0.0203,  0.0988,  ...,  0.0016, -0.0255, -0.0063],\n",
       "         [-0.0073,  0.0122,  0.0173,  ...,  0.0291,  0.0362,  0.0656]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.output.dense.bias': tensor([-0.0160,  0.0313, -0.0161,  ..., -0.1072,  0.0133,  0.0124],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.output.LayerNorm.weight': tensor([0.8496, 0.8672, 0.8774,  ..., 0.9233, 0.8101, 0.8208],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.attention.output.LayerNorm.bias': tensor([0.1011, 0.1482, 0.2445,  ..., 0.3716, 0.2233, 0.0600],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.intermediate.dense.weight': tensor([[ 0.0252, -0.0168,  0.0146,  ...,  0.0025, -0.0009, -0.0194],\n",
       "         [-0.0545,  0.0006, -0.0267,  ..., -0.0670, -0.0361, -0.0385],\n",
       "         [-0.0044, -0.0416, -0.0598,  ..., -0.0075, -0.0167,  0.0090],\n",
       "         ...,\n",
       "         [ 0.0518, -0.0105, -0.0217,  ...,  0.0293,  0.0169,  0.0397],\n",
       "         [ 0.0166,  0.0111, -0.0182,  ...,  0.0023,  0.0249, -0.0303],\n",
       "         [-0.0011, -0.0265, -0.0147,  ..., -0.0528,  0.0282, -0.0143]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.intermediate.dense.bias': tensor([ 0.0076, -0.0486, -0.0434,  ...,  0.0042, -0.0277, -0.0409],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.output.dense.weight': tensor([[-0.0149, -0.0267, -0.0617,  ...,  0.0308,  0.0175,  0.0443],\n",
       "         [-0.0310, -0.0103,  0.0168,  ..., -0.0718,  0.0170, -0.0130],\n",
       "         [ 0.0237,  0.0192, -0.0126,  ...,  0.0017,  0.0300, -0.0043],\n",
       "         ...,\n",
       "         [-0.0030,  0.0180,  0.0342,  ...,  0.0127,  0.0598, -0.0398],\n",
       "         [ 0.0292, -0.1006, -0.0222,  ..., -0.0552, -0.0016,  0.0461],\n",
       "         [-0.0047,  0.0485, -0.0295,  ..., -0.0229,  0.0123, -0.0547]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.output.dense.bias': tensor([ 0.0009, -0.0593, -0.0130,  ...,  0.0141,  0.0436,  0.0133],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.output.LayerNorm.weight': tensor([1.0586, 1.0811, 1.0264,  ..., 0.9082, 1.0176, 1.0205],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.9.output.LayerNorm.bias': tensor([ 0.0117,  0.0488, -0.0810,  ..., -0.1251,  0.0098,  0.0674],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.self.query_proj.weight': tensor([[-0.0226, -0.0003,  0.0403,  ...,  0.0146, -0.0300, -0.0629],\n",
       "         [-0.0622,  0.0382,  0.0933,  ...,  0.0242, -0.0161, -0.0520],\n",
       "         [-0.0129,  0.0623, -0.0372,  ..., -0.0345,  0.0014, -0.0629],\n",
       "         ...,\n",
       "         [ 0.0931, -0.0753, -0.0267,  ...,  0.0176,  0.0470,  0.0299],\n",
       "         [-0.0423,  0.0119,  0.0466,  ...,  0.0438,  0.0073, -0.0722],\n",
       "         [ 0.0060,  0.0331, -0.0078,  ...,  0.0144,  0.0638,  0.0379]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.self.query_proj.bias': tensor([-0.0008,  0.0160,  0.0471,  ..., -0.2336,  0.1652, -0.2778],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.self.key_proj.weight': tensor([[ 0.0217,  0.0187,  0.0617,  ...,  0.0606,  0.0243,  0.0275],\n",
       "         [ 0.0618,  0.0420, -0.0400,  ...,  0.0102,  0.0005, -0.0239],\n",
       "         [-0.0413,  0.0813, -0.0728,  ...,  0.0330, -0.0175, -0.0389],\n",
       "         ...,\n",
       "         [-0.0219, -0.0333,  0.0189,  ..., -0.0621,  0.0547, -0.0520],\n",
       "         [ 0.0411, -0.0281, -0.0164,  ..., -0.0114, -0.0378, -0.0544],\n",
       "         [ 0.0117, -0.0437, -0.0555,  ..., -0.0385, -0.0126,  0.0826]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.self.key_proj.bias': tensor([-0.1313, -0.1390, -0.0535,  ...,  0.0402, -0.0509,  0.1952],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.self.value_proj.weight': tensor([[-0.0420,  0.0023,  0.0541,  ..., -0.0029,  0.0196,  0.0236],\n",
       "         [ 0.0170,  0.0146,  0.0073,  ...,  0.0036,  0.0685, -0.0261],\n",
       "         [ 0.0394, -0.0200,  0.0292,  ...,  0.0290,  0.0338, -0.0169],\n",
       "         ...,\n",
       "         [-0.0016, -0.0918, -0.0260,  ..., -0.0194,  0.0200,  0.0583],\n",
       "         [ 0.0108, -0.0652, -0.0549,  ...,  0.0082, -0.0390,  0.0129],\n",
       "         [-0.0287,  0.0100,  0.0202,  ..., -0.0401, -0.0467,  0.0341]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.self.value_proj.bias': tensor([ 0.0216,  0.0058, -0.0070,  ..., -0.0022,  0.0102, -0.0001],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.output.dense.weight': tensor([[ 0.0052,  0.0307, -0.0096,  ..., -0.0120, -0.0051, -0.0195],\n",
       "         [-0.0006, -0.0337, -0.0131,  ..., -0.0161,  0.0156,  0.0121],\n",
       "         [ 0.0216,  0.0485,  0.0089,  ...,  0.0144,  0.0209, -0.0645],\n",
       "         ...,\n",
       "         [-0.0441,  0.0116,  0.0390,  ..., -0.0032, -0.0125,  0.0051],\n",
       "         [-0.0004, -0.0428, -0.0186,  ...,  0.0040,  0.0468,  0.0013],\n",
       "         [-0.0011, -0.0356,  0.0225,  ...,  0.0075, -0.0430, -0.0006]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.output.dense.bias': tensor([-0.0159,  0.0190, -0.0175,  ..., -0.0668, -0.0006,  0.0082],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.output.LayerNorm.weight': tensor([0.8330, 0.8945, 0.8618,  ..., 0.8418, 0.8135, 0.7905],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.attention.output.LayerNorm.bias': tensor([0.0364, 0.0446, 0.1267,  ..., 0.0658, 0.1963, 0.0718],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.intermediate.dense.weight': tensor([[-0.0113, -0.0077, -0.0258,  ...,  0.0447, -0.0217, -0.0645],\n",
       "         [ 0.0404,  0.0533, -0.0149,  ..., -0.0109, -0.0571, -0.0035],\n",
       "         [-0.0518,  0.0059,  0.0389,  ...,  0.0047, -0.0258, -0.0399],\n",
       "         ...,\n",
       "         [ 0.0050, -0.0076,  0.0144,  ..., -0.0262, -0.0143, -0.0211],\n",
       "         [-0.0488,  0.0028, -0.0376,  ..., -0.0033, -0.0314,  0.0066],\n",
       "         [ 0.0147, -0.0618, -0.0081,  ...,  0.0103, -0.0079, -0.0422]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.intermediate.dense.bias': tensor([-0.0396, -0.0210, -0.0466,  ...,  0.0182, -0.0294, -0.0074],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.output.dense.weight': tensor([[ 0.0158, -0.0462,  0.0217,  ...,  0.0204, -0.0369,  0.0158],\n",
       "         [ 0.0364,  0.0285,  0.0018,  ...,  0.0094,  0.0980, -0.0205],\n",
       "         [ 0.0360,  0.0285,  0.0065,  ..., -0.0251, -0.0048, -0.0589],\n",
       "         ...,\n",
       "         [ 0.0597, -0.0086, -0.0006,  ...,  0.0235, -0.0141,  0.0492],\n",
       "         [-0.0494, -0.0271,  0.0164,  ..., -0.0035, -0.0324, -0.0870],\n",
       "         [ 0.0130,  0.0133, -0.0492,  ...,  0.0463, -0.0293, -0.0098]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.output.dense.bias': tensor([ 0.0030, -0.0031, -0.0343,  ..., -0.0466,  0.0602, -0.0210],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.output.LayerNorm.weight': tensor([1.0498, 1.0752, 1.0381,  ..., 0.9604, 0.9780, 1.0107],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.10.output.LayerNorm.bias': tensor([ 0.0447,  0.0767, -0.0591,  ..., -0.0687, -0.0247,  0.0495],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.self.query_proj.weight': tensor([[-0.0652, -0.0200,  0.0441,  ...,  0.0303,  0.0118, -0.0161],\n",
       "         [-0.0062,  0.0156,  0.0213,  ..., -0.0203, -0.0007, -0.0018],\n",
       "         [ 0.0037, -0.0458,  0.0068,  ..., -0.0252,  0.0317,  0.0052],\n",
       "         ...,\n",
       "         [ 0.0071,  0.0204, -0.0180,  ...,  0.0155,  0.0078, -0.0343],\n",
       "         [-0.0161,  0.0070,  0.0377,  ..., -0.0418,  0.0308,  0.0344],\n",
       "         [ 0.0323,  0.0555,  0.0214,  ...,  0.0816, -0.0276,  0.0305]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.self.query_proj.bias': tensor([ 0.0308, -0.0314,  0.0115,  ...,  0.0390,  0.0071,  0.0583],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.self.key_proj.weight': tensor([[-0.0061, -0.0109,  0.0131,  ..., -0.0131,  0.0590, -0.0323],\n",
       "         [-0.0174, -0.0421,  0.0002,  ...,  0.0023, -0.0026, -0.0706],\n",
       "         [-0.0457,  0.0043,  0.0218,  ...,  0.0260,  0.0138, -0.0747],\n",
       "         ...,\n",
       "         [-0.0374,  0.0311, -0.0115,  ..., -0.0102,  0.0119,  0.0569],\n",
       "         [ 0.0132, -0.0028, -0.0202,  ...,  0.0063, -0.0700, -0.0211],\n",
       "         [ 0.0028, -0.0351,  0.0033,  ...,  0.0274,  0.0214,  0.0031]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.self.key_proj.bias': tensor([ 0.1427, -0.0833, -0.0487,  ...,  0.0671, -0.1041, -0.0336],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.self.value_proj.weight': tensor([[-0.0183, -0.0015, -0.0178,  ..., -0.0303,  0.0430, -0.0073],\n",
       "         [-0.0271,  0.0249,  0.0092,  ..., -0.0040,  0.0413, -0.0089],\n",
       "         [-0.0361,  0.0403,  0.0070,  ...,  0.0307,  0.0467, -0.0284],\n",
       "         ...,\n",
       "         [-0.0028,  0.0243,  0.0045,  ..., -0.0614,  0.0159, -0.0304],\n",
       "         [ 0.0843,  0.0311,  0.0133,  ...,  0.0441, -0.0162,  0.0088],\n",
       "         [ 0.0374, -0.0254,  0.0037,  ...,  0.0141, -0.0388,  0.0183]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.self.value_proj.bias': tensor([-0.0115,  0.0056,  0.0075,  ...,  0.0125, -0.0031,  0.0205],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.output.dense.weight': tensor([[-0.0050, -0.0329, -0.0206,  ...,  0.0043, -0.0351, -0.0228],\n",
       "         [ 0.0126,  0.0004,  0.0006,  ..., -0.0011, -0.0151, -0.0105],\n",
       "         [ 0.0312,  0.0083,  0.0111,  ..., -0.0366, -0.0724, -0.0276],\n",
       "         ...,\n",
       "         [ 0.0216,  0.0005, -0.0282,  ...,  0.0134, -0.0469,  0.0099],\n",
       "         [ 0.0484, -0.0011,  0.0170,  ..., -0.0683, -0.0121,  0.0034],\n",
       "         [-0.0320, -0.0759,  0.0014,  ...,  0.0212, -0.0339, -0.0573]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.output.dense.bias': tensor([-0.0021,  0.0698, -0.0621,  ..., -0.0477, -0.0248,  0.0670],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.output.LayerNorm.weight': tensor([0.8169, 0.8901, 0.8535,  ..., 0.8081, 0.7935, 0.8042],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.attention.output.LayerNorm.bias': tensor([0.1113, 0.1567, 0.0941,  ..., 0.0256, 0.0966, 0.0578],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.intermediate.dense.weight': tensor([[-0.0616,  0.0379,  0.0308,  ..., -0.0202, -0.0632,  0.0092],\n",
       "         [ 0.0016,  0.0327,  0.0203,  ...,  0.0019, -0.0262, -0.0456],\n",
       "         [-0.0355, -0.0083, -0.0278,  ..., -0.0255,  0.0049, -0.0392],\n",
       "         ...,\n",
       "         [ 0.0289,  0.0119, -0.0417,  ...,  0.0114,  0.0735,  0.0197],\n",
       "         [ 0.0114, -0.0169,  0.0334,  ...,  0.0096, -0.0237,  0.0154],\n",
       "         [ 0.0234, -0.0062,  0.0069,  ..., -0.0247, -0.0089,  0.0329]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.intermediate.dense.bias': tensor([-0.0480, -0.0430, -0.0137,  ..., -0.0466,  0.0123, -0.0306],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.output.dense.weight': tensor([[ 0.0143, -0.0305, -0.0781,  ...,  0.0613, -0.0196, -0.0048],\n",
       "         [-0.1092,  0.0507,  0.0498,  ..., -0.0366, -0.0028, -0.0034],\n",
       "         [ 0.0082,  0.0025, -0.0105,  ...,  0.0101,  0.0026, -0.0336],\n",
       "         ...,\n",
       "         [-0.0300,  0.0059, -0.0369,  ..., -0.0384,  0.0064,  0.0089],\n",
       "         [ 0.0445, -0.0368, -0.0396,  ...,  0.0699,  0.0082, -0.0576],\n",
       "         [-0.0219,  0.0005,  0.0482,  ..., -0.0577,  0.0260,  0.0334]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.output.dense.bias': tensor([ 0.0046, -0.0129, -0.0088,  ..., -0.0114,  0.0330, -0.0319],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.output.LayerNorm.weight': tensor([1.0713, 1.0947, 1.0801,  ..., 1.0107, 1.0205, 1.0332],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.11.output.LayerNorm.bias': tensor([ 0.0228,  0.0261, -0.0076,  ...,  0.0224,  0.0097,  0.0578],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.self.query_proj.weight': tensor([[ 0.0050, -0.0138, -0.0343,  ..., -0.0558,  0.0360,  0.0392],\n",
       "         [-0.0111,  0.0120,  0.0196,  ...,  0.0001, -0.0490,  0.0153],\n",
       "         [ 0.0025, -0.0187,  0.0493,  ...,  0.0314, -0.0564,  0.0388],\n",
       "         ...,\n",
       "         [ 0.0148,  0.0151,  0.0134,  ..., -0.0428, -0.0886,  0.0074],\n",
       "         [ 0.0312,  0.0523,  0.0486,  ...,  0.0166, -0.0433,  0.0066],\n",
       "         [-0.0558,  0.0523,  0.0081,  ..., -0.0097,  0.0082,  0.0565]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.self.query_proj.bias': tensor([ 0.0858,  0.0736,  0.0051,  ..., -0.0795, -0.0404, -0.0092],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.self.key_proj.weight': tensor([[-0.0709,  0.0124,  0.1155,  ..., -0.0099, -0.0246,  0.0634],\n",
       "         [ 0.0430,  0.0267,  0.0207,  ...,  0.0428,  0.0602, -0.0036],\n",
       "         [-0.0043,  0.0354, -0.0937,  ..., -0.0573,  0.0179, -0.0071],\n",
       "         ...,\n",
       "         [ 0.0303,  0.0064, -0.0158,  ...,  0.0351,  0.0116, -0.0293],\n",
       "         [ 0.0122,  0.0338,  0.0424,  ..., -0.0363, -0.0413, -0.0120],\n",
       "         [-0.0300, -0.0201,  0.0022,  ...,  0.0509,  0.0199,  0.0088]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.self.key_proj.bias': tensor([ 0.0768,  0.1234, -0.1710,  ..., -0.0412,  0.2039, -0.0864],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.self.value_proj.weight': tensor([[ 0.0486, -0.0189,  0.0262,  ...,  0.0156,  0.0048,  0.0120],\n",
       "         [ 0.0015, -0.0046,  0.0307,  ...,  0.0021, -0.0001, -0.0353],\n",
       "         [ 0.0158,  0.0035, -0.0146,  ..., -0.0288, -0.0151,  0.0103],\n",
       "         ...,\n",
       "         [ 0.0283,  0.0124,  0.0517,  ..., -0.0393,  0.0258, -0.0117],\n",
       "         [-0.0187,  0.0259, -0.0164,  ..., -0.0030,  0.0382,  0.0079],\n",
       "         [ 0.0469, -0.0539, -0.0002,  ..., -0.0012, -0.0019,  0.0023]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.self.value_proj.bias': tensor([-0.0004,  0.0005,  0.0116,  ..., -0.0120,  0.0051,  0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.output.dense.weight': tensor([[ 0.0059, -0.0032,  0.0097,  ..., -0.0226,  0.0305, -0.0824],\n",
       "         [ 0.0167,  0.0184, -0.0060,  ..., -0.0047,  0.0118, -0.0057],\n",
       "         [ 0.0103, -0.0123,  0.0129,  ..., -0.0019, -0.0637, -0.0127],\n",
       "         ...,\n",
       "         [-0.0028, -0.0140,  0.0416,  ...,  0.0240,  0.0024,  0.0370],\n",
       "         [-0.0385, -0.0242, -0.0035,  ..., -0.0024, -0.0624,  0.0665],\n",
       "         [-0.0235, -0.0103, -0.0253,  ..., -0.0072, -0.0044, -0.0082]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.output.dense.bias': tensor([-0.0300,  0.0365, -0.0476,  ..., -0.0933, -0.0267,  0.0417],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.output.LayerNorm.weight': tensor([0.7817, 0.8936, 0.7910,  ..., 0.7549, 0.7393, 0.7563],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.attention.output.LayerNorm.bias': tensor([-0.1227, -0.0569, -0.0383,  ..., -0.1106, -0.0914, -0.1205],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.intermediate.dense.weight': tensor([[ 0.0152, -0.0327,  0.0198,  ..., -0.0040,  0.0299,  0.0116],\n",
       "         [-0.0120,  0.0352, -0.0331,  ...,  0.0494, -0.0083, -0.0194],\n",
       "         [ 0.0635, -0.0138, -0.0328,  ..., -0.0470,  0.0989, -0.0632],\n",
       "         ...,\n",
       "         [ 0.0024,  0.0327, -0.0007,  ..., -0.0002,  0.0290, -0.0008],\n",
       "         [ 0.0239,  0.0188, -0.0095,  ...,  0.0036, -0.0150,  0.0374],\n",
       "         [ 0.0222,  0.0579, -0.0139,  ...,  0.0594,  0.0098,  0.0386]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.intermediate.dense.bias': tensor([ 0.0333, -0.0097, -0.0585,  ..., -0.0548, -0.0196, -0.0492],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.output.dense.weight': tensor([[ 0.0010,  0.0119, -0.0210,  ...,  0.0786, -0.0309,  0.0726],\n",
       "         [ 0.0149,  0.0015,  0.0095,  ...,  0.0394, -0.0151,  0.0156],\n",
       "         [ 0.0397,  0.0076, -0.0002,  ...,  0.0157, -0.0313, -0.0273],\n",
       "         ...,\n",
       "         [ 0.0346, -0.0088, -0.0265,  ...,  0.0264,  0.0345, -0.0151],\n",
       "         [ 0.0399, -0.0130,  0.0391,  ..., -0.0324,  0.0354,  0.0039],\n",
       "         [ 0.0139, -0.0581, -0.0803,  ..., -0.0145,  0.0478,  0.0978]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.output.dense.bias': tensor([ 0.0217,  0.0250,  0.0460,  ..., -0.0454,  0.0565,  0.0347],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.output.LayerNorm.weight': tensor([1.0469, 1.0615, 1.0596,  ..., 0.9966, 0.9941, 0.9878],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.12.output.LayerNorm.bias': tensor([ 0.0072, -0.0045, -0.0366,  ..., -0.0162,  0.0003,  0.0378],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.self.query_proj.weight': tensor([[ 0.0043,  0.0116,  0.0156,  ..., -0.0377, -0.0509,  0.0036],\n",
       "         [ 0.0082,  0.0135, -0.0420,  ...,  0.0206, -0.0269, -0.0074],\n",
       "         [ 0.0243,  0.0083, -0.0320,  ...,  0.0200, -0.0142, -0.0356],\n",
       "         ...,\n",
       "         [ 0.0464, -0.0107,  0.0491,  ...,  0.0281, -0.0030, -0.0454],\n",
       "         [ 0.0197,  0.0048, -0.0656,  ...,  0.0009, -0.0116,  0.0198],\n",
       "         [ 0.0136,  0.0154, -0.0506,  ...,  0.0153,  0.0665, -0.0048]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.self.query_proj.bias': tensor([-0.0119,  0.0182, -0.0202,  ..., -0.0242,  0.0571, -0.0143],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.self.key_proj.weight': tensor([[ 0.0360,  0.0470, -0.0488,  ...,  0.0204, -0.0539, -0.0304],\n",
       "         [ 0.0150, -0.0329, -0.0133,  ..., -0.0558,  0.0501,  0.0386],\n",
       "         [ 0.0540,  0.0325, -0.0222,  ...,  0.0404, -0.0088,  0.0045],\n",
       "         ...,\n",
       "         [-0.0779, -0.0038, -0.0220,  ...,  0.0137,  0.0385, -0.0039],\n",
       "         [ 0.0181,  0.0011, -0.0054,  ...,  0.0216,  0.0419, -0.0270],\n",
       "         [-0.0179,  0.0519,  0.0072,  ..., -0.0679, -0.0354,  0.0260]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.self.key_proj.bias': tensor([0.0088, 0.2311, 0.0507,  ..., 0.0195, 0.0033, 0.2274],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.self.value_proj.weight': tensor([[-0.0159, -0.0084, -0.0020,  ...,  0.0879,  0.0595, -0.0467],\n",
       "         [-0.0472, -0.0084,  0.0049,  ..., -0.0355,  0.0010,  0.0271],\n",
       "         [ 0.0066, -0.0295, -0.0199,  ...,  0.0057,  0.0080,  0.0336],\n",
       "         ...,\n",
       "         [ 0.0226, -0.0144, -0.0066,  ...,  0.0800,  0.0947, -0.0172],\n",
       "         [ 0.0518,  0.0101, -0.0550,  ...,  0.0047, -0.0782, -0.0100],\n",
       "         [ 0.0141, -0.0049, -0.0107,  ..., -0.0171,  0.0309, -0.0477]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.self.value_proj.bias': tensor([ 0.0350, -0.0025, -0.0104,  ...,  0.0094, -0.0337,  0.0040],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.output.dense.weight': tensor([[ 0.0196, -0.0273, -0.0478,  ...,  0.0274, -0.0029,  0.0022],\n",
       "         [ 0.0062, -0.0228, -0.0111,  ..., -0.0183, -0.0275,  0.0003],\n",
       "         [ 0.0182, -0.0198,  0.0182,  ...,  0.0458, -0.0814, -0.0345],\n",
       "         ...,\n",
       "         [-0.0204, -0.0507, -0.0076,  ...,  0.0509, -0.0620,  0.0340],\n",
       "         [-0.0143, -0.0560, -0.0049,  ...,  0.0309, -0.0840,  0.0383],\n",
       "         [-0.0119,  0.0019,  0.0062,  ..., -0.0032, -0.0401,  0.0416]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.output.dense.bias': tensor([ 0.0067,  0.0299, -0.0174,  ..., -0.0490, -0.0004, -0.0176],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.output.LayerNorm.weight': tensor([0.8311, 0.9058, 0.8364,  ..., 0.7524, 0.7568, 0.7852],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.attention.output.LayerNorm.bias': tensor([-0.1858, -0.1068, -0.0491,  ..., -0.1791, -0.1389, -0.1078],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.intermediate.dense.weight': tensor([[ 0.0455,  0.0107, -0.0277,  ..., -0.0029,  0.0271,  0.0205],\n",
       "         [ 0.0237, -0.0267, -0.0393,  ...,  0.0256,  0.0217, -0.0368],\n",
       "         [-0.0129, -0.0017, -0.0338,  ...,  0.0102, -0.0289, -0.0386],\n",
       "         ...,\n",
       "         [ 0.0216,  0.0378, -0.0306,  ...,  0.0165, -0.0148, -0.0394],\n",
       "         [-0.0066,  0.0343,  0.0267,  ...,  0.0137, -0.0180,  0.0019],\n",
       "         [ 0.0178,  0.0114,  0.0134,  ...,  0.0310,  0.0276, -0.0252]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.intermediate.dense.bias': tensor([-0.0367, -0.0151, -0.0196,  ..., -0.0453, -0.0423, -0.0181],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.output.dense.weight': tensor([[ 0.0650, -0.0159, -0.0258,  ..., -0.0165, -0.0837,  0.0053],\n",
       "         [ 0.0254, -0.0094,  0.0054,  ..., -0.0088, -0.0039,  0.0141],\n",
       "         [ 0.0203, -0.0206,  0.0054,  ..., -0.0189,  0.0405, -0.0048],\n",
       "         ...,\n",
       "         [ 0.0110, -0.0409, -0.0178,  ...,  0.0069, -0.0286,  0.0371],\n",
       "         [-0.0098, -0.0220, -0.0193,  ..., -0.0451,  0.0334, -0.0384],\n",
       "         [ 0.0378, -0.0224, -0.0164,  ..., -0.0635, -0.0299, -0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.output.dense.bias': tensor([-0.0213,  0.0120, -0.0376,  ...,  0.0098,  0.0194,  0.0200],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.output.LayerNorm.weight': tensor([1.0723, 1.0723, 1.0742,  ..., 1.0020, 1.0410, 1.0479],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.13.output.LayerNorm.bias': tensor([-0.0148, -0.0351, -0.1030,  ...,  0.0103, -0.0388, -0.0213],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.self.query_proj.weight': tensor([[-0.0200,  0.0144,  0.0312,  ..., -0.0272,  0.0085,  0.0453],\n",
       "         [-0.0226, -0.0244,  0.0074,  ..., -0.0265,  0.0127, -0.0032],\n",
       "         [-0.0026,  0.0295, -0.0016,  ...,  0.0099, -0.0309,  0.0245],\n",
       "         ...,\n",
       "         [-0.0361, -0.0450,  0.0527,  ..., -0.0726,  0.0188,  0.0070],\n",
       "         [ 0.0250,  0.0600,  0.0237,  ...,  0.0024,  0.0312, -0.0011],\n",
       "         [ 0.0224, -0.0183,  0.0279,  ...,  0.0036, -0.0272,  0.0123]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.self.query_proj.bias': tensor([-0.0238,  0.0262,  0.0506,  ..., -0.0697,  0.0190,  0.0329],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.self.key_proj.weight': tensor([[-0.0387,  0.0345, -0.0082,  ..., -0.0214,  0.0462, -0.0197],\n",
       "         [ 0.0362, -0.0081,  0.0034,  ..., -0.0378, -0.0162, -0.0445],\n",
       "         [ 0.0069,  0.0414, -0.0207,  ...,  0.0061, -0.0563, -0.0165],\n",
       "         ...,\n",
       "         [ 0.0132,  0.0829, -0.0130,  ...,  0.0457, -0.0084, -0.0206],\n",
       "         [-0.0154,  0.0179, -0.0121,  ...,  0.0485,  0.0182,  0.0068],\n",
       "         [-0.0862,  0.0467,  0.0130,  ...,  0.0850, -0.0597, -0.0207]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.self.key_proj.bias': tensor([-0.0974,  0.0471, -0.0490,  ..., -0.1313, -0.0765,  0.2185],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.self.value_proj.weight': tensor([[ 0.0031,  0.0233,  0.0560,  ...,  0.0012,  0.0041, -0.0005],\n",
       "         [-0.0217, -0.0070,  0.0246,  ...,  0.0906, -0.0005, -0.0527],\n",
       "         [-0.0100, -0.0001, -0.0061,  ..., -0.0103,  0.0006,  0.0726],\n",
       "         ...,\n",
       "         [-0.0042,  0.0121,  0.0346,  ...,  0.0684,  0.0538, -0.0143],\n",
       "         [-0.0186, -0.0074, -0.0162,  ..., -0.0436,  0.0139,  0.0071],\n",
       "         [ 0.0321,  0.0125,  0.0039,  ..., -0.0593,  0.0062,  0.0158]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.self.value_proj.bias': tensor([ 0.0008,  0.0008,  0.0042,  ...,  0.0483,  0.0106, -0.0306],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.output.dense.weight': tensor([[ 0.0086,  0.0031, -0.0338,  ...,  0.0106,  0.0130,  0.0162],\n",
       "         [-0.0005,  0.0088, -0.0054,  ..., -0.0367, -0.0055,  0.0303],\n",
       "         [ 0.0200, -0.0312, -0.0098,  ...,  0.0184,  0.0095, -0.0130],\n",
       "         ...,\n",
       "         [-0.0231, -0.0103,  0.0552,  ..., -0.0138,  0.0356,  0.0407],\n",
       "         [ 0.0367, -0.0721,  0.0490,  ...,  0.0088, -0.0058,  0.0013],\n",
       "         [ 0.0363, -0.0918,  0.0580,  ..., -0.0025,  0.0364, -0.0077]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.output.dense.bias': tensor([ 0.0124,  0.0170, -0.0542,  ..., -0.0251, -0.0076,  0.0199],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.output.LayerNorm.weight': tensor([0.8086, 0.9395, 0.8452,  ..., 0.7627, 0.7617, 0.7593],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.attention.output.LayerNorm.bias': tensor([-0.1984, -0.0876, -0.1589,  ..., -0.1448, -0.1418, -0.1008],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.intermediate.dense.weight': tensor([[-0.0045,  0.0228,  0.0091,  ...,  0.0208, -0.0094,  0.0211],\n",
       "         [-0.0092, -0.0314, -0.0422,  ..., -0.0704, -0.0266,  0.0414],\n",
       "         [ 0.2413,  0.0197, -0.0307,  ..., -0.0612, -0.0246, -0.0603],\n",
       "         ...,\n",
       "         [ 0.0212,  0.0276,  0.0046,  ...,  0.0095,  0.0280,  0.0138],\n",
       "         [ 0.0469,  0.0249,  0.0586,  ...,  0.0165, -0.0143, -0.0287],\n",
       "         [ 0.0161,  0.0154,  0.0309,  ..., -0.0037, -0.0233, -0.0422]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.intermediate.dense.bias': tensor([-0.0443, -0.0423, -0.0630,  ..., -0.0474,  0.0096, -0.0292],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.output.dense.weight': tensor([[ 0.0556,  0.0034,  0.0177,  ...,  0.0580, -0.0420,  0.0318],\n",
       "         [ 0.0097, -0.0406, -0.0005,  ..., -0.0114, -0.0151,  0.0058],\n",
       "         [-0.0015,  0.0192, -0.0163,  ..., -0.0244, -0.0644,  0.0168],\n",
       "         ...,\n",
       "         [-0.0252, -0.0077, -0.0455,  ...,  0.0424, -0.0344, -0.0224],\n",
       "         [ 0.0165,  0.0234, -0.0049,  ...,  0.0061,  0.0077, -0.0287],\n",
       "         [ 0.0243, -0.0530,  0.0084,  ..., -0.0061,  0.0077, -0.0411]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.output.dense.bias': tensor([-0.0296,  0.0091, -0.0311,  ..., -0.0081,  0.0560,  0.0290],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.output.LayerNorm.weight': tensor([1.0586, 1.0664, 1.0801,  ..., 1.0068, 1.0400, 1.0293],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.14.output.LayerNorm.bias': tensor([ 0.0021, -0.0575, -0.0540,  ..., -0.0062, -0.0020, -0.0257],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.self.query_proj.weight': tensor([[ 0.0095, -0.0407,  0.0208,  ...,  0.0589, -0.0599, -0.0090],\n",
       "         [ 0.0222, -0.0040,  0.0211,  ...,  0.0520,  0.0092, -0.0454],\n",
       "         [ 0.0037,  0.0058,  0.0238,  ...,  0.0364, -0.0658,  0.0500],\n",
       "         ...,\n",
       "         [-0.0300, -0.0002, -0.0202,  ...,  0.0195,  0.0368,  0.0086],\n",
       "         [-0.0293, -0.0017,  0.0133,  ...,  0.0035,  0.0342,  0.0217],\n",
       "         [-0.0080, -0.0193, -0.0457,  ..., -0.0306,  0.0374, -0.0174]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.self.query_proj.bias': tensor([ 0.0028,  0.0055,  0.0032,  ..., -0.0244, -0.0280,  0.0736],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.self.key_proj.weight': tensor([[-0.0018,  0.0066,  0.0167,  ..., -0.0720,  0.0857, -0.0148],\n",
       "         [-0.0232, -0.0135, -0.0114,  ..., -0.0036,  0.0031,  0.0512],\n",
       "         [-0.0072, -0.0227, -0.0408,  ..., -0.0317,  0.0818,  0.0219],\n",
       "         ...,\n",
       "         [ 0.0222, -0.0092,  0.0246,  ...,  0.0158, -0.0156, -0.0055],\n",
       "         [ 0.0036, -0.0408,  0.0097,  ...,  0.0454, -0.0275,  0.0217],\n",
       "         [-0.0108, -0.0153, -0.0182,  ...,  0.0346,  0.0080,  0.0429]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.self.key_proj.bias': tensor([ 0.0029, -0.0091, -0.0575,  ..., -0.0836,  0.0310,  0.0459],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.self.value_proj.weight': tensor([[ 0.0380,  0.0373,  0.0002,  ..., -0.0355,  0.0042,  0.0766],\n",
       "         [-0.0282, -0.0373, -0.0130,  ..., -0.0087,  0.0644, -0.0312],\n",
       "         [ 0.0040, -0.0255,  0.0449,  ...,  0.0397, -0.0497, -0.0749],\n",
       "         ...,\n",
       "         [-0.0441,  0.0381,  0.0662,  ...,  0.0404,  0.0209, -0.0253],\n",
       "         [ 0.0296,  0.0003, -0.0726,  ..., -0.0465, -0.0052,  0.0468],\n",
       "         [-0.0140,  0.0162,  0.0141,  ..., -0.0593,  0.0226,  0.0595]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.self.value_proj.bias': tensor([ 0.0101,  0.0087, -0.0050,  ...,  0.0102,  0.0251, -0.0120],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.output.dense.weight': tensor([[ 0.0183, -0.0019, -0.0354,  ..., -0.0602,  0.0215, -0.0226],\n",
       "         [ 0.0149,  0.0072, -0.0128,  ..., -0.0091,  0.0090,  0.0001],\n",
       "         [ 0.0098,  0.0004, -0.0203,  ...,  0.0007, -0.0268,  0.0387],\n",
       "         ...,\n",
       "         [-0.0189,  0.0243,  0.0014,  ...,  0.0739,  0.0336,  0.0229],\n",
       "         [ 0.0310, -0.0320, -0.0245,  ...,  0.0067, -0.0753, -0.0437],\n",
       "         [-0.0290, -0.0050, -0.0229,  ..., -0.0323,  0.0536,  0.0583]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.output.dense.bias': tensor([ 0.0147, -0.0540, -0.0191,  ...,  0.0271, -0.0284,  0.0028],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.output.LayerNorm.weight': tensor([0.8281, 0.9536, 0.8467,  ..., 0.7495, 0.7725, 0.7393],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.attention.output.LayerNorm.bias': tensor([-0.1954, -0.1136, -0.1223,  ..., -0.1046, -0.1193, -0.1143],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.intermediate.dense.weight': tensor([[ 0.0073,  0.0095,  0.0054,  ...,  0.0364,  0.0234,  0.0221],\n",
       "         [-0.0049, -0.0070,  0.0490,  ...,  0.0433, -0.0072,  0.0385],\n",
       "         [ 0.0309,  0.0023, -0.0346,  ...,  0.0121,  0.0142,  0.0045],\n",
       "         ...,\n",
       "         [ 0.0115,  0.0132, -0.0182,  ...,  0.0723,  0.0466,  0.0581],\n",
       "         [-0.0013,  0.0098, -0.0229,  ...,  0.0590, -0.0496,  0.0079],\n",
       "         [-0.0271,  0.0177, -0.0076,  ...,  0.0166, -0.0245,  0.0410]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.intermediate.dense.bias': tensor([-0.0260, -0.0307, -0.0522,  ..., -0.0508, -0.0347,  0.0010],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.output.dense.weight': tensor([[-0.0290, -0.0143, -0.0044,  ..., -0.0267,  0.0064, -0.0073],\n",
       "         [ 0.0063, -0.0019,  0.0125,  ...,  0.0121,  0.0063,  0.0201],\n",
       "         [-0.0094,  0.0170, -0.0348,  ..., -0.0291, -0.0065, -0.0167],\n",
       "         ...,\n",
       "         [-0.0297,  0.0050, -0.0002,  ...,  0.0613,  0.0422,  0.0247],\n",
       "         [ 0.0088,  0.0012,  0.0161,  ...,  0.0249, -0.0086,  0.0329],\n",
       "         [-0.0266, -0.0285,  0.0215,  ..., -0.0191, -0.0542,  0.0323]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.output.dense.bias': tensor([ 0.0027,  0.0402, -0.0986,  ...,  0.0113,  0.0186, -0.0007],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.output.LayerNorm.weight': tensor([1.0615, 1.0947, 1.1143,  ..., 1.0176, 1.0830, 1.0469],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.15.output.LayerNorm.bias': tensor([ 0.0107, -0.0713, -0.1007,  ..., -0.0332, -0.0252, -0.0527],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.self.query_proj.weight': tensor([[-0.0123,  0.0044, -0.0093,  ..., -0.0045,  0.0055,  0.0016],\n",
       "         [ 0.0305, -0.0204,  0.0117,  ..., -0.0309,  0.0022,  0.0324],\n",
       "         [-0.0297, -0.0560, -0.0087,  ...,  0.0157, -0.0171,  0.0045],\n",
       "         ...,\n",
       "         [-0.0160, -0.0168,  0.0359,  ..., -0.0086, -0.0102, -0.0582],\n",
       "         [ 0.0300, -0.0209, -0.0483,  ..., -0.0138,  0.0149,  0.0410],\n",
       "         [-0.0563, -0.0008, -0.0604,  ...,  0.0073,  0.0053, -0.0479]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.self.query_proj.bias': tensor([ 0.0211,  0.0125, -0.0054,  ...,  0.0414,  0.0731,  0.0907],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.self.key_proj.weight': tensor([[ 0.0329,  0.0128, -0.0025,  ...,  0.0023,  0.0047, -0.0218],\n",
       "         [-0.0312, -0.0172,  0.0057,  ...,  0.0273,  0.0537, -0.0626],\n",
       "         [ 0.0237,  0.0212,  0.0183,  ...,  0.0208, -0.0609,  0.0037],\n",
       "         ...,\n",
       "         [ 0.0053, -0.0186, -0.0316,  ...,  0.0021,  0.0323,  0.0512],\n",
       "         [ 0.0009, -0.0065, -0.0084,  ...,  0.0013, -0.0018,  0.0142],\n",
       "         [-0.0010, -0.0200, -0.0204,  ...,  0.0247, -0.0273,  0.0189]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.self.key_proj.bias': tensor([-0.0879,  0.0424, -0.0991,  ...,  0.0531,  0.0712,  0.0170],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.self.value_proj.weight': tensor([[ 0.0382,  0.0100,  0.0126,  ..., -0.0072,  0.0381, -0.0267],\n",
       "         [-0.0220,  0.0188, -0.0033,  ..., -0.0052, -0.0767,  0.0236],\n",
       "         [ 0.0276,  0.0134,  0.0069,  ..., -0.0154, -0.0165, -0.0062],\n",
       "         ...,\n",
       "         [ 0.0102, -0.0084, -0.0220,  ...,  0.0018, -0.0784,  0.0387],\n",
       "         [ 0.0040, -0.0355, -0.0165,  ..., -0.0186,  0.0405, -0.0531],\n",
       "         [ 0.0422,  0.0004,  0.0459,  ...,  0.0506,  0.0373,  0.0012]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.self.value_proj.bias': tensor([-0.0098, -0.0061, -0.0221,  ..., -0.0163,  0.0039,  0.0112],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.output.dense.weight': tensor([[-0.0084, -0.0309, -0.0110,  ...,  0.0535, -0.0486, -0.0091],\n",
       "         [ 0.0013, -0.0018, -0.0082,  ...,  0.0020, -0.0016,  0.0070],\n",
       "         [-0.0133, -0.0276,  0.0278,  ...,  0.0113, -0.0249, -0.0225],\n",
       "         ...,\n",
       "         [ 0.0337, -0.0737, -0.0207,  ..., -0.0271,  0.0129, -0.0632],\n",
       "         [ 0.0339, -0.0172,  0.0064,  ...,  0.0797, -0.0082, -0.0097],\n",
       "         [ 0.0673,  0.0014, -0.0084,  ..., -0.0939,  0.0302, -0.0282]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.output.dense.bias': tensor([ 0.0187, -0.1237, -0.0146,  ...,  0.0111, -0.0595,  0.0353],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.output.LayerNorm.weight': tensor([0.8140, 0.9893, 0.8423,  ..., 0.7227, 0.7329, 0.7437],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.attention.output.LayerNorm.bias': tensor([-0.1261, -0.1021, -0.2120,  ..., -0.0824, -0.1414, -0.0988],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.intermediate.dense.weight': tensor([[ 0.0108,  0.0846,  0.0303,  ...,  0.0339,  0.0254, -0.0145],\n",
       "         [-0.0207,  0.0094,  0.0200,  ...,  0.0241,  0.0305,  0.0164],\n",
       "         [-0.0218,  0.0299,  0.0728,  ...,  0.0106,  0.0132,  0.0528],\n",
       "         ...,\n",
       "         [ 0.0273,  0.0309,  0.0027,  ..., -0.0539, -0.0451,  0.0130],\n",
       "         [ 0.0387, -0.0134, -0.0644,  ..., -0.0272,  0.0247, -0.0006],\n",
       "         [-0.0453, -0.0115,  0.0559,  ..., -0.0432,  0.0351,  0.0677]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.intermediate.dense.bias': tensor([-0.0450, -0.0312, -0.0450,  ..., -0.0350, -0.0350, -0.0523],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.output.dense.weight': tensor([[ 4.0527e-02,  1.0956e-02, -2.9266e-02,  ..., -3.2623e-02,\n",
       "           1.8997e-02, -1.2366e-01],\n",
       "         [-4.4800e-02,  9.4833e-03,  2.9938e-02,  ..., -1.6617e-02,\n",
       "           1.0395e-04, -1.0933e-02],\n",
       "         [-2.4567e-02, -8.8120e-04,  3.3173e-02,  ..., -1.0193e-02,\n",
       "           3.1311e-02,  6.4514e-02],\n",
       "         ...,\n",
       "         [-4.2847e-02, -5.9395e-03,  2.7130e-02,  ...,  1.8280e-02,\n",
       "          -2.7954e-02, -3.5686e-03],\n",
       "         [-4.5868e-02, -2.3010e-02,  3.8357e-03,  ..., -1.6815e-02,\n",
       "           3.1464e-02,  4.5990e-02],\n",
       "         [ 6.8481e-02,  1.5312e-02,  2.4490e-03,  ...,  6.9458e-02,\n",
       "           1.3107e-02,  2.3392e-02]], dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.output.dense.bias': tensor([-0.0125,  0.0367, -0.0825,  ..., -0.0175,  0.0237,  0.0580],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.output.LayerNorm.weight': tensor([1.0947, 1.1172, 1.0840,  ..., 1.0303, 1.0635, 1.0547],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.16.output.LayerNorm.bias': tensor([-0.0222, -0.0745, -0.0394,  ..., -0.0628, -0.0245, -0.0529],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.self.query_proj.weight': tensor([[-0.0222, -0.0147,  0.0008,  ...,  0.0543,  0.0144, -0.0158],\n",
       "         [-0.0508,  0.0170, -0.0624,  ..., -0.0021, -0.1099, -0.0203],\n",
       "         [-0.0921, -0.0222, -0.0620,  ..., -0.0489, -0.0519, -0.0776],\n",
       "         ...,\n",
       "         [ 0.0632, -0.0179,  0.0318,  ..., -0.0358,  0.0684,  0.0140],\n",
       "         [ 0.0675, -0.0223, -0.0146,  ..., -0.0302,  0.0845,  0.0050],\n",
       "         [-0.0359, -0.0509, -0.0532,  ..., -0.0871,  0.0601, -0.0392]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.self.query_proj.bias': tensor([-0.0425,  0.0065,  0.0050,  ..., -0.0591,  0.0057,  0.0540],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.self.key_proj.weight': tensor([[ 0.0237, -0.0209,  0.0692,  ...,  0.0230,  0.0186,  0.0323],\n",
       "         [-0.0557, -0.0477, -0.0164,  ..., -0.0459,  0.0101,  0.0255],\n",
       "         [-0.0181, -0.0447,  0.0100,  ..., -0.0093,  0.0202, -0.0476],\n",
       "         ...,\n",
       "         [ 0.0302, -0.0269,  0.0008,  ..., -0.0162,  0.0249, -0.0037],\n",
       "         [ 0.0667,  0.0092,  0.0182,  ..., -0.0297,  0.0723,  0.0306],\n",
       "         [ 0.0060, -0.0589, -0.0459,  ..., -0.0582,  0.1020, -0.0131]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.self.key_proj.bias': tensor([-0.0855,  0.1440, -0.0641,  ...,  0.1164, -0.0392,  0.1870],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.self.value_proj.weight': tensor([[-0.0163, -0.0027, -0.0108,  ...,  0.0735, -0.0084, -0.0285],\n",
       "         [ 0.0430, -0.0012,  0.0089,  ...,  0.0018,  0.0107, -0.0094],\n",
       "         [-0.0176, -0.0120, -0.0097,  ...,  0.0293, -0.0548,  0.0145],\n",
       "         ...,\n",
       "         [-0.0307, -0.0089, -0.0030,  ...,  0.0568,  0.0067,  0.0430],\n",
       "         [-0.0123,  0.0053,  0.0050,  ...,  0.0170, -0.0460,  0.0424],\n",
       "         [-0.0306, -0.0062,  0.0135,  ..., -0.0416, -0.0033, -0.0174]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.self.value_proj.bias': tensor([-0.0075, -0.2056, -0.0106,  ...,  0.0030,  0.0223,  0.0040],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.output.dense.weight': tensor([[-0.0167,  0.0047,  0.0199,  ...,  0.0183, -0.0079,  0.0011],\n",
       "         [ 0.0038, -0.0029,  0.0046,  ..., -0.0095,  0.0125,  0.0060],\n",
       "         [ 0.0102, -0.0551, -0.0309,  ...,  0.0257, -0.0317, -0.0229],\n",
       "         ...,\n",
       "         [ 0.0187,  0.0077,  0.0310,  ..., -0.0270,  0.0142, -0.0591],\n",
       "         [-0.0018,  0.0176, -0.0374,  ..., -0.0001,  0.0204,  0.0223],\n",
       "         [ 0.0068,  0.0043, -0.0217,  ...,  0.0036,  0.0964,  0.0326]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.output.dense.bias': tensor([ 0.0121, -0.1049, -0.0934,  ..., -0.0239, -0.0158, -0.0578],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.output.LayerNorm.weight': tensor([0.7998, 1.0225, 0.8696,  ..., 0.7266, 0.7349, 0.7227],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.attention.output.LayerNorm.bias': tensor([-0.1346, -0.0871, -0.1832,  ..., -0.0914, -0.1049, -0.0652],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.intermediate.dense.weight': tensor([[ 0.0586,  0.0060, -0.0004,  ...,  0.0098,  0.0133, -0.0050],\n",
       "         [-0.0445, -0.0178,  0.0325,  ..., -0.0106, -0.0504, -0.0384],\n",
       "         [-0.0052, -0.0458,  0.0833,  ..., -0.0339,  0.0247, -0.0303],\n",
       "         ...,\n",
       "         [ 0.0515, -0.0196,  0.0375,  ...,  0.0322,  0.0363,  0.0366],\n",
       "         [-0.0461,  0.0038,  0.0105,  ...,  0.0202,  0.0014,  0.0157],\n",
       "         [ 0.0071, -0.0088,  0.0042,  ..., -0.0108,  0.0158,  0.0237]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.intermediate.dense.bias': tensor([-0.0144, -0.0299, -0.0649,  ..., -0.0361, -0.0310, -0.0097],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.output.dense.weight': tensor([[ 0.0166,  0.0554, -0.0518,  ...,  0.0229, -0.0211,  0.0047],\n",
       "         [ 0.0034, -0.0038,  0.0262,  ..., -0.0123,  0.0067,  0.0027],\n",
       "         [ 0.0115, -0.0147,  0.0047,  ...,  0.0057, -0.0152,  0.0360],\n",
       "         ...,\n",
       "         [ 0.0259,  0.0146,  0.0460,  ...,  0.0398,  0.0328,  0.0189],\n",
       "         [ 0.0184, -0.0203, -0.0593,  ...,  0.0497, -0.0035,  0.0021],\n",
       "         [ 0.0656, -0.0372, -0.0828,  ...,  0.0020, -0.0027, -0.0523]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.output.dense.bias': tensor([-0.0115,  0.0753, -0.1074,  ...,  0.0150, -0.0208,  0.0104],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.output.LayerNorm.weight': tensor([1.0537, 1.1582, 1.0742,  ..., 1.0156, 1.0420, 0.9980],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.17.output.LayerNorm.bias': tensor([ 0.0076, -0.0290,  0.0068,  ..., -0.0124, -0.0127, -0.0266],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.self.query_proj.weight': tensor([[ 0.0225, -0.0386, -0.0941,  ...,  0.0096, -0.0547,  0.0551],\n",
       "         [-0.0182,  0.0062,  0.0081,  ...,  0.0238,  0.0036,  0.0429],\n",
       "         [-0.1284,  0.0174, -0.0736,  ...,  0.0457, -0.1744, -0.0079],\n",
       "         ...,\n",
       "         [-0.0311,  0.0584,  0.0028,  ..., -0.0095,  0.0215,  0.0298],\n",
       "         [ 0.0337,  0.0195,  0.0335,  ..., -0.0273, -0.0344,  0.0116],\n",
       "         [ 0.0414, -0.0185,  0.0356,  ...,  0.0041,  0.0067,  0.0262]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.self.query_proj.bias': tensor([-0.0124, -0.0264,  0.0970,  ...,  0.0732, -0.1559, -0.1000],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.self.key_proj.weight': tensor([[ 0.0091, -0.0481, -0.0732,  ..., -0.0124,  0.0148,  0.0597],\n",
       "         [-0.0101, -0.0260,  0.0755,  ...,  0.0402,  0.0932,  0.0101],\n",
       "         [-0.0970, -0.0334, -0.0267,  ...,  0.0514, -0.0780, -0.0118],\n",
       "         ...,\n",
       "         [-0.0071, -0.0005, -0.0038,  ..., -0.0226,  0.0122,  0.0379],\n",
       "         [-0.0406, -0.0066, -0.0237,  ..., -0.0591, -0.0166,  0.0056],\n",
       "         [ 0.0110, -0.0459, -0.0928,  ...,  0.0124, -0.0795,  0.0682]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.self.key_proj.bias': tensor([-0.4563, -0.0076, -0.3567,  ...,  0.1431, -0.1141, -0.0393],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.self.value_proj.weight': tensor([[ 0.0351,  0.0299,  0.0312,  ..., -0.0293,  0.0218,  0.0260],\n",
       "         [ 0.0245, -0.0088, -0.0161,  ..., -0.0369, -0.0544, -0.0958],\n",
       "         [-0.0121,  0.0224,  0.0191,  ..., -0.0247, -0.0277,  0.0135],\n",
       "         ...,\n",
       "         [-0.0530,  0.0231, -0.0398,  ...,  0.0019, -0.0382, -0.0020],\n",
       "         [-0.0015,  0.0270, -0.0420,  ..., -0.0055, -0.0422, -0.0272],\n",
       "         [-0.0021, -0.0162, -0.0057,  ...,  0.0287, -0.0476,  0.0073]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.self.value_proj.bias': tensor([-0.0215,  0.0054, -0.0072,  ...,  0.0040, -0.0012,  0.0111],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.output.dense.weight': tensor([[ 7.3242e-03, -2.5970e-02, -2.2247e-02,  ...,  1.2650e-02,\n",
       "           2.7451e-02,  2.1133e-02],\n",
       "         [-8.4991e-03,  7.9422e-03,  5.1956e-03,  ..., -1.3390e-02,\n",
       "          -5.1727e-03,  2.6398e-02],\n",
       "         [-3.6025e-04,  4.9744e-03, -7.3700e-03,  ...,  4.5258e-02,\n",
       "          -6.4240e-03, -3.0609e-02],\n",
       "         ...,\n",
       "         [-7.9651e-02, -1.5617e-02,  2.1591e-03,  ..., -1.8890e-02,\n",
       "          -3.9917e-02,  4.0665e-03],\n",
       "         [ 2.3331e-02, -1.6510e-02,  1.5087e-03,  ..., -4.7760e-02,\n",
       "           3.7964e-02,  5.1453e-02],\n",
       "         [-2.9449e-02, -1.9897e-02, -3.2444e-03,  ..., -9.8825e-05,\n",
       "           2.4918e-02,  1.5556e-02]], dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.output.dense.bias': tensor([ 0.0441, -0.0443,  0.0031,  ..., -0.0177, -0.0267,  0.0475],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.output.LayerNorm.weight': tensor([0.8008, 1.0283, 0.8711,  ..., 0.6909, 0.7485, 0.7178],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.attention.output.LayerNorm.bias': tensor([-0.1191, -0.0670, -0.2030,  ...,  0.0028, -0.0952, -0.0524],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.intermediate.dense.weight': tensor([[ 4.3457e-02,  9.5673e-03, -4.3793e-02,  ...,  1.6830e-02,\n",
       "          -2.5146e-02, -7.9651e-02],\n",
       "         [-1.6129e-02,  8.0261e-03,  1.9745e-02,  ..., -3.5736e-02,\n",
       "          -3.0548e-02,  5.0873e-02],\n",
       "         [ 6.1218e-02, -7.7286e-03,  3.7537e-02,  ..., -6.6467e-02,\n",
       "           1.3962e-02, -8.6288e-03],\n",
       "         ...,\n",
       "         [-1.7703e-05,  1.4961e-02,  3.1738e-03,  ...,  1.1009e-02,\n",
       "           2.0844e-02,  2.7908e-02],\n",
       "         [ 2.0996e-02,  2.1439e-02, -2.9083e-02,  ..., -1.3344e-02,\n",
       "           1.4641e-02,  2.5726e-02],\n",
       "         [ 7.4615e-03, -1.8600e-02,  4.9988e-02,  ..., -2.8687e-02,\n",
       "          -4.6539e-02, -7.4425e-03]], dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.intermediate.dense.bias': tensor([ 0.0301,  0.0053,  0.0056,  ..., -0.0584, -0.0326, -0.0397],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.output.dense.weight': tensor([[-0.0522,  0.0009, -0.0541,  ..., -0.0110, -0.0099, -0.0300],\n",
       "         [-0.0266, -0.0188, -0.0009,  ...,  0.0210, -0.0300,  0.0054],\n",
       "         [ 0.0309,  0.0056, -0.0330,  ..., -0.0255,  0.0254,  0.0411],\n",
       "         ...,\n",
       "         [-0.0080,  0.0050, -0.0121,  ..., -0.0139,  0.0262,  0.0064],\n",
       "         [ 0.0128,  0.0077,  0.0187,  ..., -0.0126,  0.0145, -0.0031],\n",
       "         [ 0.1053, -0.0410,  0.0158,  ...,  0.0242, -0.0335, -0.0196]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.output.dense.bias': tensor([ 0.0116,  0.0546, -0.0464,  ..., -0.0009,  0.0788, -0.0172],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.output.LayerNorm.weight': tensor([1.0400, 1.1562, 1.0342,  ..., 0.9551, 0.9873, 0.9707],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.18.output.LayerNorm.bias': tensor([ 0.0112, -0.0215,  0.0284,  ..., -0.0367,  0.0001, -0.0351],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.self.query_proj.weight': tensor([[ 0.0944, -0.0097, -0.0201,  ...,  0.0508, -0.0031, -0.0327],\n",
       "         [-0.0105, -0.0094, -0.0157,  ..., -0.0501,  0.0305, -0.0388],\n",
       "         [ 0.0455,  0.0141, -0.0085,  ..., -0.0859, -0.0854, -0.0238],\n",
       "         ...,\n",
       "         [ 0.0133,  0.0107, -0.0346,  ...,  0.0311,  0.0030,  0.0441],\n",
       "         [-0.0693, -0.0414,  0.0135,  ..., -0.0360,  0.0844,  0.0324],\n",
       "         [ 0.0116,  0.0201,  0.0204,  ...,  0.0611,  0.0121,  0.0095]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.self.query_proj.bias': tensor([ 0.0182,  0.0989,  0.0500,  ...,  0.0186, -0.0095,  0.0175],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.self.key_proj.weight': tensor([[-0.0706, -0.0254,  0.0025,  ...,  0.0683,  0.0096,  0.0065],\n",
       "         [-0.0310, -0.0079, -0.0271,  ..., -0.0281, -0.0172,  0.0230],\n",
       "         [ 0.0072,  0.0684,  0.0104,  ..., -0.0009, -0.0326, -0.0424],\n",
       "         ...,\n",
       "         [-0.0629,  0.0602, -0.0165,  ...,  0.0031, -0.0129,  0.0544],\n",
       "         [ 0.0713, -0.0049, -0.0276,  ..., -0.0468,  0.0724, -0.0371],\n",
       "         [-0.0216,  0.0374,  0.0053,  ...,  0.1245,  0.0293,  0.0334]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.self.key_proj.bias': tensor([-0.0123,  0.2534, -0.0107,  ..., -0.1381,  0.1100,  0.0673],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.self.value_proj.weight': tensor([[ 0.0293, -0.0087, -0.0502,  ..., -0.0081, -0.0216,  0.0077],\n",
       "         [ 0.0114,  0.0061,  0.0019,  ..., -0.0275,  0.0227,  0.0007],\n",
       "         [-0.0332,  0.0016, -0.0239,  ...,  0.0367, -0.0081, -0.0187],\n",
       "         ...,\n",
       "         [-0.0507,  0.0097, -0.0049,  ..., -0.0287, -0.0045,  0.0355],\n",
       "         [-0.0072, -0.0143, -0.0041,  ...,  0.0974, -0.0241, -0.0022],\n",
       "         [ 0.0471,  0.0007, -0.0066,  ..., -0.0186,  0.0281, -0.0169]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.self.value_proj.bias': tensor([-0.0185,  0.0077,  0.0047,  ...,  0.0055,  0.0161,  0.0134],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.output.dense.weight': tensor([[ 0.0255, -0.0011, -0.0126,  ...,  0.0105, -0.0155, -0.0063],\n",
       "         [-0.0030, -0.0074, -0.0135,  ..., -0.0038, -0.0103, -0.0108],\n",
       "         [-0.0030, -0.0064,  0.0163,  ..., -0.0130,  0.0213, -0.0282],\n",
       "         ...,\n",
       "         [-0.0167, -0.0113,  0.0206,  ..., -0.0471, -0.0468, -0.0601],\n",
       "         [ 0.0078,  0.0015,  0.0134,  ..., -0.0239, -0.0295,  0.0379],\n",
       "         [-0.0059, -0.0341,  0.0032,  ..., -0.0124,  0.0114, -0.0415]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.output.dense.bias': tensor([ 0.0107, -0.0101, -0.0062,  ..., -0.0359, -0.0387,  0.0125],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.output.LayerNorm.weight': tensor([0.7822, 0.9805, 0.8496,  ..., 0.7280, 0.7412, 0.6968],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.attention.output.LayerNorm.bias': tensor([-0.1619, -0.0662, -0.2164,  ..., -0.0332, -0.0277, -0.0750],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.intermediate.dense.weight': tensor([[-0.0171,  0.0192,  0.0147,  ...,  0.0534,  0.0194,  0.0439],\n",
       "         [ 0.0296, -0.0298,  0.0431,  ..., -0.0243, -0.0266, -0.0453],\n",
       "         [ 0.0150,  0.0293,  0.0241,  ..., -0.0189, -0.0286,  0.0040],\n",
       "         ...,\n",
       "         [-0.0554,  0.0273,  0.0049,  ...,  0.0152, -0.0394,  0.0348],\n",
       "         [ 0.0032, -0.0152, -0.0318,  ..., -0.0529, -0.0163,  0.0283],\n",
       "         [ 0.0194,  0.0219, -0.0035,  ...,  0.0384,  0.0362, -0.0348]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.intermediate.dense.bias': tensor([-0.0271, -0.0394, -0.0496,  ..., -0.0198, -0.0055, -0.0188],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.output.dense.weight': tensor([[ 0.0350,  0.0266, -0.0030,  ..., -0.0097, -0.0341,  0.0385],\n",
       "         [ 0.0055, -0.0458,  0.0481,  ...,  0.0135,  0.0108,  0.0015],\n",
       "         [ 0.0174,  0.0358, -0.0607,  ..., -0.0021,  0.0234, -0.0042],\n",
       "         ...,\n",
       "         [-0.0572,  0.0181, -0.0251,  ..., -0.0298, -0.0310, -0.0352],\n",
       "         [-0.0440, -0.0219,  0.0367,  ...,  0.0607, -0.0143, -0.0362],\n",
       "         [ 0.0239,  0.0336,  0.0657,  ...,  0.0103,  0.0136,  0.0262]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.output.dense.bias': tensor([-0.0304,  0.0161, -0.0646,  ...,  0.0109,  0.0884, -0.0076],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.output.LayerNorm.weight': tensor([1.0547, 1.1367, 1.0400,  ..., 1.0176, 1.0312, 0.9863],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.19.output.LayerNorm.bias': tensor([ 0.0210, -0.0314,  0.0606,  ..., -0.0404, -0.0323, -0.0367],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.self.query_proj.weight': tensor([[-0.0209, -0.0156,  0.0504,  ...,  0.0454, -0.0110,  0.0771],\n",
       "         [ 0.0092,  0.0718,  0.0450,  ...,  0.0016,  0.0201,  0.0341],\n",
       "         [ 0.0284, -0.0481, -0.0271,  ..., -0.0510,  0.0526,  0.0065],\n",
       "         ...,\n",
       "         [ 0.0064,  0.0010,  0.0714,  ...,  0.0840,  0.0027, -0.0283],\n",
       "         [-0.0382, -0.0367,  0.0735,  ...,  0.0092, -0.0361,  0.0017],\n",
       "         [-0.0327, -0.0499, -0.0546,  ..., -0.0267, -0.0782,  0.0105]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.self.query_proj.bias': tensor([-0.0846, -0.1091,  0.1738,  ...,  0.0411,  0.0382,  0.0468],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.self.key_proj.weight': tensor([[-0.0164, -0.0021, -0.0054,  ...,  0.0635, -0.0263,  0.0388],\n",
       "         [ 0.0321,  0.0213, -0.0246,  ...,  0.0730, -0.0467,  0.0715],\n",
       "         [-0.0023,  0.0261,  0.0222,  ..., -0.0492,  0.0378,  0.0469],\n",
       "         ...,\n",
       "         [ 0.0135, -0.0177, -0.0512,  ..., -0.0531,  0.0204,  0.0237],\n",
       "         [-0.0469,  0.0101,  0.0381,  ...,  0.0880, -0.0515, -0.0072],\n",
       "         [ 0.0461, -0.0144, -0.0008,  ...,  0.0611, -0.0236,  0.0417]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.self.key_proj.bias': tensor([-0.4241,  0.0323,  0.0648,  ...,  0.0602,  0.1956,  0.0384],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.self.value_proj.weight': tensor([[ 0.0569,  0.0298, -0.0665,  ..., -0.0179,  0.0253,  0.0075],\n",
       "         [-0.1047, -0.0461, -0.0293,  ..., -0.0710, -0.0110, -0.0978],\n",
       "         [-0.0156, -0.0759,  0.0352,  ...,  0.0118, -0.0148, -0.0284],\n",
       "         ...,\n",
       "         [ 0.0063,  0.0039, -0.0163,  ..., -0.0426,  0.0446, -0.0651],\n",
       "         [ 0.0129, -0.0530,  0.0256,  ...,  0.0238,  0.0058, -0.0236],\n",
       "         [ 0.0424, -0.0071,  0.0395,  ..., -0.0203, -0.0072,  0.0028]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.self.value_proj.bias': tensor([-0.0042,  0.0106, -0.0025,  ...,  0.0051, -0.0031,  0.0240],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.output.dense.weight': tensor([[ 0.0787, -0.0304,  0.0246,  ...,  0.0047,  0.0242, -0.0294],\n",
       "         [-0.0040, -0.0046,  0.0137,  ..., -0.0071,  0.0152, -0.0116],\n",
       "         [ 0.0051,  0.0232, -0.0240,  ..., -0.0403,  0.0158,  0.0076],\n",
       "         ...,\n",
       "         [ 0.0104, -0.0223, -0.0020,  ..., -0.0060, -0.0166, -0.0135],\n",
       "         [ 0.0186,  0.0217, -0.0356,  ...,  0.0333,  0.0147,  0.0079],\n",
       "         [-0.0037, -0.0064,  0.0109,  ..., -0.0078,  0.0146, -0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.output.dense.bias': tensor([ 0.0962, -0.0120,  0.1031,  ..., -0.0334,  0.0233,  0.0363],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.output.LayerNorm.weight': tensor([0.7544, 0.9380, 0.7988,  ..., 0.6904, 0.7183, 0.6709],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.attention.output.LayerNorm.bias': tensor([-0.1488, -0.0327, -0.2009,  ..., -0.0177, -0.0212, -0.0486],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.intermediate.dense.weight': tensor([[-0.0151,  0.0230, -0.0025,  ...,  0.0034, -0.0102,  0.0257],\n",
       "         [ 0.0227, -0.0279,  0.0198,  ...,  0.0089,  0.1035,  0.0318],\n",
       "         [ 0.0375, -0.0162,  0.0447,  ...,  0.0848,  0.0412,  0.0276],\n",
       "         ...,\n",
       "         [ 0.0323,  0.0285,  0.0005,  ..., -0.0233, -0.0166, -0.0231],\n",
       "         [ 0.0910, -0.0026,  0.0043,  ..., -0.0237, -0.0192,  0.0073],\n",
       "         [ 0.0399,  0.0376,  0.0201,  ..., -0.0900,  0.0461,  0.1030]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.intermediate.dense.bias': tensor([-0.0115, -0.0503, -0.0473,  ..., -0.0307, -0.0276, -0.0327],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.output.dense.weight': tensor([[-0.0527, -0.1250, -0.0227,  ..., -0.0305,  0.0166,  0.0138],\n",
       "         [-0.0106, -0.0242, -0.0423,  ...,  0.0445,  0.0019,  0.0003],\n",
       "         [-0.0363,  0.0449, -0.0171,  ..., -0.0381,  0.0227,  0.0043],\n",
       "         ...,\n",
       "         [ 0.0184,  0.0193,  0.0426,  ..., -0.0375,  0.0564,  0.0588],\n",
       "         [-0.0029,  0.0372, -0.0237,  ..., -0.0293, -0.0112, -0.0172],\n",
       "         [ 0.0020, -0.0084, -0.0808,  ...,  0.0310,  0.0398,  0.0075]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.output.dense.bias': tensor([-0.0480, -0.0475, -0.0258,  ..., -0.0082,  0.0780, -0.0143],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.output.LayerNorm.weight': tensor([1.1172, 1.1963, 1.0752,  ..., 1.0361, 1.0684, 1.0029],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.20.output.LayerNorm.bias': tensor([-0.0089, -0.0941,  0.0604,  ..., -0.0822, -0.0434, -0.0482],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.self.query_proj.weight': tensor([[-0.0652,  0.0394, -0.0128,  ...,  0.0428,  0.0376,  0.0635],\n",
       "         [ 0.0076,  0.0064,  0.0296,  ...,  0.0443,  0.0266,  0.0363],\n",
       "         [-0.0021, -0.0118, -0.0040,  ...,  0.0361,  0.0331,  0.0330],\n",
       "         ...,\n",
       "         [-0.0284,  0.0245,  0.0119,  ...,  0.0353, -0.0095, -0.0480],\n",
       "         [ 0.0508, -0.0478, -0.0220,  ..., -0.0363, -0.0822, -0.0558],\n",
       "         [ 0.0193,  0.0951, -0.0365,  ..., -0.0688,  0.0163, -0.0065]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.self.query_proj.bias': tensor([-0.0681, -0.1240, -0.1208,  ..., -0.0022,  0.0100,  0.1549],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.self.key_proj.weight': tensor([[ 0.0030, -0.0610, -0.0472,  ..., -0.0075, -0.0184, -0.0086],\n",
       "         [ 0.0245, -0.0168, -0.0171,  ...,  0.0349,  0.0093,  0.0074],\n",
       "         [ 0.0013, -0.0085, -0.0040,  ..., -0.0767,  0.0145,  0.0428],\n",
       "         ...,\n",
       "         [ 0.0183,  0.0340, -0.0117,  ...,  0.0515, -0.0095, -0.0365],\n",
       "         [ 0.0414, -0.0844,  0.0022,  ...,  0.0068, -0.0595, -0.0104],\n",
       "         [ 0.0671,  0.0914,  0.0001,  ..., -0.0105, -0.0087,  0.0057]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.self.key_proj.bias': tensor([-0.0373,  0.0334, -0.0261,  ...,  0.1658, -0.0947, -0.3176],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.self.value_proj.weight': tensor([[ 0.0400, -0.0757,  0.0410,  ...,  0.0037, -0.0346,  0.0765],\n",
       "         [-0.0007, -0.0014,  0.0171,  ...,  0.0382,  0.0372,  0.0160],\n",
       "         [ 0.0211,  0.0600, -0.0493,  ..., -0.0493,  0.0298,  0.0468],\n",
       "         ...,\n",
       "         [-0.0208, -0.0020, -0.0020,  ...,  0.0477,  0.0299, -0.0629],\n",
       "         [ 0.0311,  0.0163,  0.0253,  ..., -0.0080, -0.0294, -0.0131],\n",
       "         [ 0.0191, -0.0014,  0.0002,  ..., -0.0267,  0.0018, -0.0154]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.self.value_proj.bias': tensor([ 0.0009, -0.0008, -0.0008,  ...,  0.0058, -0.0109, -0.0071],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.output.dense.weight': tensor([[ 0.0095, -0.0219,  0.0021,  ..., -0.0069, -0.0314,  0.0284],\n",
       "         [ 0.0110, -0.0170, -0.0066,  ..., -0.0190,  0.0084,  0.0016],\n",
       "         [-0.0212, -0.0310,  0.0756,  ..., -0.0184,  0.0453,  0.0057],\n",
       "         ...,\n",
       "         [-0.0168, -0.0381,  0.0256,  ...,  0.0004, -0.0103, -0.0144],\n",
       "         [-0.0067, -0.0293, -0.0555,  ..., -0.0075,  0.0556,  0.0562],\n",
       "         [-0.0167, -0.0135, -0.0054,  ...,  0.0189, -0.0160,  0.0086]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.output.dense.bias': tensor([ 0.0560,  0.0645,  0.0635,  ..., -0.0070, -0.0022, -0.0435],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.output.LayerNorm.weight': tensor([0.7598, 0.9014, 0.7627,  ..., 0.7085, 0.7109, 0.7041],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.attention.output.LayerNorm.bias': tensor([-0.2084, -0.0414, -0.1310,  ..., -0.0284, -0.0110, -0.0099],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.intermediate.dense.weight': tensor([[ 0.0113,  0.0446,  0.0074,  ...,  0.0364, -0.0143, -0.0312],\n",
       "         [-0.0035, -0.0075,  0.0090,  ...,  0.0191, -0.0191, -0.0117],\n",
       "         [-0.0077,  0.0155,  0.0155,  ..., -0.0779, -0.0084,  0.1115],\n",
       "         ...,\n",
       "         [-0.0373,  0.0120,  0.0177,  ..., -0.0062,  0.0466,  0.0156],\n",
       "         [-0.0283, -0.0213, -0.0223,  ...,  0.0570, -0.0204,  0.0253],\n",
       "         [ 0.0232, -0.0546,  0.0029,  ..., -0.0232, -0.0065, -0.0195]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.intermediate.dense.bias': tensor([-0.0390, -0.0133, -0.0362,  ..., -0.0194, -0.0064, -0.0475],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.output.dense.weight': tensor([[-0.0551, -0.0158,  0.0326,  ..., -0.0178, -0.0025, -0.1087],\n",
       "         [-0.0238,  0.0107, -0.0070,  ...,  0.0311,  0.0074,  0.0064],\n",
       "         [-0.0169,  0.0446, -0.0367,  ...,  0.0500,  0.0136, -0.0100],\n",
       "         ...,\n",
       "         [ 0.0050, -0.0199, -0.0057,  ...,  0.0519,  0.0058, -0.0346],\n",
       "         [-0.0263, -0.0127,  0.0839,  ...,  0.0137,  0.0042,  0.0569],\n",
       "         [-0.0612,  0.0186,  0.0861,  ...,  0.0119, -0.0519, -0.0190]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.output.dense.bias': tensor([-0.0238, -0.0827, -0.0128,  ...,  0.0229,  0.0236, -0.0058],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.output.LayerNorm.weight': tensor([1.0068, 1.1406, 1.0293,  ..., 1.0547, 1.0488, 1.0361],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.21.output.LayerNorm.bias': tensor([ 0.0894, -0.0504,  0.1051,  ..., -0.0120, -0.0415, -0.0273],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.self.query_proj.weight': tensor([[ 0.0034, -0.0635, -0.0069,  ...,  0.0169, -0.0436, -0.0299],\n",
       "         [-0.0410,  0.0458, -0.0747,  ..., -0.0012, -0.0055, -0.0795],\n",
       "         [-0.0323,  0.0273, -0.0013,  ..., -0.0134, -0.0251, -0.0782],\n",
       "         ...,\n",
       "         [ 0.0417, -0.0049, -0.0379,  ...,  0.0300,  0.0091, -0.0322],\n",
       "         [ 0.0169,  0.0383, -0.0766,  ..., -0.0231, -0.0018, -0.0023],\n",
       "         [ 0.0222, -0.0206,  0.0514,  ...,  0.1168, -0.0771, -0.0057]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.self.query_proj.bias': tensor([-0.0010,  0.0368,  0.0492,  ...,  0.0119,  0.0007,  0.0204],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.self.key_proj.weight': tensor([[-0.0162, -0.0634,  0.0013,  ...,  0.0101,  0.0105, -0.0322],\n",
       "         [-0.0155,  0.0055, -0.0916,  ..., -0.0110, -0.0232, -0.0755],\n",
       "         [-0.0009,  0.0381, -0.0282,  ..., -0.0074, -0.0290, -0.0480],\n",
       "         ...,\n",
       "         [ 0.0508,  0.0423,  0.0376,  ...,  0.0185, -0.0191,  0.0043],\n",
       "         [ 0.0005, -0.0327,  0.0142,  ..., -0.0041,  0.0689, -0.0589],\n",
       "         [-0.0146,  0.0280, -0.0592,  ..., -0.0837, -0.0698, -0.0988]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.self.key_proj.bias': tensor([-0.0978, -0.1376, -0.3979,  ..., -0.0461,  0.0149,  0.2046],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.self.value_proj.weight': tensor([[ 0.0015,  0.0132, -0.0076,  ..., -0.0790,  0.0053,  0.0050],\n",
       "         [ 0.0402, -0.0211, -0.0197,  ..., -0.0576,  0.0261, -0.0231],\n",
       "         [ 0.0251,  0.0320,  0.0177,  ..., -0.0130, -0.0315, -0.1194],\n",
       "         ...,\n",
       "         [ 0.0063,  0.0030, -0.0105,  ...,  0.0159,  0.0050, -0.0454],\n",
       "         [ 0.0101, -0.0230,  0.0342,  ...,  0.0636, -0.0135, -0.0516],\n",
       "         [-0.0045, -0.0116, -0.0519,  ...,  0.0167, -0.0319, -0.0425]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.self.value_proj.bias': tensor([-0.0088,  0.0016,  0.0192,  ...,  0.0015, -0.0056, -0.0066],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.output.dense.weight': tensor([[-0.0635, -0.0379,  0.0458,  ..., -0.0049, -0.0211, -0.0828],\n",
       "         [-0.0612,  0.0378,  0.0077,  ...,  0.0004, -0.0049, -0.0186],\n",
       "         [-0.0041, -0.0440, -0.0073,  ...,  0.0169,  0.0345,  0.0652],\n",
       "         ...,\n",
       "         [-0.0041,  0.0242,  0.0279,  ...,  0.0634, -0.0138,  0.0097],\n",
       "         [ 0.0335,  0.0267, -0.0312,  ..., -0.0145,  0.0388,  0.0054],\n",
       "         [-0.0490,  0.0206, -0.0358,  ..., -0.0135, -0.0502,  0.0027]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.output.dense.bias': tensor([ 0.0569,  0.0794,  0.0343,  ...,  0.0073, -0.0340, -0.0278],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.output.LayerNorm.weight': tensor([0.7158, 0.8252, 0.6948,  ..., 0.7036, 0.7061, 0.6724],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.attention.output.LayerNorm.bias': tensor([-0.1222, -0.1412, -0.0417,  ...,  0.0599, -0.1029,  0.0988],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.intermediate.dense.weight': tensor([[ 0.0425, -0.0109,  0.0508,  ...,  0.0139, -0.0750,  0.0719],\n",
       "         [ 0.0201,  0.0123,  0.0339,  ..., -0.0311, -0.0302,  0.0392],\n",
       "         [-0.0193, -0.0299, -0.0536,  ..., -0.0087,  0.0657,  0.0443],\n",
       "         ...,\n",
       "         [ 0.0456,  0.0574, -0.0153,  ..., -0.0567,  0.0138,  0.0195],\n",
       "         [ 0.0254,  0.0086, -0.0043,  ...,  0.0046,  0.0378,  0.0397],\n",
       "         [-0.0278,  0.0072, -0.0187,  ..., -0.0494,  0.0023,  0.0245]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.intermediate.dense.bias': tensor([-0.0221, -0.0262, -0.0447,  ..., -0.0496, -0.0002, -0.0093],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.output.dense.weight': tensor([[ 0.0235,  0.0583,  0.0367,  ..., -0.0184,  0.0187,  0.0483],\n",
       "         [-0.0377,  0.0157, -0.0042,  ..., -0.0225, -0.0242, -0.0004],\n",
       "         [ 0.0517, -0.0388,  0.0473,  ..., -0.0097,  0.0331,  0.0089],\n",
       "         ...,\n",
       "         [ 0.0916,  0.0444, -0.0398,  ...,  0.0097,  0.0110, -0.0093],\n",
       "         [ 0.0101, -0.0358,  0.0038,  ..., -0.0146, -0.0249, -0.0108],\n",
       "         [ 0.0313, -0.0437, -0.0846,  ...,  0.0040, -0.0397, -0.0189]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.output.dense.bias': tensor([ 0.0155, -0.0951, -0.0121,  ...,  0.0545, -0.0190,  0.0164],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.output.LayerNorm.weight': tensor([0.9692, 1.1357, 0.9556,  ..., 1.0576, 1.0469, 0.9438],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.22.output.LayerNorm.bias': tensor([ 0.0509, -0.1152,  0.0260,  ..., -0.0720, -0.0198, -0.1013],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.self.query_proj.weight': tensor([[-0.0701,  0.0025,  0.0601,  ...,  0.0711,  0.0688, -0.0265],\n",
       "         [ 0.0693,  0.0007, -0.0739,  ..., -0.0077,  0.0243, -0.0400],\n",
       "         [ 0.0251,  0.0174,  0.0643,  ..., -0.0057, -0.0266, -0.0390],\n",
       "         ...,\n",
       "         [-0.0045,  0.0396,  0.0051,  ...,  0.0438,  0.0508, -0.0301],\n",
       "         [ 0.1064,  0.0089, -0.0020,  ...,  0.0976, -0.0309,  0.0419],\n",
       "         [-0.0121,  0.0637,  0.0188,  ..., -0.0417, -0.0446, -0.0378]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.self.query_proj.bias': tensor([ 0.0195,  0.0608,  0.0032,  ..., -0.0428, -0.0088,  0.0120],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.self.key_proj.weight': tensor([[ 0.0137,  0.0422, -0.0131,  ..., -0.0460, -0.0012,  0.0306],\n",
       "         [-0.0553, -0.0144,  0.0264,  ...,  0.0159, -0.0522,  0.0728],\n",
       "         [ 0.0062,  0.0410, -0.0261,  ...,  0.0118, -0.0151, -0.0065],\n",
       "         ...,\n",
       "         [-0.0170,  0.0381,  0.0165,  ..., -0.0220,  0.0192, -0.0698],\n",
       "         [-0.0151, -0.0374, -0.0080,  ..., -0.0164, -0.0439,  0.0159],\n",
       "         [-0.0327, -0.0564, -0.0358,  ..., -0.0045,  0.0272, -0.0045]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.self.key_proj.bias': tensor([ 0.3132,  0.2605, -0.1482,  ..., -0.3008, -0.0075, -0.3740],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.self.value_proj.weight': tensor([[-0.0079,  0.0162, -0.0057,  ..., -0.0159,  0.0063,  0.0722],\n",
       "         [ 0.0577, -0.0089,  0.0422,  ...,  0.0159,  0.0497,  0.0119],\n",
       "         [ 0.0297,  0.0177,  0.0153,  ..., -0.0068, -0.0067, -0.0579],\n",
       "         ...,\n",
       "         [ 0.0005,  0.0047,  0.0454,  ..., -0.0068, -0.0372, -0.0028],\n",
       "         [ 0.0017, -0.0225,  0.0149,  ..., -0.0226, -0.0252,  0.0093],\n",
       "         [ 0.0231, -0.0031,  0.0092,  ..., -0.0213, -0.0436, -0.0964]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.self.value_proj.bias': tensor([-2.9999e-02, -5.9090e-03,  4.8161e-05,  ...,  2.5387e-03,\n",
       "          1.2732e-01,  2.7283e-02], dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.output.dense.weight': tensor([[-0.0238,  0.0007,  0.0312,  ...,  0.0109, -0.0606,  0.0107],\n",
       "         [ 0.0161, -0.0160, -0.0032,  ..., -0.0041, -0.0028, -0.0043],\n",
       "         [-0.0199,  0.0407,  0.0424,  ...,  0.0594, -0.0445, -0.0040],\n",
       "         ...,\n",
       "         [ 0.0106, -0.0060, -0.0029,  ..., -0.0145,  0.0162, -0.0056],\n",
       "         [ 0.0019,  0.0043, -0.0070,  ..., -0.0182,  0.0039,  0.0002],\n",
       "         [ 0.0015, -0.0195, -0.0090,  ...,  0.0341,  0.0235,  0.0332]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.output.dense.bias': tensor([ 0.0015,  0.0289, -0.0671,  ...,  0.0304,  0.0510, -0.0994],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.output.LayerNorm.weight': tensor([0.6865, 0.7847, 0.6899,  ..., 0.7690, 0.7251, 0.6543],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.attention.output.LayerNorm.bias': tensor([-0.1484, -0.2372,  0.1497,  ...,  0.0682, -0.1642,  0.0923],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.intermediate.dense.weight': tensor([[-0.0159, -0.0024,  0.0052,  ...,  0.0248,  0.0193, -0.0123],\n",
       "         [ 0.0175,  0.0621,  0.0351,  ...,  0.0502, -0.0490,  0.0509],\n",
       "         [-0.0098, -0.0078, -0.0265,  ..., -0.0321, -0.0084,  0.0074],\n",
       "         ...,\n",
       "         [ 0.0111,  0.0193,  0.0027,  ..., -0.0025,  0.0220,  0.0054],\n",
       "         [-0.0202,  0.0135, -0.0261,  ...,  0.0331,  0.0895,  0.0348],\n",
       "         [-0.0540, -0.0032,  0.0371,  ...,  0.0413, -0.0085, -0.0110]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.intermediate.dense.bias': tensor([-0.0224, -0.0436,  0.0049,  ..., -0.2482,  0.0039, -0.0044],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.output.dense.weight': tensor([[ 0.0030,  0.0809, -0.0579,  ..., -0.0087,  0.0143,  0.0125],\n",
       "         [ 0.0156,  0.2080, -0.0340,  ...,  0.0049, -0.0248, -0.0123],\n",
       "         [ 0.0140, -0.0212,  0.0494,  ...,  0.0042,  0.0018, -0.0349],\n",
       "         ...,\n",
       "         [-0.0259,  0.0007, -0.0065,  ..., -0.0224,  0.0472,  0.0327],\n",
       "         [ 0.0085, -0.0289, -0.0412,  ...,  0.0355, -0.0234,  0.0271],\n",
       "         [-0.0706,  0.0134,  0.0032,  ..., -0.0089,  0.0101,  0.0181]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.output.dense.bias': tensor([ 0.0029, -0.0518,  0.0048,  ...,  0.0057, -0.0548,  0.0058],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.output.LayerNorm.weight': tensor([0.9321, 0.9365, 1.0361,  ..., 0.9146, 0.8022, 0.9419],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.layer.23.output.LayerNorm.bias': tensor([ 0.0717, -0.0412,  0.0081,  ..., -0.0154,  0.0520, -0.0150],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.rel_embeddings.weight': tensor([[-0.0002,  0.0009, -0.0008,  ..., -0.0001, -0.0003, -0.0007],\n",
       "         [-0.0665,  0.0164,  0.0274,  ...,  0.0143,  0.0118, -0.0126],\n",
       "         [-0.0291,  0.0205,  0.0170,  ...,  0.0097,  0.0320, -0.0127],\n",
       "         ...,\n",
       "         [-0.0329, -0.0169,  0.0041,  ...,  0.0073,  0.0265, -0.0106],\n",
       "         [-0.0360, -0.0199, -0.0017,  ...,  0.0106,  0.0260, -0.0075],\n",
       "         [-0.0714, -0.0375,  0.0062,  ...,  0.0090,  0.0168,  0.0001]],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.LayerNorm.weight': tensor([0.1584, 0.3347, 0.2878,  ..., 0.3396, 0.3511, 0.3794],\n",
       "        dtype=torch.float16),\n",
       " 'deberta.encoder.LayerNorm.bias': tensor([-0.1101, -0.1172,  0.0080,  ..., -0.0306,  0.0161, -0.1530],\n",
       "        dtype=torch.float16),\n",
       " 'lm_predictions.lm_head.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float16),\n",
       " 'lm_predictions.lm_head.dense.weight': tensor([[-3.5787e-04, -3.8171e-04, -3.6192e-04,  ..., -5.1403e-04,\n",
       "           1.4782e-04,  5.2023e-04],\n",
       "         [ 6.7186e-04, -9.5654e-04, -2.6679e-04,  ..., -2.0885e-04,\n",
       "           4.8137e-04, -1.5593e-04],\n",
       "         [-5.2977e-04,  3.0327e-04,  2.5392e-04,  ..., -2.1398e-05,\n",
       "           4.6909e-05, -2.2173e-05],\n",
       "         ...,\n",
       "         [-6.0940e-04, -2.7966e-04, -8.2111e-04,  ...,  5.3501e-04,\n",
       "          -4.1008e-04, -1.0514e-04],\n",
       "         [ 4.2868e-04,  3.3569e-04, -4.7207e-04,  ...,  8.9169e-05,\n",
       "          -5.6934e-04,  1.6546e-04],\n",
       "         [-2.3425e-05,  1.8787e-04, -7.6580e-04,  ..., -1.6272e-04,\n",
       "          -2.6643e-05, -7.7772e-04]], dtype=torch.float16),\n",
       " 'lm_predictions.lm_head.dense.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float16),\n",
       " 'lm_predictions.lm_head.LayerNorm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float16),\n",
       " 'lm_predictions.lm_head.LayerNorm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float16),\n",
       " 'mask_predictions.dense.weight': tensor([[ 0.0394,  0.0104, -0.0396,  ...,  0.0145,  0.0010,  0.0224],\n",
       "         [ 0.0547,  0.0291,  0.0473,  ..., -0.0226,  0.0072,  0.0185],\n",
       "         [ 0.0378, -0.0279,  0.0297,  ...,  0.0251,  0.0048,  0.0360],\n",
       "         ...,\n",
       "         [-0.0394, -0.0713, -0.0214,  ...,  0.0158, -0.0007,  0.0547],\n",
       "         [-0.0259, -0.0304, -0.0381,  ..., -0.0410,  0.0039,  0.0338],\n",
       "         [ 0.0580, -0.0040, -0.0227,  ...,  0.0041,  0.0035,  0.0286]],\n",
       "        dtype=torch.float16),\n",
       " 'mask_predictions.dense.bias': tensor([-0.0562, -0.0572, -0.0432,  ...,  0.0023,  0.0127, -0.0281],\n",
       "        dtype=torch.float16),\n",
       " 'mask_predictions.LayerNorm.weight': tensor([0.9624, 0.9106, 0.8188,  ..., 0.9189, 0.5723, 0.9653],\n",
       "        dtype=torch.float16),\n",
       " 'mask_predictions.LayerNorm.bias': tensor([0.1306, 0.0424, 0.0654,  ..., 0.0135, 0.2578, 0.0447],\n",
       "        dtype=torch.float16),\n",
       " 'mask_predictions.classifier.weight': tensor([[0.1241, 0.4050, 0.2898,  ..., 0.0498, 0.0488, 0.0818]],\n",
       "        dtype=torch.float16),\n",
       " 'mask_predictions.classifier.bias': tensor([0.0123], dtype=torch.float16)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42289774",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator['deberta.embeddings.word_embeddings._weight'] = discriminator['deberta.embeddings.word_embeddings.weight']\n",
    "discriminator['deberta.embeddings.position_embeddings._weight'] = discriminator['deberta.embeddings.position_embeddings.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b5f2ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2Model(\n",
       "  (embeddings): DebertaV2Embeddings(\n",
       "    (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (encoder): DebertaV2Encoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (1): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (2): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (3): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (4): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (5): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (6): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (7): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (8): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (9): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (10): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (11): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (12): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (13): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (14): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (15): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (16): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (17): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (18): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (19): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (20): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (21): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (22): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (23): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_embeddings): Embedding(512, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModel.from_pretrained('microsoft/deberta-v3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9875686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at models/deberta-v3-large-mental-health-v2 were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'deberta.embeddings.word_embeddings._weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "AutoModel.from_pretrained('models/deberta-v3-large-mental-health-v2').save_pretrained('models/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ebb87d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "new = torch.load('models/test/pytorch_model.bin', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1018a295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deberta.embeddings.word_embeddings.weight',\n",
       " 'deberta.embeddings.position_embeddings.weight',\n",
       " 'deberta.embeddings.LayerNorm.weight',\n",
       " 'deberta.embeddings.LayerNorm.bias']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_k = [k for k in original.keys() if 'deberta.embeddings' in k]\n",
    "n_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88b5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models/roberta-large-mental-health-v1\n",
    "!cp deproberta/trained_models/deproberta_v2/checkpoint-151519-epoch-1/* models/roberta-large-mental-health-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp trained_models/deproberta_v2/checkpoint-151519-epoch-1/pytorch_model.bin pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844123a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
