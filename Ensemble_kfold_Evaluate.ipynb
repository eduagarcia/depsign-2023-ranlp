{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e83683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.multiprocessing.set_start_method('spawn')\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d811204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_df = pd.read_csv('../data/dev_data.csv', encoding=\"utf8\")\n",
    "test_df = pd.read_csv('../data/test_data_with_label.csv', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f1c3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def reencode_and_normalize(text):\n",
    "    transl_table = dict([(ord(x), ord(y)) for x,y in zip( u\"‘’´“”–-\",  u\"'''\\\"\\\"--\")])\n",
    "    fixed_text = text.replace('鈥�', '\"').replace('鉂�', '').encode('gb18030').decode('utf8')\n",
    "    fixed_text = unicodedata.normalize(\"NFKD\", fixed_text)\n",
    "    fixed_text = fixed_text.translate(transl_table)\n",
    "    return fixed_text\n",
    "\n",
    "test_df['Text data'] = test_df['Text data'].apply(reencode_and_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba980a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Text data'] = test_df['Text data'].str.strip()\n",
    "#dev_df['text data'] = dev_df['text data'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562378d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = list(test_df['Text data'].values)\n",
    "#dev_texts = list(dev_df['text data'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49ca4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = 'kfold/output'\n",
    "n_folds = 4\n",
    "\n",
    "model_names = [d for d in os.listdir(models_path) if os.path.isdir(os.path.join(models_path, d)) and not d.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e4cfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regression-v2',\n",
       " 'deberta-mental-health-v3',\n",
       " 'oll-roberta-mental-health-v2-fixloss',\n",
       " 'roberta-large-v3-maxlen',\n",
       " 'deberta-large-v3-maxlen',\n",
       " 'roberta-mental-health-headtail-75',\n",
       " 'roberta-large-v3-maxlen_class_weights',\n",
       " 'roberta-mental-health-headtail-0',\n",
       " 'roberta-large-v3-maxlen_oversampled',\n",
       " 'roberta-mental-health-v3-maxlen',\n",
       " 'corn-roberta-mental-health-v2',\n",
       " 'roberta-mental-health-headtail-50',\n",
       " 'roberta-mental-health-headtail-25',\n",
       " 'roberta-mental-health-v6-labelsmoothing']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9b17427",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0:\"not depression\",\n",
    "    1:\"moderate\",\n",
    "    2:\"severe\"\n",
    "}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ae229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from hypsearch.coral import CoralRobertaForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_model(model_path):\n",
    "    with open(os.path.join(model_path, 'config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    if 'class_regression' in config and config['class_regression']:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=1)\n",
    "    elif ('corn_model' in config or 'coral_model' in config) and (config['corn_model'] or config['coral_model']):\n",
    "        model = CoralRobertaForSequenceClassification.from_pretrained(model_path)\n",
    "    else:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "#model, tokenizer = load_model('hypsearch/output/roberta-large-v3-maxlen/trial_4')\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d269f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from hypsearch.coral import proba_to_label_np, corn_label_from_logits_np\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def predict(texts, model, tokenizer, batchsize=64, device=torch.device('cpu'), max_seq_length=512):\n",
    "    all_logits = []\n",
    "    for i in range(0, len(texts), batchsize):\n",
    "        #print(len(all_logits), len(texts)//batchsize)\n",
    "        batch = texts[i:i+batchsize]\n",
    "        \n",
    "        max_head_limit = None\n",
    "        if hasattr(model.config, 'max_head_limit'):\n",
    "            max_head_limit = model.config.max_head_limit\n",
    "            \n",
    "        if max_head_limit is None:\n",
    "            inputs = tokenizer(batch, truncation=True, padding=True, return_tensors='pt', max_length=max_seq_length).to(device)\n",
    "        else:\n",
    "            head_limit = max_head_limit\n",
    "            if isinstance(head_limit, float):\n",
    "                head_limit = round(max_seq_length*head_limit)\n",
    "                if head_limit == 0:\n",
    "                    head_limit = 1\n",
    "            #print('head_limit', head_limit)\n",
    "            inputs = {\n",
    "                'input_ids': [],\n",
    "                'attention_mask': []\n",
    "            }\n",
    "            tokenized_dataset = tokenizer(batch, padding=True, truncation=False)\n",
    "            token_to_find = tokenizer.sep_token_id\n",
    "            for tokens, attention_mask in zip(tokenized_dataset['input_ids'], tokenized_dataset['attention_mask']):\n",
    "                size = tokens.index(token_to_find) + 1\n",
    "                if size > max_seq_length:\n",
    "                    inputs['input_ids'].append(tokens[:head_limit]+ tokens[size-max_seq_length+head_limit:size])\n",
    "                    inputs['attention_mask'].append(attention_mask[:head_limit]+ attention_mask[size-max_seq_length+head_limit:size])\n",
    "                else:\n",
    "                    inputs['input_ids'].append(tokens[:max_seq_length])\n",
    "                    inputs['attention_mask'].append(attention_mask[:max_seq_length])\n",
    "            inputs['input_ids'] = torch.tensor(inputs['input_ids'], dtype=torch.long, device=device)\n",
    "            inputs['attention_mask'] = torch.tensor(inputs['attention_mask'], dtype=torch.long, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        all_logits.append(outputs.logits.detach().cpu())\n",
    "        \n",
    "        del inputs\n",
    "        del outputs\n",
    "    \n",
    "    all_logits = torch.cat(all_logits)\n",
    "    softmax = F.softmax(all_logits, dim=-1).numpy()\n",
    "    all_logits = all_logits.numpy()\n",
    "    \n",
    "    if (hasattr(model.config, 'class_regression') and model.config.class_regression) or (hasattr(model.config, 'problem_type') and model.config.problem_type == \"regression\"):\n",
    "        soft_preds = np.squeeze(all_logits)\n",
    "        preds = np.clip(np.round(soft_preds).astype(int), 0, len(label2id)-1) \n",
    "        logits_output = np.eye(len(label2id))[preds]\n",
    "        softmax_output = logits_output.copy()\n",
    "    elif (hasattr(model.config, 'corn_model') and model.config.corn_model):\n",
    "        preds = corn_label_from_logits_np(all_logits)\n",
    "        soft_preds = preds.copy()\n",
    "        logits_output = np.eye(len(label2id))[preds]\n",
    "        softmax_output = logits_output.copy()\n",
    "    elif (hasattr(model.config, 'coral_model') and model.config.coral_model):\n",
    "        return None\n",
    "    else:\n",
    "        remap_labels = []\n",
    "        for label in label2id:\n",
    "            remap_labels.append(model.config.label2id[label])\n",
    "        logits_output = all_logits[:, remap_labels].copy()\n",
    "        softmax_output = softmax[:, remap_labels].copy()\n",
    "        preds = softmax_output.argmax(-1)\n",
    "        \n",
    "        #soft preds\n",
    "        #[0.7, 0.1, 0.2] -> (0 + 0.1 + 0.2) -> 0.3\n",
    "        #[0.1, 0.7, 0.2] -> (1 - 0.1 + 0.2) -> 1.1\n",
    "        #[0.1, 0.2, 0.7] -> (2 - 0.1 - 0.2) -> 1.7\n",
    "        \n",
    "        #[0.3, 0.3, 0.4] -> (2 - 0.3 - 0.3) -> 1.4 .round() -> 1 #error\n",
    "        #[0.3333, 0.333, 0.33..4] -> lower bound\n",
    "        #[0.49, 0.0, 0.51] -> (2 - 0.49 - 0.0) -> 1.51 .round() -> 2\n",
    "        dist_mask = np.array([\n",
    "            [0, 1, 1],\n",
    "            [-1, 0, 1],\n",
    "            [-1, -1, 0]\n",
    "        ])\n",
    "\n",
    "        soft_preds = preds + np.clip(np.sum(dist_mask[preds] * softmax_output, axis=-1), -0.499, 0.499)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds, soft_preds, softmax_output, logits_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76fc9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_outputs = {model_name: {} for model_name in model_names}\n",
    "test_outputs = {model_name: {} for model_name in model_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d64073ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del dev_outputs['.ipynb_checkpoints']\n",
    "#del test_outputs['.ipynb_checkpoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9c422a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if os.path.exists('dev_outputs.pickle'):\n",
    "    with open('dev_outputs.pickle', 'rb') as f:\n",
    "        dev_outputs = pickle.load(f)\n",
    "    with open('test_outputs.pickle', 'rb') as f:\n",
    "        test_outputs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b613ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping regression-v2_0\n",
      "skipping deberta-mental-health-v3_0\n",
      "skipping oll-roberta-mental-health-v2-fixloss_0\n",
      "skipping roberta-large-v3-maxlen_0\n",
      "skipping deberta-large-v3-maxlen_0\n",
      "skipping roberta-mental-health-headtail-75_0\n",
      "skipping roberta-mental-health-headtail-0_0\n",
      "skipping roberta-mental-health-v3-maxlen_0\n",
      "skipping corn-roberta-mental-health-v2_0\n",
      "skipping roberta-mental-health-headtail-50_0\n",
      "skipping roberta-mental-health-headtail-25_0\n",
      "skipping roberta-mental-health-v6-labelsmoothing_0\n",
      "kfold/output/regression-v2/fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold/output/deberta-mental-health-v3/fold_1\n",
      "kfold/output/oll-roberta-mental-health-v2-fixloss/fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold/output/roberta-large-v3-maxlen/fold_1\n",
      "kfold/output/deberta-large-v3-maxlen/fold_1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m load_model(model_path)\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 17\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m dev_outputs[model_name][fold]\u001b[38;5;241m.\u001b[39mappend(model_outputs)\n\u001b[1;32m     20\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m predict(test_texts, model, tokenizer, batchsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(texts, model, tokenizer, batchsize, device, max_seq_length)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     43\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 45\u001b[0m all_logits\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m outputs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "device = torch.device('cuda:7')\n",
    "for fold in range(n_folds):\n",
    "    dev_df = pd.read_csv(f'./kfold/{fold}/dev_data.csv', encoding=\"utf8\")\n",
    "    dev_df['text data'] = dev_df['text data'].str.strip()\n",
    "    dev_texts = list(dev_df['text data'].values)\n",
    "    for model_name in model_names:\n",
    "        if len(dev_outputs[model_name][fold]) > 0 and len(test_outputs[model_name][fold]) > 0:\n",
    "            print(f\"skipping {model_name}/fold_{fold}\")\n",
    "            continue\n",
    "        \n",
    "        model_path = os.path.join(models_path, model_name, 'fold_'+str(fold))\n",
    "        print(model_path)\n",
    "        \n",
    "        model, tokenizer = load_model(model_path)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        model_outputs = predict(dev_texts, model, tokenizer, batchsize=128, device=device)\n",
    "        dev_outputs[model_name][fold].append(model_outputs)\n",
    "        \n",
    "        model_outputs = predict(test_texts, model, tokenizer, batchsize=128, device=device)\n",
    "        test_outputs[model_name][fold].append(model_outputs)\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "576fa865",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36520: starting process on GPU cuda:1\n",
      "36521: starting process on GPU cuda:5\n",
      "36522: starting process on GPU cuda:6\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/regression-v2/fold_0\n",
      "kfold/output/deberta-mental-health-v3/fold_0\n",
      "kfold/output/oll-roberta-mental-health-v2-fixloss/fold_0\n",
      "kfold/output/roberta-large-v3-maxlen/fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/deberta-large-v3-maxlen/fold_0\n",
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/roberta-mental-health-headtail-75/fold_0\n",
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-mental-health-headtail-0/fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/roberta-mental-health-v3-maxlen/fold_0\n",
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/corn-roberta-mental-health-v2/fold_0\n",
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-mental-health-headtail-50/fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/roberta-mental-health-headtail-25/fold_0\n",
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/roberta-mental-health-v6-labelsmoothing/fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/regression-v2/fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/deberta-mental-health-v3/fold_1\n",
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/oll-roberta-mental-health-v2-fixloss/fold_1\n",
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/roberta-large-v3-maxlen/fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/deberta-large-v3-maxlen/fold_1\n",
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/roberta-mental-health-headtail-75/fold_1\n",
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/roberta-mental-health-headtail-0/fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-mental-health-v3-maxlen/fold_1\n",
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/corn-roberta-mental-health-v2/fold_1\n",
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/roberta-mental-health-headtail-50/fold_1\n",
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/roberta-mental-health-headtail-25/fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-mental-health-v6-labelsmoothing/fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/regression-v2/fold_2\n",
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/deberta-mental-health-v3/fold_2\n",
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/oll-roberta-mental-health-v2-fixloss/fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-large-v3-maxlen/fold_2\n",
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/deberta-large-v3-maxlen/fold_2\n",
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/roberta-mental-health-headtail-75/fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-mental-health-headtail-0/fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/roberta-mental-health-v3-maxlen/fold_2\n",
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/corn-roberta-mental-health-v2/fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-mental-health-headtail-50/fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/roberta-mental-health-headtail-25/fold_2\n",
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/roberta-mental-health-v6-labelsmoothing/fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/regression-v2/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/deberta-mental-health-v3/fold_3\n",
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/oll-roberta-mental-health-v2-fixloss/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/roberta-large-v3-maxlen/fold_3\n",
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/deberta-large-v3-maxlen/fold_3\n",
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/roberta-mental-health-headtail-75/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/roberta-mental-health-headtail-0/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-mental-health-v3-maxlen/fold_3\n",
      "36520: finished\n",
      "36520: starting process on GPU cuda:1\n",
      "kfold/output/corn-roberta-mental-health-v2/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36523: finished\n",
      "36523: starting process on GPU cuda:7\n",
      "kfold/output/roberta-mental-health-headtail-50/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36521: finished\n",
      "36521: starting process on GPU cuda:5\n",
      "kfold/output/roberta-mental-health-headtail-25/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36522: finished\n",
      "36522: starting process on GPU cuda:6\n",
      "kfold/output/roberta-mental-health-v6-labelsmoothing/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36520: finished\n",
      "36523: finished\n",
      "36521: finished\n",
      "36522: finished\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, current_process, Queue\n",
    "\n",
    "NUM_GPUS = 4\n",
    "PROC_PER_GPU = 1    \n",
    "\n",
    "queue = Queue()\n",
    "\n",
    "data = []\n",
    "for fold in range(n_folds):\n",
    "    for model_name in model_names:\n",
    "        data.append((fold, model_name))\n",
    "        \n",
    "def foo(model_data):\n",
    "    device = queue.get()\n",
    "    #torch.multiprocessing.set_start_method('spawn')\n",
    "    #device = torch.device(f'cuda:{gpu_id}')\n",
    "    fold, model_name = model_data\n",
    "    try:\n",
    "        # run processing on GPU <gpu_id>\n",
    "        ident = current_process().ident\n",
    "        print('{}: starting process on GPU {}'.format(ident, device))\n",
    "        \n",
    "        if len(dev_outputs[model_name][fold]) > 0 and len(test_outputs[model_name][fold]) > 0:\n",
    "            print(f\"skipping {model_name}/fold_{fold}\")\n",
    "            return fold, model_name, dev_outputs[model_name][fold], test_outputs[model_name][fold]\n",
    "        \n",
    "        dev_df = pd.read_csv(f'./kfold/{fold}/dev_data.csv', encoding=\"utf8\")\n",
    "        dev_df['text data'] = dev_df['text data'].str.strip()\n",
    "        dev_texts = list(dev_df['text data'].values)\n",
    "        \n",
    "        model_path = os.path.join(models_path, model_name, 'fold_'+str(fold))\n",
    "        print(model_path)\n",
    "        \n",
    "        model, tokenizer = load_model(model_path)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        dev_model_outputs = predict(dev_texts, model, tokenizer, batchsize=128, device=device)\n",
    "        #dev_outputs[model_name][fold].append(model_outputs)\n",
    "        \n",
    "        test_model_outputs = predict(test_texts, model, tokenizer, batchsize=128, device=device)\n",
    "        #test_outputs[model_name][fold].append(model_outputs)\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print('{}: finished'.format(ident))\n",
    "        return fold, model_name, dev_model_outputs, test_model_outputs\n",
    "    finally:\n",
    "        queue.put(device)\n",
    "\n",
    "# initialize the queue with the GPU ids\n",
    "for gpu_id in [1,5,6,7]:\n",
    "    for _ in range(PROC_PER_GPU):\n",
    "        queue.put(torch.device(f'cuda:{gpu_id}'))\n",
    "\n",
    "pool = Pool(processes=PROC_PER_GPU * NUM_GPUS)\n",
    "for results in pool.imap_unordered(foo, data):\n",
    "    fold, model_name, dev_model_outputs, test_model_outputs = results\n",
    "    dev_outputs[model_name][fold] = dev_model_outputs\n",
    "    test_outputs[model_name][fold] = test_model_outputs\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbebbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c499af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "with open('dev_outputs.pickle', 'wb') as f:\n",
    "    pickle.dump(dev_outputs, f)\n",
    "with open('test_outputs.pickle', 'wb') as f:\n",
    "    pickle.dump(test_outputs, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "328e4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_scores = []\n",
    "temp_model_names = model_names.copy()\n",
    "model_names = []\n",
    "for model_name in temp_model_names:\n",
    "    results_path = os.path.join(models_path, model_name, 'mean_run_results.json')\n",
    "    if not os.path.exists(results_path) or 'class_weights' in model_name:\n",
    "        continue\n",
    "    model_names.append(model_name)\n",
    "    with open(results_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    model_scores.append(results[\"eval_f1 (macro)\"])\n",
    "    #model_scores[model_name] = results[\"eval_f1 (macro)\"]\n",
    "model_scores = np.asarray(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6accf304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_y_true = []\n",
    "for fold in range(n_folds):\n",
    "    dev_df = pd.read_csv(f'./kfold/{fold}/dev_data.csv', encoding=\"utf8\")\n",
    "    y_true = dev_df['label'].map(label2id).values\n",
    "    dev_y_true.append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcbcff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "score_sort = np.flip(model_scores.argsort())\n",
    "sorted_model_names = np.asarray(model_names)[score_sort]\n",
    "all_scores = []\n",
    "for i in range(len(score_sort)):\n",
    "    i = i+1\n",
    "    print(i)\n",
    "    for fold in range(n_folds):\n",
    "        y_true = dev_y_true[fold]\n",
    "        \n",
    "        selected_model_names = sorted_model_names[:i]\n",
    "        \n",
    "        preds = np.asarray([dev_outputs[model_name][fold][0] for model_name in selected_model_names])\n",
    "        soft_preds = np.asarray([dev_outputs[model_name][fold][1] for model_name in selected_model_names])\n",
    "        softmax = np.asarray([dev_outputs[model_name][fold][2] for model_name in selected_model_names])\n",
    "        logits = np.asarray([dev_outputs[model_name][fold][3] for model_name in selected_model_names])\n",
    "        \n",
    "        temp_results = {\n",
    "            \"softmax_mean_preds\": np.mean(softmax, axis=0).argmax(-1),\n",
    "            #\"softmax_max_preds\": np.max(softmax, axis=0).argmax(-1),\n",
    "            #\"logits_mean_preds\": np.mean(logits, axis=0).argmax(-1),\n",
    "            #\"logits_max_preds\": np.max(logits, axis=0).argmax(-1),\n",
    "            \"preds_mode\": stats.mode(preds, axis=0).mode[0],\n",
    "            \"preds_ordered_mean\": np.mean(preds, axis=0).round(),\n",
    "            #\"softmax_to_scalar_mean\": np.mean(soft_preds, axis=0).round()\n",
    "        }\n",
    "        i_scores = {'i': i, 'fold': fold}\n",
    "        for r in temp_results:\n",
    "            i_scores[r] = f1_score(y_true, temp_results[r], average=\"macro\")\n",
    "\n",
    "        all_scores.append(i_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "917ba4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i                     12.000000\n",
       "fold                   3.000000\n",
       "softmax_mean_preds     0.649661\n",
       "preds_mode             0.643666\n",
       "preds_ordered_mean     0.643123\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_scores = pd.DataFrame(all_scores)\n",
    "df_scores.max().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67ebeb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>softmax_mean_preds</th>\n",
       "      <th>preds_mode</th>\n",
       "      <th>preds_ordered_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.617868</td>\n",
       "      <td>0.617868</td>\n",
       "      <td>0.617868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.619412</td>\n",
       "      <td>0.617320</td>\n",
       "      <td>0.615497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.625724</td>\n",
       "      <td>0.625616</td>\n",
       "      <td>0.622821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.626420</td>\n",
       "      <td>0.622458</td>\n",
       "      <td>0.622906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.623963</td>\n",
       "      <td>0.623825</td>\n",
       "      <td>0.622210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.624981</td>\n",
       "      <td>0.625049</td>\n",
       "      <td>0.622107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.628342</td>\n",
       "      <td>0.628872</td>\n",
       "      <td>0.625932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.627416</td>\n",
       "      <td>0.628599</td>\n",
       "      <td>0.627949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.627623</td>\n",
       "      <td>0.630987</td>\n",
       "      <td>0.628563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.627867</td>\n",
       "      <td>0.628945</td>\n",
       "      <td>0.626777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.625788</td>\n",
       "      <td>0.627312</td>\n",
       "      <td>0.625665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.625255</td>\n",
       "      <td>0.628122</td>\n",
       "      <td>0.626102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  softmax_mean_preds  preds_mode  preds_ordered_mean\n",
       "i                                                           \n",
       "1    1.5            0.617868    0.617868            0.617868\n",
       "2    1.5            0.619412    0.617320            0.615497\n",
       "3    1.5            0.625724    0.625616            0.622821\n",
       "4    1.5            0.626420    0.622458            0.622906\n",
       "5    1.5            0.623963    0.623825            0.622210\n",
       "6    1.5            0.624981    0.625049            0.622107\n",
       "7    1.5            0.628342    0.628872            0.625932\n",
       "8    1.5            0.627416    0.628599            0.627949\n",
       "9    1.5            0.627623    0.630987            0.628563\n",
       "10   1.5            0.627867    0.628945            0.626777\n",
       "11   1.5            0.625788    0.627312            0.625665\n",
       "12   1.5            0.625255    0.628122            0.626102"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.groupby('i').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd7e4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Number of Models'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_scores.groupby('i').mean().reset_index(drop=True) \\\n",
    "    .drop('fold', axis=1) \\\n",
    "    .rename(columns={'softmax_mean_preds': 'Softmax Mean',\n",
    "             'preds_ordered_mean': 'Mean', \n",
    "             'preds_mode': 'Voting'})\\\n",
    "    .rename_axis('Number of Models').plot(figsize=(10, 5), xticks=df_scores['i'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a7376a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold                      1.500000\n",
       "preds_mode                0.625415\n",
       "softmax_mean_preds        0.625055\n",
       "logits_mean_preds         0.624508\n",
       "preds_ordered_mean        0.623700\n",
       "softmax_to_scalar_mean    0.621929\n",
       "logits_max_preds          0.618392\n",
       "softmax_max_preds         0.615026\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.groupby('i').mean().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c79fbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold                      1.500000\n",
       "preds_mode                0.630987\n",
       "preds_ordered_mean        0.628563\n",
       "softmax_mean_preds        0.628342\n",
       "logits_mean_preds         0.627189\n",
       "softmax_max_preds         0.624583\n",
       "softmax_to_scalar_mean    0.623753\n",
       "logits_max_preds          0.621622\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.groupby('i').mean().max().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72da6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_model_score = []\n",
    "for i, model_name in enumerate(sorted_model_names):\n",
    "    for fold in range(n_folds):\n",
    "        with open(os.path.join(models_path, model_name, f\"fold_{fold}\", 'all_results.json'), 'r') as f:\n",
    "            results = json.load(f)\n",
    "        analysis_model_score.append({'order': i, 'model_name': model_name, 'fold': fold, 'f1_macro': results[\"eval_f1 (macro)\"]})\n",
    "df_analysis = pd.DataFrame(analysis_model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "462b94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dict = df_analysis.groupby(\"fold\")[\"f1_macro\"].min().to_dict()\n",
    "max_dict = df_analysis.groupby(\"fold\")[\"f1_macro\"].max().to_dict()\n",
    "df_analysis['f1_macro_norm'] = df_analysis.apply(lambda row: (row['f1_macro'] - min_dict[row['fold']])/(max_dict[row['fold']] - min_dict[row['fold']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5882730d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_macro_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>roberta-mental-health-headtail-50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627637</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>roberta-large-v3-maxlen</td>\n",
       "      <td>3</td>\n",
       "      <td>0.622300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>deberta-mental-health-v3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.608772</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>roberta-mental-health-headtail-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.635307</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>roberta-mental-health-headtail-75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607931</td>\n",
       "      <td>0.965447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>roberta-mental-health-headtail-50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606738</td>\n",
       "      <td>0.916430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>roberta-mental-health-headtail-75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633013</td>\n",
       "      <td>0.915506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>roberta-mental-health-v6-labelsmoothing</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606556</td>\n",
       "      <td>0.908957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>corn-roberta-mental-health-v2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624580</td>\n",
       "      <td>0.871162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>roberta-mental-health-headtail-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624477</td>\n",
       "      <td>0.866824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>roberta-mental-health-v3-maxlen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623669</td>\n",
       "      <td>0.832767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>regression-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.617478</td>\n",
       "      <td>0.819772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>roberta-mental-health-headtail-50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629858</td>\n",
       "      <td>0.799252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>roberta-large-v3-maxlen</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628583</td>\n",
       "      <td>0.752290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>deberta-large-v3-maxlen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621525</td>\n",
       "      <td>0.742399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>roberta-mental-health-v3-maxlen</td>\n",
       "      <td>1</td>\n",
       "      <td>0.627830</td>\n",
       "      <td>0.724556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>corn-roberta-mental-health-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.627189</td>\n",
       "      <td>0.700928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>roberta-mental-health-v3-maxlen</td>\n",
       "      <td>3</td>\n",
       "      <td>0.612973</td>\n",
       "      <td>0.651402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>roberta-mental-health-v6-labelsmoothing</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625636</td>\n",
       "      <td>0.643723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>roberta-mental-health-v3-maxlen</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600028</td>\n",
       "      <td>0.640778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>roberta-mental-health-headtail-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.599996</td>\n",
       "      <td>0.639478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>roberta-mental-health-headtail-0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624962</td>\n",
       "      <td>0.618894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8</td>\n",
       "      <td>regression-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.597108</td>\n",
       "      <td>0.520830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>roberta-mental-health-headtail-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.608471</td>\n",
       "      <td>0.483118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>roberta-mental-health-v6-labelsmoothing</td>\n",
       "      <td>3</td>\n",
       "      <td>0.608422</td>\n",
       "      <td>0.481294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>roberta-mental-health-headtail-50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.606771</td>\n",
       "      <td>0.419591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>roberta-large-v3-maxlen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613863</td>\n",
       "      <td>0.419499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>11</td>\n",
       "      <td>oll-roberta-mental-health-v2-fixloss</td>\n",
       "      <td>1</td>\n",
       "      <td>0.618172</td>\n",
       "      <td>0.368740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>deberta-mental-health-v3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612427</td>\n",
       "      <td>0.359006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10</td>\n",
       "      <td>deberta-large-v3-maxlen</td>\n",
       "      <td>3</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>0.318052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9</td>\n",
       "      <td>roberta-mental-health-headtail-0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.603944</td>\n",
       "      <td>0.313936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>roberta-mental-health-v6-labelsmoothing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611121</td>\n",
       "      <td>0.303965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>roberta-mental-health-headtail-75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610484</td>\n",
       "      <td>0.277117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>roberta-mental-health-headtail-75</td>\n",
       "      <td>3</td>\n",
       "      <td>0.602016</td>\n",
       "      <td>0.241864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9</td>\n",
       "      <td>roberta-mental-health-headtail-0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590250</td>\n",
       "      <td>0.239147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>roberta-large-v3-maxlen</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.235604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11</td>\n",
       "      <td>oll-roberta-mental-health-v2-fixloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608774</td>\n",
       "      <td>0.205037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>11</td>\n",
       "      <td>oll-roberta-mental-health-v2-fixloss</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600715</td>\n",
       "      <td>0.193230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>corn-roberta-mental-health-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600497</td>\n",
       "      <td>0.185084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>deberta-mental-health-v3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611232</td>\n",
       "      <td>0.113077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10</td>\n",
       "      <td>deberta-large-v3-maxlen</td>\n",
       "      <td>2</td>\n",
       "      <td>0.587105</td>\n",
       "      <td>0.109947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>roberta-mental-health-headtail-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.606421</td>\n",
       "      <td>0.105865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11</td>\n",
       "      <td>oll-roberta-mental-health-v2-fixloss</td>\n",
       "      <td>2</td>\n",
       "      <td>0.585977</td>\n",
       "      <td>0.063632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>regression-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608230</td>\n",
       "      <td>0.002473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>corn-roberta-mental-health-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.584428</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10</td>\n",
       "      <td>deberta-large-v3-maxlen</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608163</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>regression-v2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.603909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>deberta-mental-health-v3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.595545</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order                               model_name  fold  f1_macro  \\\n",
       "0       0        roberta-mental-health-headtail-50     0  0.627637   \n",
       "15      3                  roberta-large-v3-maxlen     3  0.622300   \n",
       "30      7                 deberta-mental-health-v3     2  0.608772   \n",
       "5       1        roberta-mental-health-headtail-25     1  0.635307   \n",
       "18      4        roberta-mental-health-headtail-75     2  0.607931   \n",
       "2       0        roberta-mental-health-headtail-50     2  0.606738   \n",
       "17      4        roberta-mental-health-headtail-75     1  0.633013   \n",
       "22      5  roberta-mental-health-v6-labelsmoothing     2  0.606556   \n",
       "24      6            corn-roberta-mental-health-v2     0  0.624580   \n",
       "4       1        roberta-mental-health-headtail-25     0  0.624477   \n",
       "8       2          roberta-mental-health-v3-maxlen     0  0.623669   \n",
       "35      8                            regression-v2     3  0.617478   \n",
       "1       0        roberta-mental-health-headtail-50     1  0.629858   \n",
       "13      3                  roberta-large-v3-maxlen     1  0.628583   \n",
       "40     10                  deberta-large-v3-maxlen     0  0.621525   \n",
       "9       2          roberta-mental-health-v3-maxlen     1  0.627830   \n",
       "25      6            corn-roberta-mental-health-v2     1  0.627189   \n",
       "11      2          roberta-mental-health-v3-maxlen     3  0.612973   \n",
       "21      5  roberta-mental-health-v6-labelsmoothing     1  0.625636   \n",
       "10      2          roberta-mental-health-v3-maxlen     2  0.600028   \n",
       "6       1        roberta-mental-health-headtail-25     2  0.599996   \n",
       "37      9         roberta-mental-health-headtail-0     1  0.624962   \n",
       "34      8                            regression-v2     2  0.597108   \n",
       "7       1        roberta-mental-health-headtail-25     3  0.608471   \n",
       "23      5  roberta-mental-health-v6-labelsmoothing     3  0.608422   \n",
       "3       0        roberta-mental-health-headtail-50     3  0.606771   \n",
       "12      3                  roberta-large-v3-maxlen     0  0.613863   \n",
       "45     11     oll-roberta-mental-health-v2-fixloss     1  0.618172   \n",
       "28      7                 deberta-mental-health-v3     0  0.612427   \n",
       "43     10                  deberta-large-v3-maxlen     3  0.604054   \n",
       "39      9         roberta-mental-health-headtail-0     3  0.603944   \n",
       "20      5  roberta-mental-health-v6-labelsmoothing     0  0.611121   \n",
       "16      4        roberta-mental-health-headtail-75     0  0.610484   \n",
       "19      4        roberta-mental-health-headtail-75     3  0.602016   \n",
       "38      9         roberta-mental-health-headtail-0     2  0.590250   \n",
       "14      3                  roberta-large-v3-maxlen     2  0.590164   \n",
       "44     11     oll-roberta-mental-health-v2-fixloss     0  0.608774   \n",
       "47     11     oll-roberta-mental-health-v2-fixloss     3  0.600715   \n",
       "27      6            corn-roberta-mental-health-v2     3  0.600497   \n",
       "29      7                 deberta-mental-health-v3     1  0.611232   \n",
       "42     10                  deberta-large-v3-maxlen     2  0.587105   \n",
       "36      9         roberta-mental-health-headtail-0     0  0.606421   \n",
       "46     11     oll-roberta-mental-health-v2-fixloss     2  0.585977   \n",
       "33      8                            regression-v2     1  0.608230   \n",
       "26      6            corn-roberta-mental-health-v2     2  0.584428   \n",
       "41     10                  deberta-large-v3-maxlen     1  0.608163   \n",
       "32      8                            regression-v2     0  0.603909   \n",
       "31      7                 deberta-mental-health-v3     3  0.595545   \n",
       "\n",
       "    f1_macro_norm  \n",
       "0        1.000000  \n",
       "15       1.000000  \n",
       "30       1.000000  \n",
       "5        1.000000  \n",
       "18       0.965447  \n",
       "2        0.916430  \n",
       "17       0.915506  \n",
       "22       0.908957  \n",
       "24       0.871162  \n",
       "4        0.866824  \n",
       "8        0.832767  \n",
       "35       0.819772  \n",
       "1        0.799252  \n",
       "13       0.752290  \n",
       "40       0.742399  \n",
       "9        0.724556  \n",
       "25       0.700928  \n",
       "11       0.651402  \n",
       "21       0.643723  \n",
       "10       0.640778  \n",
       "6        0.639478  \n",
       "37       0.618894  \n",
       "34       0.520830  \n",
       "7        0.483118  \n",
       "23       0.481294  \n",
       "3        0.419591  \n",
       "12       0.419499  \n",
       "45       0.368740  \n",
       "28       0.359006  \n",
       "43       0.318052  \n",
       "39       0.313936  \n",
       "20       0.303965  \n",
       "16       0.277117  \n",
       "19       0.241864  \n",
       "38       0.239147  \n",
       "14       0.235604  \n",
       "44       0.205037  \n",
       "47       0.193230  \n",
       "27       0.185084  \n",
       "29       0.113077  \n",
       "42       0.109947  \n",
       "36       0.105865  \n",
       "46       0.063632  \n",
       "33       0.002473  \n",
       "26       0.000000  \n",
       "41       0.000000  \n",
       "32       0.000000  \n",
       "31       0.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis.sort_values([\"f1_macro_norm\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c36d29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_analysis, x=\"fold\", y=\"f1_macro_norm\", color=\"model_name\")\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc97f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "mean_preds = []\n",
    "mode_preds = []\n",
    "all_preds = []\n",
    "mean_softmaxs = []\n",
    "mean_logits = []\n",
    "selected_model_names = sorted_model_names[:i]\n",
    "for model_name in selected_model_names:\n",
    "    fold_preds = np.asarray([test_outputs[model_name][fold][0] for fold in range(n_folds)])\n",
    "    fold_softmaxs = np.asarray([test_outputs[model_name][fold][2] for fold in range(n_folds)])\n",
    "    fold_logits = np.asarray([test_outputs[model_name][fold][3] for fold in range(n_folds)])\n",
    "    all_preds.extend(fold_preds)\n",
    "    model_mod_preds = stats.mode(fold_preds, axis=0).mode[0]\n",
    "    mode_preds.append(model_mod_preds)\n",
    "    model_mean_preds = np.mean(fold_preds, axis=0).round()\n",
    "    mean_preds.append(model_mean_preds)\n",
    "    mean_softmax = np.mean(fold_softmaxs, axis=0)\n",
    "    mean_softmaxs.append(mean_softmax)\n",
    "    mean_logit = np.mean(fold_logits, axis=0)\n",
    "    mean_logits.append(mean_logit)\n",
    "preds = np.asarray(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dceff04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"best_model_mode\": mode_preds[0],\n",
    "    \"best_model_mean\": mean_preds[0],\n",
    "    \"best_model_softmax\": mean_softmaxs[0].argmax(axis=1),\n",
    "    \"best_model_logits\": mean_logits[0].argmax(axis=1),\n",
    "    \"best_model_fold1_preds\": test_outputs[selected_model_names[0]][3][0],\n",
    "    \"s1_model_mode\": mode_preds[3],\n",
    "    \"s1_model_mean\": mean_preds[3],\n",
    "    \"s1_model_softmax\": mean_softmaxs[3].argmax(axis=1),\n",
    "    #\"mode_mode\": stats.mode(mode_preds, axis=0).mode[0],\n",
    "    \"mode_mean\": stats.mode(mean_preds, axis=0).mode[0],\n",
    "    \"mode_all\": stats.mode(all_preds, axis=0).mode[0],\n",
    "    \"softmax_all\": np.mean(mean_softmaxs, axis=0).argmax(axis=1),\n",
    "    #\"mean_mode\": np.mean(mode_preds, axis=0).round(),\n",
    "    #\"mean_mean\": np.mean(mean_preds, axis=0).round(),\n",
    "    #\"mean_all\": np.mean(all_preds, axis=0).round(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4d8110c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_model_mode': 0.4634765971078402,\n",
       " 'best_model_mean': 0.4678242848916388,\n",
       " 'best_model_softmax': 0.49153318277165753,\n",
       " 'best_model_logits': 0.48775718862675377,\n",
       " 'best_model_fold1_preds': 0.4765829224325954,\n",
       " 's1_model_mode': 0.4479995191360986,\n",
       " 's1_model_mean': 0.44971944372792727,\n",
       " 's1_model_softmax': 0.45046604302135335,\n",
       " 'mode_mean': 0.4435152053234326,\n",
       " 'mode_all': 0.4512634212924254,\n",
       " 'softmax_all': 0.4667614051510344}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_scores = {}\n",
    "test_y_true = test_df['Label'].map(label2id).values\n",
    "for r in results:\n",
    "    i_scores[r] = f1_score(test_y_true, results[r], average=\"macro\")\n",
    "i_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "190492fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = set()\n",
    "for k1 in results.keys():\n",
    "    for k2 in results.keys():\n",
    "        if k1 == k2:\n",
    "            continue\n",
    "        key_pair = frozenset([k1, k2])\n",
    "        pairs.add(key_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d9c2b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_mean mode_all 39\n",
      "mode_all mode_mean 30\n",
      "best_model_mean mode_mean 31\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs:\n",
    "    pair = list(pair)\n",
    "    print(pair[0], pair[1], (results[pair[0]] != results[pair[1]]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1d2c824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    #\"BestModel\": mode_preds[0],\n",
    "    \"BestModel4Mean\": mean_preds[0],\n",
    "    #\"KFoldMode\": stats.mode(mode_preds, axis=0).mode[0],\n",
    "    \"KFoldMean9Mode\": stats.mode(mean_preds, axis=0).mode[0],\n",
    "    \"All36Mode\": stats.mode(all_preds, axis=0).mode[0],\n",
    "    #\"mean_mode\": np.mean(mode_preds, axis=0).round(),\n",
    "    #\"mean_mean\": np.mean(mean_preds, axis=0).round(),\n",
    "    #\"mean_all\": np.mean(all_preds, axis=0).round(),\n",
    "}\n",
    "\n",
    "for name, preds_model in results.items():\n",
    "    sub_df = test_df.copy()\n",
    "    sub_df['class_label'] = preds_model\n",
    "    sub_df['class_label'] = sub_df['class_label'].map(id2label)\n",
    "    sub_df['pid'] = sub_df['Pid']\n",
    "    sub_df.to_csv(os.path.join('submissions', name+'_v2.csv'), index=False)\n",
    "    sub_df[['pid', 'class_label']].to_csv(os.path.join('submissions', 'DeepLearningBrasil_'+name+'_v2.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6b490fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results[\"best_model\"] != results[\"mode\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb90022a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results[\"best_model\"] != results[\"mode_all\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "538d47d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results[\"mode_all\"] != results[\"mode\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09f5286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_mean(preds):\n",
    "    #map_ordered = {0:1, 1:0, 2:2}\n",
    "    #unmap_ordered = {1:0, 0:1, 2:2}\n",
    "    \n",
    "    pred_ordered = preds#np.vectorize(lambda x: map_ordered[x])(preds)\n",
    "    pred_ordered_mean = np.mean(pred_ordered, axis=0).round()\n",
    "    #pred_ordered_mean_unmap = np.vectorize(lambda x: unmap_ordered[x])(pred_ordered_mean)\n",
    "    return pred_ordered\n",
    "\n",
    "def softmax_to_scalar_mean(softmax):\n",
    "    #[0.7, 0.1, 0.2] -> (0 + 0.1 + 0.2) -> 0.3\n",
    "    #[0.1, 0.7, 0.2] -> (1 - 0.1 + 0.2) -> 1.1\n",
    "    #[0.1, 0.2, 0.7] -> (2 - 0.1 - 0.2) -> 1.7\n",
    "    \n",
    "    #[0.49, 0.0, 0.51] -> (2 - 0.49 - 0.0) -> 1.51 .round() -> 2\n",
    "    #map_ordered = [1,0,2]\n",
    "    #unmap_ordered = {1:0, 0:1, 2:2}\n",
    "    dist_mask = np.array([\n",
    "        [0, 1, 1],\n",
    "        [-1, 0, 1],\n",
    "        [-1, -1, 0]\n",
    "    ])\n",
    "    \n",
    "    #map_ordered = [1,0,2]\n",
    "    softmax_ordered = softmax#[:, :, map_ordered]\n",
    "    preds_ordered = softmax_ordered.argmax(-1)\n",
    "    scalar_labels = preds_ordered + np.sum(dist_mask[preds_ordered] * softmax_ordered, axis=-1)\n",
    "    scalar_labels_mean = np.mean(scalar_labels, axis=0).round()\n",
    "    #scalar_labels_mean_unmap = np.vectorize(lambda x: unmap_ordered[x])(scalar_labels_mean)\n",
    "    return scalar_labels_mean#_unmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005ff415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "score_sort = np.flip(model_scores.argsort())\n",
    "all_scores = []\n",
    "for i in range(len(score_sort)):\n",
    "    i = i+1\n",
    "    print(i)\n",
    "    temp_results = {\n",
    "        \"softmax_mean_preds\": np.mean(softmax[score_sort][:i], axis=0).argmax(-1),\n",
    "        \"softmax_max_preds\": np.max(softmax[score_sort][:i], axis=0).argmax(-1),\n",
    "        \"logits_mean_preds\": np.mean(logits[score_sort][:i], axis=0).argmax(-1),\n",
    "        \"logits_max_preds\": np.max(logits[score_sort][:i], axis=0).argmax(-1),\n",
    "        \"preds_mode\": stats.mode(preds[score_sort][:i], axis=0).mode[0],\n",
    "        \"preds_ordered_mean\": np.mean(preds[score_sort][:i], axis=0).round(),\n",
    "        \"softmax_to_scalar_mean\": np.mean(soft_preds[score_sort][:i], axis=0).round()\n",
    "    }\n",
    "    i_scores = {'i': i}\n",
    "    for r in temp_results:\n",
    "        i_scores[r] = f1_score(y_true, temp_results[r], average=\"macro\")\n",
    "    \n",
    "    all_scores.append(i_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035cad31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds[score_sort[0]] != soft_preds[score_sort[0]].round()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "327b63e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[score_sort[0]][(preds[score_sort[0]] != soft_preds[score_sort[0]].round())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef5fc972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_preds[score_sort[0]][(preds[score_sort[0]] != soft_preds[score_sort[0]].round())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a05494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i                         12.000000\n",
       "preds_ordered_mean         0.616459\n",
       "preds_mode                 0.613477\n",
       "softmax_to_scalar_mean     0.605563\n",
       "softmax_mean_preds         0.604406\n",
       "logits_mean_preds          0.602459\n",
       "logits_max_preds           0.595776\n",
       "softmax_max_preds          0.593982\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_scores = pd.DataFrame(all_scores)\n",
    "df_scores.max().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e72656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i                         6.500000\n",
       "preds_ordered_mean        0.605867\n",
       "preds_mode                0.603373\n",
       "softmax_to_scalar_mean    0.601801\n",
       "softmax_mean_preds        0.598653\n",
       "logits_mean_preds         0.597429\n",
       "softmax_max_preds         0.589351\n",
       "logits_max_preds          0.584376\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61aab4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>softmax_mean_preds</th>\n",
       "      <th>softmax_max_preds</th>\n",
       "      <th>logits_mean_preds</th>\n",
       "      <th>logits_max_preds</th>\n",
       "      <th>preds_mode</th>\n",
       "      <th>preds_ordered_mean</th>\n",
       "      <th>softmax_to_scalar_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.593982</td>\n",
       "      <td>0.593982</td>\n",
       "      <td>0.593982</td>\n",
       "      <td>0.593982</td>\n",
       "      <td>0.593982</td>\n",
       "      <td>0.593982</td>\n",
       "      <td>0.593982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.592261</td>\n",
       "      <td>0.592261</td>\n",
       "      <td>0.591864</td>\n",
       "      <td>0.595776</td>\n",
       "      <td>0.598089</td>\n",
       "      <td>0.591414</td>\n",
       "      <td>0.596315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.604406</td>\n",
       "      <td>0.592261</td>\n",
       "      <td>0.595936</td>\n",
       "      <td>0.584727</td>\n",
       "      <td>0.609223</td>\n",
       "      <td>0.608227</td>\n",
       "      <td>0.598572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.601786</td>\n",
       "      <td>0.592261</td>\n",
       "      <td>0.596753</td>\n",
       "      <td>0.585579</td>\n",
       "      <td>0.606778</td>\n",
       "      <td>0.609412</td>\n",
       "      <td>0.605563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.601783</td>\n",
       "      <td>0.592261</td>\n",
       "      <td>0.599133</td>\n",
       "      <td>0.584756</td>\n",
       "      <td>0.613477</td>\n",
       "      <td>0.616459</td>\n",
       "      <td>0.605318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.600588</td>\n",
       "      <td>0.592261</td>\n",
       "      <td>0.602459</td>\n",
       "      <td>0.586288</td>\n",
       "      <td>0.605748</td>\n",
       "      <td>0.610771</td>\n",
       "      <td>0.604332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.600801</td>\n",
       "      <td>0.592261</td>\n",
       "      <td>0.599964</td>\n",
       "      <td>0.583080</td>\n",
       "      <td>0.606795</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.603021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.600832</td>\n",
       "      <td>0.584932</td>\n",
       "      <td>0.600647</td>\n",
       "      <td>0.583393</td>\n",
       "      <td>0.600338</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.603071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.599474</td>\n",
       "      <td>0.584932</td>\n",
       "      <td>0.597920</td>\n",
       "      <td>0.582382</td>\n",
       "      <td>0.606019</td>\n",
       "      <td>0.610273</td>\n",
       "      <td>0.602940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.599536</td>\n",
       "      <td>0.584932</td>\n",
       "      <td>0.599192</td>\n",
       "      <td>0.579655</td>\n",
       "      <td>0.599782</td>\n",
       "      <td>0.606976</td>\n",
       "      <td>0.602096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.592862</td>\n",
       "      <td>0.584932</td>\n",
       "      <td>0.598023</td>\n",
       "      <td>0.578384</td>\n",
       "      <td>0.600918</td>\n",
       "      <td>0.604269</td>\n",
       "      <td>0.603121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.595525</td>\n",
       "      <td>0.584932</td>\n",
       "      <td>0.593275</td>\n",
       "      <td>0.574507</td>\n",
       "      <td>0.599328</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.603279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     i  softmax_mean_preds  softmax_max_preds  logits_mean_preds  \\\n",
       "0    1            0.593982           0.593982           0.593982   \n",
       "1    2            0.592261           0.592261           0.591864   \n",
       "2    3            0.604406           0.592261           0.595936   \n",
       "3    4            0.601786           0.592261           0.596753   \n",
       "4    5            0.601783           0.592261           0.599133   \n",
       "5    6            0.600588           0.592261           0.602459   \n",
       "6    7            0.600801           0.592261           0.599964   \n",
       "7    8            0.600832           0.584932           0.600647   \n",
       "8    9            0.599474           0.584932           0.597920   \n",
       "9   10            0.599536           0.584932           0.599192   \n",
       "10  11            0.592862           0.584932           0.598023   \n",
       "11  12            0.595525           0.584932           0.593275   \n",
       "\n",
       "    logits_max_preds  preds_mode  preds_ordered_mean  softmax_to_scalar_mean  \n",
       "0           0.593982    0.593982            0.593982                0.593982  \n",
       "1           0.595776    0.598089            0.591414                0.596315  \n",
       "2           0.584727    0.609223            0.608227                0.598572  \n",
       "3           0.585579    0.606778            0.609412                0.605563  \n",
       "4           0.584756    0.613477            0.616459                0.605318  \n",
       "5           0.586288    0.605748            0.610771                0.604332  \n",
       "6           0.583080    0.606795            0.609272                0.603021  \n",
       "7           0.583393    0.600338            0.607383                0.603071  \n",
       "8           0.582382    0.606019            0.610273                0.602940  \n",
       "9           0.579655    0.599782            0.606976                0.602096  \n",
       "10          0.578384    0.600918            0.604269                0.603121  \n",
       "11          0.574507    0.599328            0.601961                0.603279  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0372696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"softmax_mean_preds\": np.mean(softmax, axis=0).argmax(-1),\n",
    "    \"softmax_max_preds\": np.max(softmax, axis=0).argmax(-1),\n",
    "    \"logits_mean_preds\": np.mean(logits, axis=0).argmax(-1),\n",
    "    \"logits_max_preds\": np.max(logits, axis=0).argmax(-1),\n",
    "    \"preds_mode\": stats.mode(preds, axis=0).mode[0],\n",
    "    \"preds_ordered_mean\": np.mean(preds, axis=0).round(),\n",
    "    \"softmax_to_scalar_mean\": np.mean(soft_preds, axis=0).round()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0be0c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'softmax_to_scalar_mean': 0.6032792363637886,\n",
       " 'preds_ordered_mean': 0.6019612850902755,\n",
       " 'preds_mode': 0.5993277234770933,\n",
       " 'softmax_mean_preds': 0.5955246275632538,\n",
       " 'logits_mean_preds': 0.5932751647612658,\n",
       " 'softmax_max_preds': 0.584931618534673,\n",
       " 'logits_max_preds': 0.5745068159059707}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "for r in results:\n",
    "    scores[r] = f1_score(y_true, results[r], average=\"macro\")\n",
    "dict(sorted(scores.items(), key=lambda item: item[1], reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
